{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# todo   description                              hours  progress    hours_spent\n",
        "# todo0: no lib python function csv parser.          ~6  COMPLETE\n",
        "# todo1: make defs from repeated code.               ~1  COMPLETE\n",
        "# todo2: def into class.                             ~1  COMPLETE\n",
        "# todo3: flip column                                 ~2  COMPLETE\n",
        "# todo4: improve efficiency auxilliary space         ~7  COMPLETE\n",
        "# todo5: mean, standard deviation                    ~6  COMPLETE\n",
        "# todo6: kurt, skew, covar, cor, r squared, ANOVA    ~9  PROCESSING  10.5\n",
        "# todo7: interpret results                           ~20\n",
        "#                                             TOTAL  ~ PROCESSING\n",
        "import sys\n",
        "#from datetime import datetime\n",
        "print(sys.version)\n",
        "# 3.10.12 (main, Mar 22 2024, 16:50:05) [GCC 11.4.0]\n",
        "\n",
        "# Part A: CSV parser class to open the file and parse the values into a list\n",
        "class CSV_Parser:\n",
        "  # Initialize the input variables\n",
        "  def __init__(self, data_path, data_bool):\n",
        "    self.data_path = data_path\n",
        "    self.data_bool = data_bool\n",
        "  # Function to open file, 1 to print contents, 0 to not print\n",
        "  def file_opener(self):\n",
        "    with open(self.data_path, \"r\") as data_open:\n",
        "      data_read = data_open.read()\n",
        "      if self.data_bool == 1:\n",
        "        print(data_read)\n",
        "      return data_read\n",
        "  # Index the commas and line breaks\n",
        "  def comma_index(self, open_file):\n",
        "    data_comma_place = []\n",
        "    column_pl_len = 0\n",
        "    for i in range(len(open_file)):\n",
        "      data1_col1 = open_file[i]\n",
        "      if data1_col1 == \",\":\n",
        "        data_comma_place.append(i)\n",
        "      if data1_col1 == \"\\n\":\n",
        "        data_comma_place.append(i)\n",
        "    las_val = data_comma_place[-1] + 2\n",
        "    data_comma_place.append(las_val)\n",
        "    return data_comma_place\n",
        "  # Get the width of the column TODO avoid repeated code\n",
        "  def comma_width(self, open_file, column_len):\n",
        "    data_comma_place = []\n",
        "    column_pl_len = 0\n",
        "    for i in range(len(open_file)):\n",
        "      data1_col1 = open_file[i]\n",
        "      if data1_col1 == \",\":\n",
        "        data_comma_place.append(i)\n",
        "      if data1_col1 == \"\\n\":\n",
        "        data_comma_place.append(i)\n",
        "        # If you want to use the function to get the column width, set to 1\n",
        "        if column_len == 1:\n",
        "          data_comma_place = len(data_comma_place)\n",
        "          break\n",
        "    return data_comma_place\n",
        "  # Splitting the csv characters into list of words based on indexed comma position\n",
        "  def csv_value_list(self, data_comma_out, open_file):\n",
        "    j = 0\n",
        "    data_val_list = []\n",
        "    for k in data_comma_out:\n",
        "      data_val = open_file[j:k]\n",
        "      data_val_list.append(data_val)\n",
        "      j = k + 1\n",
        "    return data_val_list\n",
        "\n",
        "  # Flipping the columns from high to low for readability\n",
        "  # If the original value was 5, set it to equal 0 (no pain)\n",
        "  # If the original value was 0, set it to equal to 5 (high pain) etc.\n",
        "  def csv_flipper(self, csv_list, col_num):\n",
        "    csv_flipped = []\n",
        "    j = 0\n",
        "    for m in csv_list:\n",
        "      # The j counts the position to append the id\n",
        "      # If the j or count is divisible by the number of columns\n",
        "      # (the column) is appended to the list. Otherwise the first 5 ID column\n",
        "      # would also be flipped since they are equal to the numbers\n",
        "      # The first 'if' statement excludes the \"ID\" column at position \"0\"\n",
        "      if j % col_num == 0:\n",
        "        csv_flipped.append(m)\n",
        "      elif m == str(5):\n",
        "        n = str(1)\n",
        "        csv_flipped.append(n)\n",
        "      elif m == str(4):\n",
        "        n = str(2)\n",
        "        csv_flipped.append(n)\n",
        "      elif m == str(3):\n",
        "        n = str(3)\n",
        "        csv_flipped.append(n)\n",
        "      elif m == str(2):\n",
        "        n = str(4)\n",
        "        csv_flipped.append(n)\n",
        "      elif m == str(1):\n",
        "        n = str(5)\n",
        "        csv_flipped.append(n)\n",
        "      else:\n",
        "        csv_flipped.append(m)\n",
        "      j += 1\n",
        "    return csv_flipped\n",
        "\n",
        "  # Append the unflipped stamina column to the flipped pain scale columns\n",
        "  # (three steps)\n",
        "\n",
        "  # Step 0) Extract the fourth column (3) by making a list of every nth (n-1)\n",
        "  # value the width of the column (col_num)\n",
        "  def stm_extract(self, csv_list, col_num):\n",
        "    stamina_col = []\n",
        "    j = col_num - 1\n",
        "    for sta in csv_list[3:]:\n",
        "      if j == col_num - 1:\n",
        "        stamina_col.append(sta)\n",
        "        j = 0\n",
        "      else:\n",
        "        j += 1\n",
        "    return stamina_col\n",
        "  # Step 1) Remove flipped stamina values from third column\n",
        "  def stm_remove(self, flip_list, col_num):\n",
        "    og_col_num = col_num - 1\n",
        "    og_flip_list_len = len(flip_list)\n",
        "    col_len = 32\n",
        "    for i in range(len(flip_list)):\n",
        "      if i == (og_flip_list_len - (col_len)):\n",
        "        break\n",
        "      elif i == 3:\n",
        "        flip_list.pop(i)\n",
        "        col_num = i + col_num - 1\n",
        "      elif i == col_num:\n",
        "        flip_list.pop(i)\n",
        "        col_num += og_col_num\n",
        "    return flip_list\n",
        "  # Step 2) Append unflipped stamina values to flipped list as a new column\n",
        "  def stm_append(self, stm_rm, stamina_col, col_num):\n",
        "    og_col_num = col_num\n",
        "    col_len = 32\n",
        "    j = 0\n",
        "    for i in range(len(stm_rm) + col_len):\n",
        "      if i == 3:\n",
        "        stm_rm.insert(i, stamina_col[j])\n",
        "        col_num = i + col_num\n",
        "        j += 1\n",
        "      elif i == col_num:\n",
        "        stm_rm.insert(i, stamina_col[j])\n",
        "        col_num += og_col_num\n",
        "        j += 1\n",
        "    return stm_rm\n",
        "\n",
        "  # Part B: Get descriptive statistics of each column, starting with the mean.\n",
        "  def mu(self, stm_ext_flip, col_num, strt_col):\n",
        "    # The first three values are dates and id and dont need means\n",
        "    # The number of actual values i.e. the days in the month of study\n",
        "    col_len = 32 - 1\n",
        "    strt_col_val = col_num + strt_col\n",
        "    total = 0\n",
        "    for i in range(col_len):\n",
        "      total = total + int(stm_ext_flip[strt_col_val])\n",
        "      strt_col_val += col_num\n",
        "    mean = float(total / col_len)\n",
        "    return mean\n",
        "\n",
        "  # The standard deviation using the mean previously defined in 'mu'\n",
        "  # https://www.nlm.nih.gov/oet/ed/stats/02-900.html\n",
        "\n",
        "  # TODO Refractor the following statistical methods\n",
        "  def stn(self, data1_stm_flip, col_num, strt_col, mean):\n",
        "    col_len = 32 - 1\n",
        "    strt_col_val = col_num + strt_col\n",
        "    sig_cap = 0\n",
        "    for i in range(col_len):\n",
        "      # Issue 0: CSV with whole integers only at the moment\n",
        "      n1 = int(data1_stm_flip[strt_col_val]) - mean\n",
        "      n1_sqr = n1 ** 2\n",
        "      sig_cap = sig_cap + n1_sqr\n",
        "      strt_col_val += col_num\n",
        "    sig_small_sqr = float(sig_cap) / float(col_len)\n",
        "    sig_small = sig_small_sqr ** .5\n",
        "    return sig_small\n",
        "  # Kurtosis or the tailness (see kurtosis descriptions)\n",
        "  # The fourth standardized moment\n",
        "  # = ((sigcap(xi - mu) ^ 4) / n) / ((sigcap(xi - mu) ^ 2) / n)\n",
        "  def kur(self, data1_stm_flip, col_num, strt_col, mean, stn_dev):\n",
        "    col_len = 32 - 1\n",
        "    strt_col_val = col_num + strt_col\n",
        "    s4 = 0\n",
        "    for i in range(col_len):\n",
        "      # (xi - mu)^4 / n\n",
        "      n1 = int(data1_stm_flip[strt_col_val]) - mean\n",
        "      n1_quar = n1 ** 4\n",
        "      s4 = s4 + n1_quar\n",
        "      strt_col_val += col_num\n",
        "    m4 = float(s4) / float(col_len)\n",
        "    kurt = m4 / (stn_dev)**4\n",
        "    return kurt\n",
        "  # The skewness or the third standardized moment\n",
        "  def skew(self, data1_stm_flip, col_num, strt_col, mean, stn_dev):\n",
        "    col_len = 32 - 1\n",
        "    strt_col_val = col_num + strt_col\n",
        "    s3 = 0\n",
        "    for i in range(col_len):\n",
        "      # (xi - mu)^3 / n\n",
        "      n1 = int(data1_stm_flip[strt_col_val]) - mean\n",
        "      n1_cube = n1 ** 3\n",
        "      s3 = s3 + n1_cube\n",
        "      strt_col_val += col_num\n",
        "    m3 = float(s3) / float(col_len)\n",
        "    skew = m3 / (stn_dev)**3\n",
        "    return skew\n",
        "  # Find the covariance of each column\n",
        "  # Cov = (Xi-Xmu)(Yi−Ymu) / n\n",
        "  def covar(self, data1_stm_flip, data1_col_num, data1_mean_list, data1_strt_col, data2_list, data2_col_num, data2_mean_list, data2_strt_col):\n",
        "    col_len = 32 - 1\n",
        "    data1_strt_col_val = data1_col_num + data1_strt_col\n",
        "    data2_strt_col_val = data2_col_num + data2_strt_col\n",
        "    s1 = 0\n",
        "    for i in range(col_len):\n",
        "      x1 = float(data1_stm_flip[data1_strt_col_val]) - data1_mean_list[data1_strt_col-3]\n",
        "      # 2 is the starting column (width of column - starting column)\n",
        "      y1 = float(data2_list[data2_strt_col_val]) - data2_mean_list[data2_strt_col-2]\n",
        "      x1y1 = x1 * y1\n",
        "      s1 = s1 + x1y1\n",
        "      data1_strt_col_val += data1_col_num\n",
        "      data2_strt_col_val += data2_col_num\n",
        "    covar = s1 / col_len\n",
        "    return covar\n",
        "  # Correlation for population is covariance over the product of the two SD\n",
        "  # ρX,Y = cov(X,Y) / σXσY\n",
        "  def cor(self, covar, stn1, stn2):\n",
        "    # rho = covar / (stn1 * stn2)\n",
        "    count = 0\n",
        "    rho_list = []\n",
        "    for i in stn1:\n",
        "      for j in stn2:\n",
        "        sd1sd2 = i * j\n",
        "        rho = covar[count] / sd1sd2\n",
        "        rho_list.append(rho)\n",
        "        count += 1\n",
        "    return rho_list\n",
        "  def r_sqr(self):\n",
        "    return\n",
        "  def anova(self):\n",
        "    return\n",
        "\n",
        "# Part A\n",
        "# Execute the CSV_Parser\n",
        "# A list of CSV could be iterated over\n",
        "# The path of the CSV to be parsed, # do I need this functionality: 1 to print, 0 to not print.\n",
        "data1_path, data2_path, print_cont = \"/content/stamina.csv\", \"/content/food.csv\", 0\n",
        "# Create the CSV_Parser class object and open the files\n",
        "Data1_Parser, Data2_Parser = CSV_Parser(data1_path, print_cont), CSV_Parser(data2_path, print_cont)\n",
        "data1_read, data2_read = Data1_Parser.file_opener(), Data2_Parser.file_opener()\n",
        "# Index the comma position from the CSV and split the characters into their values\n",
        "data1_comma_place, data2_comma_place = Data1_Parser.comma_index(data1_read), Data2_Parser.comma_index(data2_read)\n",
        "data1_comma_list, data2_comma_list = Data1_Parser.csv_value_list(data1_comma_place, data1_read), Data2_Parser.csv_value_list(data2_comma_place, data2_read)\n",
        "# Get the width of columns of the csv\n",
        "data1_col_num, data2_col_num = Data1_Parser.comma_width(data1_read, 1), Data2_Parser.comma_width(data2_read, 1)\n",
        "# Flip the scale values from high to low for every column\n",
        "# Makes the pain scale more readable with high values meaning high pain and vice versa\n",
        "data1_flipped = Data1_Parser.csv_flipper(data1_comma_list, data1_col_num)\n",
        "# Extract the stamina column that was not flipped\n",
        "data1_stm_ext = Data1_Parser.stm_extract(data1_comma_list, data1_col_num)\n",
        "# Remove the flipped stamina column from the flipped list\n",
        "data1_stm_rm = Data1_Parser.stm_remove(data1_flipped, data1_col_num)\n",
        "# Append the extracted not flipped stamina to the flipped list\n",
        "data1_stm_ext_flip = Data1_Parser.stm_append(data1_stm_rm, data1_stm_ext, data1_col_num)\n",
        "\n",
        "# Part B\n",
        "# Get descriptive statistics for the stanima.csv columns (starts at 3rd column [4th from 1])\n",
        "data1_mean_list = []\n",
        "data1_stn_list = []\n",
        "for i in range(3,data1_col_num):\n",
        "  data1_mean = Data1_Parser.mu(data1_stm_ext_flip, data1_col_num, i)\n",
        "  data1_mean_list.append(data1_mean)\n",
        "  data1_stn_dev = Data1_Parser.stn(data1_stm_ext_flip, data1_col_num, i, data1_mean)\n",
        "  data1_stn_list.append(data1_stn_dev)\n",
        "  data1_kurt = Data1_Parser.kur(data1_stm_ext_flip, data1_col_num, i, data1_mean, data1_stn_dev)\n",
        "  data1_skew = Data1_Parser.skew(data1_stm_ext_flip, data1_col_num, i, data1_mean, data1_stn_dev)\n",
        "data2_mean_list = []\n",
        "data2_stn_list = []\n",
        "# Get descriptive statistics for the food.csv columns (starts at 2nd column [3rd from 1)])\n",
        "for j in range(2,data2_col_num):\n",
        "  data2_mean = Data1_Parser.mu(data2_comma_list, data2_col_num, j)\n",
        "  data2_stn_dev = Data1_Parser.stn(data2_comma_list, data2_col_num, j, data2_mean)\n",
        "  data2_mean_list.append(data2_mean)\n",
        "  data2_stn_list.append(data2_stn_dev)\n",
        "  data2_kurt = Data1_Parser.kur(data2_comma_list, data2_col_num, j, data2_mean, data2_stn_dev)\n",
        "  data2_skew = Data1_Parser.skew(data2_comma_list, data2_col_num, j, data2_mean, data2_stn_dev)\n",
        "# Get covariance and correlation\n",
        "covar_list = []\n",
        "for k in range(3,data1_col_num):\n",
        "  for m in range(2,data2_col_num):\n",
        "    covar = Data1_Parser.covar(data1_stm_ext_flip, data1_col_num, data1_mean_list, k, data2_comma_list, data2_col_num, data2_mean_list, m)\n",
        "    covar_list.append(covar)\n",
        "cor = Data1_Parser.cor(covar_list, data1_stn_list, data2_stn_list)\n",
        "print(cor)"
      ],
      "metadata": {
        "id": "IxtfVwAjhyaV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b23e220-5156-467f-b2cc-d596bbc0ec01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.10.12 (main, Mar 22 2024, 16:50:05) [GCC 11.4.0]\n",
            "[-0.1645530987447795, 0.004133345123079237, -0.2766131317293669, -0.3511706150133094, -0.354318230488469, -0.26699736959238396, -0.40125530200198745, -0.011601120632660784, 0.21731632890005487, -0.08232066489023135, -0.08469394554034333, -0.17855051462249677, -0.19142393847432482, -0.03793103448275861, 0.07789577621983806, 0.08196843693524519, 0.2898010400398384, 0.3861829047610585, 0.3965963930186023, 0.17649431150497585, 0.020636782820661486, -0.014459908858027965, 0.13758383209802194, -0.05211754033294028, -0.15750896664388822, -0.222549549284631, -0.23859528671659347, -0.18051650034429456, 0.07273187299495681, -0.2333333946964959, 0.1726965944278272, 0.35115371691802905, 0.3288570499439299, 0.10750937754475651, 0.007177012954709531, 0.07850918996125873, 0.10891110461956938, 0.21453196764494614, 0.41210770628325405, 0.5157479161455643, 0.3366438383087422, 0.254698105692875, -0.1144903277070821, 0.10348396614288326, 0.14308115564254484, 0.1159500444897556, 0.3103377992248155, 0.05013484102898976, 0.33189655172413784, 0.09173109048494528, 0.020950374542039407, 0.30368891112129787, 0.37994082416385955, 0.5519685778331616, 0.28665554096248885, 0.5342830018944315, -0.035277583644029324, 0.1061757595944848, -0.1913496176465991, -0.11912284236168576, -0.08723567442899587, -0.2253110300028915, -0.10399491587926614, 0.12459321156073949, -0.2433194490706942, 0.1630128112116728, 0.021943681487678984, 0.04626134250022504, 0.049596767610699345, 0.2452457423441453, 0.07922064005882123, -0.212814132689687, 0.009213166547046358, 0.009478779439283335, 0.09741723051615435, -0.061593395865371346, 0.3302546661277913, 0.13597308533767188, -0.06357403572096994, 0.040672172391523556, -0.09470125188558334, 0.016250399787552824, -0.09831012461643979, 0.013181178341066541, 0.15233745716579142, 0.07951159698442305, 0.1828303240432934, 0.15439526102948684, 0.14784753130946982, 0.04423459027002003, 0.033467020826746546, -0.07261372287584743, 0.00495154685727903, -0.09878550742311708, -0.10163346465950968, -0.08814582389530871, -0.13957086144541894, -0.003299892755228172, 0.05080522970040031, -0.008401285158874405, 0.03606782034617602, -0.09822611922206381, -0.06442452851042303, -0.06906951238920016, -0.08118441408859885, 0.16383045966611198, 0.056916181378585735, 0.2822422796236502, 0.2903792418526056, 0.21681133918446008, 0.23244335386167983, 0.38965517241379305, 0.23798110161193464, -0.13758383209802197, 0.05211754033294029, -0.1541577120344438, -0.10597597584982438, -0.1136168031983779, -0.05635171174768984, 0.07534389424088181, -0.15449738777599303, -0.05630204264162889, -0.057925214035365075, -0.022495250388272724, -0.0775194086001416, 0.1433658345897068]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Oawx7BKWhEkd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# time_0 = ((datetime.now()).strftime('%H:%M:%S.%f'))\n",
        "# Code to be timed\n",
        "# time_1 = ((datetime.now()).strftime('%H:%M:%S.%f'))\n",
        "# time_strp_0 = time_0.split(\":\")\n",
        "# time_strp_1 = time_1.split(\":\")\n",
        "# timed = float(time_strp_1[2])-float(time_strp_0[2])\n",
        "# return timed\n",
        "\n",
        "# Results\n",
        "# Method0 = 0.00010481281281270126\n",
        "# Method1 = 0.00005615615615591504\n",
        "\n",
        "# The first ~7 calculations of Method1 were similar to Method0,\n",
        "# then performance increased several times maybe it is log(n) complexity\n",
        "\n",
        "# Why would the decreased space used decrease the time?\n",
        "# Between the C compiler and Python Virtual Machines as Python\n",
        "# code is translated into machine readable binary, there are probably\n",
        "# methods to reduce hardware demands on redundant calculations.\n",
        "\n",
        "'''\n",
        "# Timed methods\n",
        "B = []\n",
        "for i in range(1000):\n",
        "  A = Data1_Parser.stm_remove(data1_flipped, data1_col_len)\n",
        "  B.append(A)\n",
        "  print(A)\n",
        "C = sum(B)\n",
        "print(C/999)\n",
        "# Met = 0.00010481281281270126\n",
        "# Met1 = 0.00005615615615591504\n",
        "'''"
      ],
      "metadata": {
        "id": "aCEVnSXbhEmr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "im6LHi3oyGk2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "  # TODO CS 180 Question 0\n",
        "  # 'def csv_flipper'\n",
        "  # is bad code because it assumes the ID column is in the 0 position\n",
        "  # which might be different in other CSV reducing reusability\n",
        "  # Starting the counter variable j at number of the numerical\n",
        "  # column that you want to not be flipped would be easier.\n",
        "  # The 'def column_name' function could translate the desired numerical\n",
        "  # column text into a number:\n",
        "  def column_name(self, data_val_list):\n",
        "    excluded_column_int = []\n",
        "    return excluded_column_int\n",
        "  # Then 'def csv_flipper would accept <excluded_column_int> returned from the\n",
        "  # 'def column_name' function and exclude that column from the scale flipping.\n",
        "\n",
        "  # TODO CS 180 Question 1: Auxilliary space question\n",
        "  # Does the array already exist in memory represented as binary\n",
        "  # and the loop accesses the array at index 'i'?\n",
        "  # If you remove the stamina value at index 'i' using the 'pop' method,\n",
        "  # are you keeping the same array but with the removed value?\n",
        "  # Or are you making another array which would be the same as\n",
        "  # appending all the values to a new array as in the\n",
        "  # commented function stm_remove? Time each function with 'datetime'.\n",
        "\n",
        "  # Answer 1: This doesn't matter at our several hundred numbers or even\n",
        "  # at several thousand but it would increase hardware demands as the\n",
        "  # size of the list increased. You kids these days are so spoiled,\n",
        "  # back in my day we were lucky to have two kilobytes to rub together\n",
        "  # to make install compiled binary code!\n",
        "\n",
        "  # Step 1) Remove the unnecessary flipped stamina column from the flipped list\n",
        "  # (Two methods)\n",
        "\n",
        "  '''\n",
        "  # Method 0 :\n",
        "  def stm_remove(self, flip_list, col_num):\n",
        "    time_0 = ((datetime.now()).strftime('%H:%M:%S.%f'))\n",
        "    flip_list_rm = []\n",
        "    og_col_num = col_num\n",
        "    for i in range(len(flip_list)):\n",
        "      if i == 3:\n",
        "          col_num = i + col_num\n",
        "      elif i == col_num:\n",
        "        col_num += og_col_num\n",
        "      else:\n",
        "        flip_list_rm.append(flip_list[i])\n",
        "    time_1 = ((datetime.now()).strftime('%H:%M:%S.%f'))\n",
        "    time_strp_0 = time_0.split(\":\")\n",
        "    time_strp_1 = time_1.split(\":\")\n",
        "    timed = float(time_strp_1[2])-float(time_strp_0[2])\n",
        "    # return timed\n",
        "    return flip_list\n",
        "  '''\n",
        "\n",
        "  # TODO CS 180 Question 1: Auxilliary space continued\n",
        "  # Why does Method0\n",
        "\n",
        "  # Step 3) Append unflipped stamina values to flipped list as a new column\n",
        "\n",
        "  '''\n",
        "  # Method 0 :\n",
        "  def stm_append(self, stm_rm, stamina_col, col_num):\n",
        "    flip_append_list = []\n",
        "    og_col_num = col_num\n",
        "    col_len = 32\n",
        "    j = 0\n",
        "    k = 0\n",
        "    for i in range(len(stm_rm) + col_len):\n",
        "      if i == 3:\n",
        "        flip_append_list.append(stamina_col[j])\n",
        "        col_num = i + col_num\n",
        "        j += 1\n",
        "      elif i == col_num:\n",
        "        flip_append_list.append(stamina_col[j])\n",
        "        col_num += og_col_num\n",
        "        j += 1\n",
        "      else:\n",
        "        flip_append_list.append(stm_rm[k])\n",
        "        k += 1\n",
        "    return flip_append_list\n",
        "  '''\n",
        "\n",
        "  # TODO CS 180 Question 2\n",
        "  # 0) Write a function to get the length of the column. This will be used in the\n",
        "  # 'stm_append' function to append the unflipped stamina values from 'extract'\n",
        "  # to the output of the 'stm_remove' function containing flipped values and\n",
        "  # stamina column by extending the length of the items iterated over.\n",
        "  # Or you could use the length of the original csv list from csv_value_list\n",
        "  # as input into the stm_append.\n",
        "\n",
        "  # Step 2)\n",
        "  def column_len(self):\n",
        "    col_len = 32\n",
        "    return col_len\n",
        "\n",
        "  # TODO CS 180 Question 3: Auxilliary space continued\n",
        "\n",
        "  # Examples of bad Big O\n",
        "  # The column iterator performs statistical calculations on the\n",
        "  # values of each column\n",
        "  # Method 0 : Big O n^2 very slow bad nested for loop\n",
        "  '''\n",
        "  def column_iter(self, stm_ext_flip, col_num):\n",
        "\n",
        "    og_col_num = col_num\n",
        "    # The ouput of the 'column_len' function\n",
        "    col_len = 32\n",
        "    # The column length without the column name\n",
        "    col_val = col_len - 1\n",
        "    og_flip_list_len = len(stm_ext_flip)\n",
        "    j = 3\n",
        "    for k in range(j,col_num):\n",
        "      col_vert = []\n",
        "      total = 0\n",
        "      for i in range(len(stm_ext_flip)):\n",
        "        if i == og_flip_list_len:\n",
        "          break\n",
        "        if i == k:\n",
        "          if i < (og_col_num):\n",
        "            pass\n",
        "          else:\n",
        "            col_vert.append(int(stm_ext_flip[i]))\n",
        "            total += int(stm_ext_flip[i])\n",
        "          col_num = i + og_col_num\n",
        "        elif i == col_num:\n",
        "          col_vert.append(int(stm_ext_flip[i]))\n",
        "          total += int(stm_ext_flip[i])\n",
        "          col_num += og_col_num\n",
        "\n",
        "      print(col_vert)\n",
        "      mean = Data1_Parser.mu(total, col_val)\n",
        "      print(mean)\n",
        "      print('b')\n",
        "      print(sum(col_vert)/col_val)\n",
        "    return\n",
        "   '''\n",
        "\n",
        "  # Method 1 : Still bad because of Big O n*log(n)\n",
        "  # Did not finish\n",
        "  '''\n",
        "  def column_iter(self, stm_ext_flip, col_num):\n",
        "    col_strt = 3\n",
        "    val_col_strt = col_strt + col_num\n",
        "    iter_0 = val_col_strt\n",
        "    val_col = col_num - 3\n",
        "    iter_int = len(stm_ext_flip)*val_col\n",
        "    const_stm_len = len(stm_ext_flip)\n",
        "    for u in range(iter_int):\n",
        "      print(len(stm_ext_flip))\n",
        "      if u % len(stm_ext_flip) == 0:\n",
        "        iter_0 = (u + val_col_strt + 1) - const_stm_len\n",
        "        print(iter_0)\n",
        "      elif u == iter_0:\n",
        "        # print(stm_ext_flip[u])\n",
        "        iter_0 += col_num\n",
        "    return\n",
        "    '''\n",
        "  # Part B: Standard deviation\n",
        "  '''\n",
        "  # Homer solving the crossword and einstein says hes smart .jpg\n",
        "  Google Sheets supplies a different answer for the standard deviation.\n",
        "  For example : column  'stm' standard deviation is 0.9379 while our\n",
        "  implementation in the function 'stn' yields 0.9226032029725865. The issue\n",
        "  isn't rounding, Google Sheets uses the sample method which divides the\n",
        "  numerator summation by the denominator of number of data points - 1 (n-1)\n",
        "  instead of the number of data points (n).\n",
        "\n",
        "  Also from Google Sheets Docs:\n",
        "  \"Although STDEV is specified as taking a maximum of 30 arguments,\n",
        "  Google Sheets supports an arbitrary number of arguments for this function.\"\n",
        "  https://support.google.com/docs/answer/3094054?hl=en\n",
        "  Probably has something to do with asymptotic sample size.\n",
        "\n",
        "  '''\n",
        "  # Part B: Kurtosis\n",
        "  '''\n",
        "  UCLA defines three kurtosis equations\n",
        "  https://stats.oarc.ucla.edu/other/mult-pkg/faq/general/faq-whats-with-the-different-formulas-for-kurtosis/\n",
        "\n",
        "  \"We will begin by defining two different sums of powered deviation scores:\"\n",
        "\n",
        "  a) s2 is the sum of squared deviation scores\n",
        "    s2 = sigcap(xi - mu) ^ 2\n",
        "\n",
        "  b) s4 is the sum of deviation scores raised to the fourth power.\n",
        "     s4 = sigcap(xi - mu) ^ 4\n",
        "\n",
        "  c)  i)   m2 = s2/n\n",
        "     ii)   m4 = s4/n\n",
        "    iii) V(x) = s2/n-1\n",
        "\n",
        "  0) SAS in proc means AKA excess kurtosis\n",
        "  kurtosis - 3\n",
        "  Snedecor, G.W. and Cochran, W.G. (1967) Statistical Methods, Sixth Edition. Ames, Iowa: Iowa State University Press.\n",
        "\n",
        "  kurt = (m4/m2^2) - 3\n",
        "\n",
        "  1) Used in STATA program\n",
        "  Bock, R.D. (1975) Multivariate Statistical Methods in Behavioral Research. New York: McGraw-Hill.\n",
        "  kurt = m4 / m2\n",
        "       = ((sigcap(xi - mu) ^ 4) / n) / ((sigcap(xi - mu) ^ 2) / n)\n",
        "\n",
        "  Note that in computing the kurtosis, the standard deviation is computed\n",
        "  using N in the numerator rather than N - 1.\n",
        "  https://www.itl.nist.gov/div898/handbook/eda/section3/eda35b.htm\n",
        "\n",
        "  Example\n",
        "    xi = 2, 7, 15, 4, 8\n",
        "     n = 5\n",
        "  kurt = Σ((xi - mu)^4 / n) / (SD^4)\n",
        "    mu =  sum(xi)     / n\n",
        "       = (2+7+15+4+8) / 5\n",
        "       =  7.2\n",
        "  numerator = (xi - mu)^4 / n\n",
        "            = sum((2  - 7.2)^4 + (7 - 7.2)^4 + (15 - 7.2)^4 + (4 - 7.2)^4 + (8 - 7.2)^4)) / 5\n",
        "            = 4537.936 / 5\n",
        "    SD = standard deviation\n",
        "    SD = 4.970\n",
        "  kurt = (4537.936 / N) / SD\n",
        "       = (4537.936 / 5) / (4.970)^4\n",
        "       = 907.5872 / (4.970)^4\n",
        "       = 907.5872 / 610.1344\n",
        "  kurt = 1.4875\n",
        "  '''\n",
        "  # Part B: Skewness\n",
        "  '''\n",
        "  2) UCLA page also includes a more complicated sampling kurtosis formula.\n",
        "  It's listed under wikipedia as a sampling method for standard and\n",
        "  unbiased estimations in larger numbers but is noted as being biased in\n",
        "  nonnormal samples (data that is not bell shaped). This example uses\n",
        "  n-1 in the denominator and is beyond the scope of this statistics class.\n",
        "\n",
        "  Sheskin, D.J. (2000) Handbook of Parametric and Nonparametric Statistical\n",
        "  Procedures, Second Edition. Boca Raton, Florida: Chapman & Hall/CRC.\n",
        "\n",
        "\n",
        "  The skewness is attmpeting to summarize the symmetry of the distribution\n",
        "  but it can be misleading from a lack of describing the tail. This is why\n",
        "  kurtosis is used.\n",
        "\n",
        "  https://lbj.utexas.edu/sites/default/files/file/news/Skew.pdf\n",
        "  The equation is defined in International Encyclopedia of Statistical Science\n",
        "  as E((xi - mu)/SD)^3)\n",
        "\n",
        "  A biased method or sampling method is:\n",
        "  1/n SIG((xi - mu)/SD)^3\n",
        "\n",
        "  or\n",
        "\n",
        "  SIG((xi - mu) / n ) / SD ^ 3\n",
        "\n",
        "  Which is the equation found in the NIST webpage:\n",
        "  https://www.itl.nist.gov/div898/handbook/eda/section3/eda35b.htm\n",
        "\n",
        "  Or a less biased method replacing 1/n with n / (n-1)(n-2)\n",
        "\n",
        "  '''\n",
        "# First Interpretation Notes\n",
        "# Bin the calorie column into a scale 1-5, the covariance is too high\n",
        "# Stamina and alcohol seem to move in opposite directions\n",
        "# Glute pain and alcohol seem to move in the same direction\n",
        "# Groin and protein move in same direction as does groin/alcohol\n",
        "# Muscular pain is usually delayed 24-48 hours, try moving the pain csv back\n",
        "# both one and two days and dropping the first/second day second to last/last.\n",
        "# This would leave the data less than 30 which is the minimum number for\n",
        "# using central limit theorem statistics.\n",
        "'''\n",
        "# This is the covar original version\n",
        "# Get descriptive statistics of each column\n",
        "for j in range(3,data1_col_num):\n",
        "  # Refractor these\n",
        "  data1_mean = Data1_Parser.mu(data1_stm_ext_flip, data1_col_num, j)\n",
        "  stn_dev1 = Data1_Parser.stn(data1_stm_ext_flip, data1_col_num, j, data1_mean)\n",
        "  kurt = Data1_Parser.kur(data1_stm_ext_flip, data1_col_num, j, data1_mean, stn_dev1)\n",
        "  skew = Data1_Parser.skew(data1_stm_ext_flip, data1_col_num, j, data1_mean, stn_dev1)\n",
        "  print(data1_stm_ext_flip[j])\n",
        "  print(\"covar with\")\n",
        "  for k in range(2,data2_col_num):\n",
        "    #print(data2_comma_list[k])\n",
        "    covar = Data1_Parser.covar1(data1_stm_ext_flip, data1_col_num, data1_mean, j, data2_comma_list, data2_col_num, data2_mean_list, k)\n",
        "    print(covar)\n",
        "    # cor = Data1_Parser.cor(covar, stn_dev1, stn_dev2)\n",
        "'''"
      ],
      "metadata": {
        "id": "mere2W9s4IR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d_D67vndcVxg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZZKS_mjGpn12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OPW0NTsypoBk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I2X-bJC2poEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0a8FjPGe9aQF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}