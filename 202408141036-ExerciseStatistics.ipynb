{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1_30w1VSMkOqwDN8CyagWvEUqrYjWGScl","timestamp":1723649749440},{"file_id":"1fHIWbrpk4NMYcse3Xdkb-S8XiS2pxzJm","timestamp":1721260308720},{"file_id":"1STKhtVVaknUZiohwWLdfyoZ3zg6Veimx","timestamp":1721260179755}],"authorship_tag":"ABX9TyPZ6eeYdBuQsC89O1w5usC5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# List of primary issues\n","# todo    description                     ~EST/act hours  progress    hours_in_progress\n","# todo0   no lib python function csv parser.           6  COMPLETE\n","# todo1   make defs from repeated code.                1  COMPLETE\n","# todo2   def into class.                              1  COMPLETE\n","# todo3   flip column                                  2  COMPLETE\n","# todo4   improve efficiency auxilliary space          7  COMPLETE\n","# todo5   mean, standard deviation                     6  COMPLETE\n","# todo6   kurt, skew, covar, cor                       10 COMPLETE\n","# todo7   rearrange csv list vertically by column      2  COMPLETE\n","# todo8   Unflipped stm to the flipped pain scale      1  COMPLETE\n","# todo8   more readable code and refractor            ~4  PROCESSING 6\n","# todo8   make a graph function                       ~10 COMPLETE 13.25\n","# todo9   r squared, ANOVA                            ~7  PROCESSING 2\n","# todo10  interpret results                           ~20 PROCESSING 3.5\n","#                                             TOTAL  ~   PROCESSING\n","# Total estimate  : 47\n","# Total actual    :\n","# Total remaining : 35 (estimated)\n","\n","# List of secondary issues\n","# todo   description                              progress\n","# todo1  Functionality? 1 to print, 0 to not      COMPLETE\n","# todo2  Avoid repeated code in the comma list    COMPLETE\n","# todo3  Function get length of columns           COMPLETE\n","# todo4  Function get column by the string name   COMPLETE\n","# todo5  Find a way to traverse CSV_Parser once   PROCESSING\n","# todo6  Reusable binned Graph function           PROCESSING\n","# todo7  Reusable flipper CSV_Parser function     PROCESSING\n","\n","import sys\n","#from datetime import datetime\n","print(sys.version)\n","# 3.10.12 (main, Mar 22 2024, 16:50:05) [GCC 11.4.0]\n","\n","##############################################################################\n","# Part A: CSV parser class to open the file and parse the values into a list #\n","##############################################################################\n","class CSV_Parser:\n","  # Initialize the input variables\n","  def __init__(self, data_path):\n","    self.data_path = data_path\n","  def file_opener(self):\n","    with open(self.data_path, \"r\") as data_open:\n","      data_read = data_open.read()\n","      return data_read\n","  # Index the commas and line breaks\n","  def comma_index(self, open_file, column_len):\n","    data_comma_place = [0]\n","    column_pl_len = 0\n","    for i in range(len(open_file)):\n","      data1_col1 = open_file[i]\n","      if data1_col1 == \",\":\n","        data_comma_place.append(i)\n","        data_comma_place.append(i+1)\n","      if data1_col1 == \"\\n\":\n","        data_comma_place.append(i)\n","        data_comma_place.append(i+1)\n","        # If you want to use the function to get the column width, set to 1\n","        if column_len == 1:\n","          col_width = len(data_comma_place)\n","          return col_width\n","          break\n","    las_val = data_comma_place[-1] + 2\n","    data_comma_place.append(las_val)\n","    return data_comma_place\n","  # Splitting the csv characters into list of words based on indexed comma position\n","  def csv_value_list(self, data_comma_out, open_file, col_width, col_head):\n","    j = col_head\n","    data_val_list = []\n","    for i in range(len(data_comma_out)):\n","      if j >= len(data_comma_out):\n","        break\n","      comma_strt = data_comma_out[j]\n","      j += 1\n","      comma_end = data_comma_out[j]\n","      #print(comma_strt, \"and \", comma_end)\n","      j += 1\n","      data_val_list.append(open_file[comma_strt:comma_end])\n","      j = j + (col_width * 2)\n","    return data_val_list\n","  # Flipping the columns from high to low for readability\n","  # If the original value was 5, set it to equal 0 (no pain)\n","  # If the original value was 0, set it to equal to 5 (high pain) etc.\n","  # If none of those things are true, append the string (for the column header)\n","  def csv_flipper(self, csv_list, col_width):\n","    csv_flipped = []\n","    for i in csv_list:\n","      if i == str(5):\n","        n = str(1)\n","        csv_flipped.append(n)\n","      elif i == str(4):\n","        n = str(2)\n","        csv_flipped.append(n)\n","      elif i == str(3):\n","        n = str(3)\n","        csv_flipped.append(n)\n","      elif i == str(2):\n","        n = str(4)\n","        csv_flipped.append(n)\n","      elif i == str(1):\n","        n = str(5)\n","        csv_flipped.append(n)\n","      else:\n","        csv_flipped.append(i)\n","    return csv_flipped\n","\n","\n","######################################################\n","# Part C: Data visualization with a timeseries graph #\n","######################################################\n","# 'Graph' class accepts three variables: verticle arranged 'data',\n","# the date column'date_col_num', and the data column 'data_col_num'\n","class Graph:\n","  # Initialize the input variables\n","  def __init__(self, data, date_col_num, data_col_num):\n","    self.data = data\n","    self.date_col_num = date_col_num\n","    self.data_col_num = data_col_num\n","  def hi_lo(self, data_col_num):\n","    # The date and date column to be used\n","    data_col = self.data[data_col_num]\n","    data_col_len = len(data_col)\n","    # High and low of values\n","    hi_lo_count = 1\n","    hi = data_col[1]\n","    lo = data_col[1]\n","    for e in range(len(data_col[1:])):\n","      hi_lo_count += 1\n","      if hi_lo_count == (len(data_col[1:]) + 1):\n","        break\n","      if hi < data_col[hi_lo_count]:\n","        hi = data_col[hi_lo_count]\n","      if lo > data_col[hi_lo_count]:\n","        lo = data_col[hi_lo_count]\n","    return [hi, lo]\n","  def binned(self, hi_lo):\n","    # high value (5 in this case or hi_lo[0])\n","    # The date and date column to be used\n","    # TODO it works but is not resuable for other data ranges\n","    date_col = self.data[self.date_col_num]\n","    data_col = self.data[self.data_col_num]\n","    data_col_len = len(data_col)\n","    fiver = []\n","    fourer = []\n","    threer = []\n","    twoer = []\n","    oner = []\n","    lol_stm_date = []\n","    counter = 1\n","    # Binned with date value\n","    for i in range(data_col_len):\n","      P0_column = self.data[self.data_col_num]\n","      if counter == len(self.data[0]):\n","        break\n","      if float(P0_column[counter]) == 5:\n","        fiver.append([date_col[counter], P0_column[counter]])\n","      elif float(P0_column[counter]) == 4:\n","        fourer.append([date_col[counter], P0_column[counter]])\n","      elif float(P0_column[counter]) == 3:\n","        threer.append([date_col[counter], P0_column[counter]])\n","      elif float(P0_column[counter]) == 2:\n","        twoer.append([date_col[counter], P0_column[counter]])\n","      elif float(P0_column[counter]) == 1:\n","        oner.append([date_col[counter], P0_column[counter]])\n","      counter += 1\n","    # Combining the binned data into one dictionary\n","    lol_date_stm = [fiver, fourer, threer, twoer, oner]\n","\n","    return lol_date_stm\n","\n","  def time_series(self, date_hi_lo, lol_date_stm):\n","    date_col = self.data[self.date_col_num]\n","    # Base of the month, plus 00 i.e. 500\n","    date_base = int(date_hi_lo[1]) - 1\n","    # The number of spaces is the 'day' (date - month) - 'prev_day_space_int'\n","    # The difference between the values is multiplied by ' ' for each 5,4,3,2,1\n","    # Value with a '+' character marking the position\n","    spacer = []\n","    prev_day_space_int = 0\n","    for i in lol_date_stm:\n","      spacer_mid = []\n","      # print(i)\n","      for ii in i:\n","        day = int(ii[0]) - date_base\n","        day_count = day - prev_day_space_int\n","        day_space_str = ((day_count-1)*2) * \" \"\n","        spacer_mid.append(day_space_str)\n","        prev_day_space_int = day\n","      # print(\"\\n\")\n","      prev_day_space_int = 0\n","      spacer.append(spacer_mid)\n","    y_val = [y for y in range(len(spacer),0,-1)]\n","    return [spacer, y_val]\n","  def time_series_print(self,spacer,y_val):\n","    date_col = self.data[self.date_col_num]\n","    for j,k in zip(spacer,y_val):\n","      # depen values\n","      print(k,end=\" \")\n","      for l in j:\n","        print(l,end=\"\")\n","        print(\"+\",end=\" \")\n","      print()\n","    # indpen\n","    for m in range(len(date_col[0])-1):\n","      print(\"  \",end=\"\")\n","      for n in date_col[1:]:\n","        print(n[m], end=\" \")\n","      print()\n","    return\n","\n","######################################################\n","# Part B: Get descriptive statistics of each column. #\n","######################################################\n","class Statistics:\n","  # Initialize the input variables\n","  def __init__(self, P0_flipped, P0_col_width, B0_list, B0_col_width):\n","    self.P0_flipped = P0_flipped\n","    self.P0_col_width = P0_col_width\n","    self.B0_list = B0_list\n","    self.B0_col_width = B0_col_width\n","  # Returns a dictionary with the header and mean\n","  def mu(self, column_list):\n","    total = 0\n","    for i in column_list[1:]:\n","      total = total + float(i)\n","    mean = total / (len(column_list) - 1)\n","    header_mean = [column_list[0], mean]\n","    return header_mean\n","  # Returns the 2-4 moment of the distribution\n","  def mnt(self, header, mean, column_list):\n","    col_1 = len(column_list) - 1\n","    stn = 0\n","    skew = 0\n","    kurt = 0\n","    for i in column_list[1:]:\n","      n1 = int(i) - mean\n","      n1_sqr = n1 ** 2\n","      n1_cube = n1 ** 3\n","      n1_quad = n1 ** 4\n","      stn = stn + n1_sqr\n","      skew = skew + n1_cube\n","      kurt = kurt + n1_quad\n","    stn_small_sqr = float(stn) / float(col_1)\n","    stn_small = stn_small_sqr ** .5\n","    skew_small_sqr = float(skew) / float(col_1)\n","    skew_small = skew_small_sqr / (stn_small ** 3)\n","    kurt_small_sqr = float(kurt) / float(col_1)\n","    kurt_small = kurt_small_sqr / (stn_small ** 4)\n","    return [header, stn_small, skew_small, kurt_small]\n","  # Covariance and correlation\n","  def covar(self, header, mean, column_list, P0_flipped):\n","    col_1 = len(column_list) - 1\n","    covar = 0\n","    for i in P0_flipped:\n","      for j in column_list[1:]:\n","        x1 = j - mean\n","        # y1 = i[1:] - yi_mu\n","    return\n","  def cor(self, covar, header, mean, column_list):\n","    return\n","\n","# Part A: The path of the CSV to be parsed\n","# P0.csv contains the pain scale and B0.csv contains the food records\n","P0_path, B0_path = \"/content/P0.csv\", \"/content/B0.csv\"\n","# Create the CSV_Parser class object and open the files\n","P0_Parser, B0_Parser = CSV_Parser(P0_path), CSV_Parser(B0_path)\n","P0_read, B0_read = P0_Parser.file_opener(), B0_Parser.file_opener()\n","# Index the comma position from the CSV and split the characters into their values\n","P0_comma_indexed, B0_comma_indexed = P0_Parser.comma_index(P0_read, 0), B0_Parser.comma_index(B0_read, 0)\n","# Get the width of columns of the commas\n","P0_comma_width, B0_comma_width = P0_Parser.comma_index(P0_read, 1), B0_Parser.comma_index(B0_read, 1)\n","# Sort the list into verticle columns\n","# The P0 csv gets flipped, except for the Stm column\n","# Divide by two - the list of comma places is doubled for the start/end value\n","P0_col_width = int(((P0_comma_width - 1 ) / 2) - 1)\n","# Divide by two - the list of comma places is doubled for the start/end value\n","B0_col_width = int(((B0_comma_width - 1 ) / 2) - 1)\n","P0_vert = []\n","B0_vert = []\n","# List of columns to not be flipepd\n","unflipped_col = ['ID','Date','Day','Stm']\n","for i in range(0,P0_comma_width-1,2):\n","  P0_list = P0_Parser.csv_value_list(P0_comma_indexed, P0_read, P0_col_width, i)\n","  if P0_list[0] in unflipped_col:\n","    P0_vert.append(P0_list)\n","  else:\n","    P0_flip = P0_Parser.csv_flipper(P0_list, P0_col_width)\n","    P0_vert.append(P0_flip)\n","for j in range(0,B0_comma_width-1,2):\n","  B0_list = B0_Parser.csv_value_list(B0_comma_indexed, B0_read, B0_col_width, j)\n","  B0_vert.append(B0_list)\n","\n","'''\n","# Part C: Make a graph\n","graph_count = 3\n","for m in stats_class.P0_flipped[3:]:\n","  # date_col_num = 1 # data_col_num = each successive column\n","  # this would be a loop over columns 3-20, 1st column is the date\n","  print(m[0])\n","  print()\n","  P0_graph = Graph(P0_vert, 1, graph_count)\n","  P0_hi_lo = P0_graph.hi_lo(graph_count)\n","  date_hi_lo = P0_graph.hi_lo(1)\n","  P0_binned = P0_graph.binned(P0_hi_lo)\n","  P0_time_series = P0_graph.time_series(date_hi_lo,P0_binned)\n","  P0_graph.time_series_print(P0_time_series[0],P0_time_series[1])\n","  print()\n","  graph_count += 1\n","'''\n","# Part B: Get descriptive statistics\n","stats_class = Statistics(P0_vert, P0_col_width, B0_vert, B0_col_width)\n","# The first three columns are skipped because they are ID, Date, and Day\n","for l in stats_class.P0_flipped[3:]:\n","  print(l)\n","  P0_means = stats_class.mu(l)\n","  P0_mnt2_4 = stats_class.mnt(P0_means[0],P0_means[1],l)\n","  '''\n","  P0_covar = stats_class.covar(P0_means[0],P0_means[1],l,stats_class.P0_flipped[3:])\n","  P0_cor = stats_class.cor(P0_covar,P0_means[0],P0_means[1],l)\n","  '''\n","\n","print('\\n')"],"metadata":{"id":"IxtfVwAjhyaV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1723649021523,"user_tz":300,"elapsed":178,"user":{"displayName":"David Leifer","userId":"06279506333224389759"}},"outputId":"0b7a2141-fceb-4d52-ddff-92a5abdb2984"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["3.10.12 (main, Jul 29 2024, 16:56:48) [GCC 11.4.0]\n","['Stm', '4', '2', '3', '4', '4', '5', '5', '5', '2', '4', '5', '5', '4', '5', '4', '5', '5', '5', '5', '5', '4', '4', '5', '4', '4', '5', '5', '2', '4', '5', '5']\n","\n","\n"]}]},{"cell_type":"code","source":["\"'''\n","Variable [ Standard deviation     skewness          kurtosis          ]\n","Stm  [  0.9226032029725865   -1.3448813710585974   3.982834272870202  ]\n","Feet  [  0.24567010018915827   3.54527368721251   13.568965517241404  ]\n","Ankl  [  0.6978486339607722   2.2348017520997243   7.846263423186496  ]\n","Caf  [  0.29565004483586066   2.727723627949905   8.44047619047619  ]\n","Kne  [  0.7082096258096823   1.9209855351889427   6.687600075756277  ]\n","Qua  [  0.6419273787784644   2.51183314586374   10.089837771655978  ]\n","But  [  0.9826804007566332   1.3498527688380964   3.7668512187871577  ]\n","Gro  [  0.9101119986881216   2.0692028641166686   6.015214262266103  ]\n","Abs  [  0.7901579815429607   2.335996718034223   7.827266666666666  ]\n","Bac  [  0.6321263852343689   2.739728761784831   11.233561197916652  ]\n","Lat  [  0.4181123031230877   1.3115784746777812   2.7202380952380953  ]\n","Tra  [  0.8997629471600871   1.5544354645781584   4.693918887662654  ]\n","Sho  [  0.9112546381822926   1.870590249227389   5.429824561403509  ]\n","Chs  [  0.7701507346008598   2.840711295919357   9.97305632502307  ]\n","Tric  [  0.9078224051271154   2.1804618718187427   6.3761478420569375  ]\n","Bic  [  0.24567010018915833   3.545273687212509   13.568965517241384  ]\n","Nec  [  0.8869501345075819   1.4331373346847902   4.505920886873269  ]\n","Hea  [  0.649981989664835   2.3110567133071975   9.161457448615595  ]\n","'''"],"metadata":{"id":"bxDrd479VzCM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","'''\n","  def aaaa(self, P0_flipped):\n","    space_holder = 0\n","    for j, k in zip(P0_flipped[1],P0_flipped[3]):\n","      char_len = len(j)\n","      space_holder = space_holder + char_len\n","      hed_spc = \" \" * space_holder\n","      print(hed_spc)\n","\n","    for j in P0_flipped[1]:\n","      hed_spc = \" \" * len(j)\n","      # Prints the xy label\n","      if j == P0_flipped[1][0]:\n","        print(\"  \", end=\" \")\n","      # This part makes the newline\n","      elif j == P0_flipped[1][col_len-1]:\n","        print(\"\")\n","      # Prints the number of spaces held by date label (x variable)\n","      else:\n","        print(hed_spc, end =\" \")\n","    # This is where the high low value would help\n","    for i in range(4,-1,-1):\n","      print(i+1)\n","      if i == (float(P0_flipped[0][1])):\n","        # Date column loop\n","        for j in P0_flipped[1]:\n","          if j == P0_flipped[1][0]:\n","            print(\"yx\", end=\" \")\n","          else:\n","            print(j, end =\" \")\n","    return\n","'''\n"],"metadata":{"id":"S8hWyHO4ssoQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["######################\n","# Statistics Outline #\n","######################\n","\n","# Statistics vocabulary review:\n","# The pain and nutrition scale data is ordinal -> it is categorical with clear\n","# differences in rankings. As opposed to Nominal that has no order between values\n","# (ie is blonde, brunette, etc). Or interval/numerical equally spaced numbers\n","# such as income values (ie $500, $600, $700)\n","# https://stats.oarc.ucla.edu/other/mult-pkg/whatstat/what-is-the-difference-between-categorical-ordinal-and-interval-variables/\n","# You can use ordinal data in ANOVA as the indepdent variable if the dependent variable\n","# is interval data like time:\n","# https://libguides.library.kent.edu/SPSS/OneWayANOVA\n","# It seems there are several errors by treating the ordinal data as if it were\n","# parametric. These aren't real measurements in a statistical sense since the\n","# scale is made up, thus it is more difficult to make assumptions.\n","\n","# Homer solving the crossword and einstein says hes smart .gif\n","\n","# 0) Graph\n","\n","# 1) Harmonic, geometric mean, median, mode, quartiles?\n","# https://www.cuemath.com/data/statistics/\n","\n","# 1) Mean -> Mu -> Sum of all numbers / number of values\n","\n","# 2) Standard deviation\n","# Mu -> Standard deviation (stn) = (xi - xmu). ||| (yi - ymu).\n","\n","# Google Sheets supplies a different answer for the standard deviation.\n","# For example : column  'stm' standard deviation is 0.9379 while our\n","# implementation in the function 'stn' yields 0.9226032029725865. The issue\n","# isn't rounding, Google Sheets uses the sample method which divides the\n","# numerator summation by the denominator of number of data points - 1 (n-1)\n","# instead of the number of data points (n).\n","# Also from Google Sheets Docs:\n","# \"Although STDEV is specified as taking a maximum of 30 arguments,\n","# Google Sheets supports an arbitrary number of arguments for this function.\"\n","# https://support.google.com/docs/answer/3094054?hl=en\n","# Probably has something to do with asymptotic sample size.\n","\n","# 3) Skewness\n","#  (generalized)\n","#  stn, mean -> Skew and kurtosis [(xi - xmu) / stn]\n","\n","# The skewness is attmpeting to summarize the symmetry of the distribution\n","# but it can be misleading from a lack of describing the tail. This is why\n","# kurtosis is used.\n","\n","# https://lbj.utexas.edu/sites/default/files/file/news/Skew.pdf\n","# The equation is defined in International Encyclopedia of Statistical Science\n","# as E((xi - mu)/SD)^3)\n","# A biased method or sampling method is:\n","# 1/n SIG((xi - mu)/SD)^3\n","# or\n","# SIG((xi - mu) / n ) / SD ^ 3\n","# Which is the equation found in the NIST webpage:\n","#https://www.itl.nist.gov/div898/handbook/eda/section3/eda35b.htm\n","#Or a less biased method replacing 1/n with n / (n-1)(n-2)\n","\n","# 4) Kurtosis\n","# UCLA defines three kurtosis equations\n","# https://stats.oarc.ucla.edu/other/mult-pkg/faq/general/faq-whats-with-the-different-formulas-for-kurtosis/\n","\n","# \"We will begin by defining two different sums of powered deviation scores:\"\n","\n","# a) s2 is the sum of squared deviation scores\n","#    s2 = sigcap(xi - mu) ^ 2\n","# b) s4 is the sum of deviation scores raised to the fourth power.\n","#    s4 = sigcap(xi - mu) ^ 4\n","# c)  i)   m2 = s2/n\n","#    ii)   m4 = s4/n\n","#   iii) V(x) = s2/n-1\n","\n","# 0) SAS in proc means AKA excess kurtosis\n","# kurtosis - 3\n","# Snedecor, G.W. and Cochran, W.G. (1967) Statistical Methods, Sixth Edition. Ames, Iowa: Iowa State University Press.\n","\n","# kurt = (m4/m2^2) - 3\n","# 1) Used in STATA program\n","# Bock, R.D. (1975) Multivariate Statistical Methods in Behavioral Research. New York: McGraw-Hill.\n","# kurt = m4 / m2\n","#      = ((sigcap(xi - mu) ^ 4) / n) / ((sigcap(xi - mu) ^ 2) / n)\n","\n","# Note that in computing the kurtosis, the standard deviation is computed\n","# using N in the numerator rather than N - 1.\n","# https://www.itl.nist.gov/div898/handbook/eda/section3/eda35b.htm\n","\n","# Example\n","#   xi = 2, 7, 15, 4, 8\n","#    n = 5\n","# kurt = Σ((xi - mu)^4 / n) / (SD^4)\n","#   mu =  sum(xi)     / n\n","#      = (2+7+15+4+8) / 5\n","#      =  7.2\n","# numerator = (xi - mu)^4 / n\n","#           = sum((2  - 7.2)^4 + (7 - 7.2)^4 + (15 - 7.2)^4 + (4 - 7.2)^4 + (8 - 7.2)^4)) / 5\n","#           = 4537.936 / 5\n","#   SD = standard deviation\n","#   SD = 4.970\n","# kurt = (4537.936 / N) / SD\n","#      = (4537.936 / 5) / (4.970)^4\n","#      = 907.5872 / (4.970)^4\n","#      = 907.5872 / 610.1344\n","# kurt = 1.4875\n","\n","# UCLA page also includes a more complicated sampling kurtosis formula.\n","# It's listed under wikipedia as a sampling method for standard and\n","# unbiased estimations in larger numbers but is noted as being biased in\n","# nonnormal samples (data that is not bell shaped). This example uses\n","# n-1 in the denominator and is beyond the scope of this statistics class.\n","\n","# Sheskin, D.J. (2000) Handbook of Parametric and Nonparametric Statistical\n","# Procedures, Second Edition. Boca Raton, Florida: Chapman & Hall/CRC.\n","\n","# 4) Covariance and correlation\n","# a.) Covariance generalized\n","# Cov (xi - xmu)(yi - ymu), cor ((xi - xmu)(yi - ymu) / (stn1 * stn2)),\n","#       and least square regression (y(triangle_hat)) = xmu + (xi - xmu) (yi - ymu) / (xi - xmu)^2\n","#    rsqr = SSR = (y(triangle_hat) - ymu)^2\n","#           SSE = (yi - y(triangle_hat))^2\n","#           SST_1 = [(y(triangle_hat) - ymu)^2] + [(yi - y(triangle_hat))^2]\n","#       rsqr = SSR / SST\n","#    or rsqr = 1 - SSE / SST\n","# b.) correlation TODO\n","\n","# Parametric statistics are based on assumptions and used for Continuous variables.\n","# Continuous random variables can be used to describe variables like weight or income.\n","# Variable is measurable.\n","# https://libanswers.lib.miamioh.edu/stats-faq/faq/343628\n","# 5) One way ANOVA finds if there is a difference between the means being effected through\n","#    one independent variable. Two way ANOVA finds if there is a difference in means\n","#    being effected by two indpendent variables. It is an omnibus statistic which means\n","#    it says if there is a difference, not which mean specifically is different. For that\n","#    you need to conduct a post-hoc test. ANOVA does this by calculating the f stat\n","#    If it is greater than the F table value at a level of significance, then you\n","#    a.) reject the null hypothesis and there is a difference between\n","#    the means being testing -> ad hoc follow up to tell which\n","#    b.) Fail to reject the null hypothesis is there is not enough evidence to\n","#    prove that each groups means are different. Does not prove they are the same?\n","#\n","#    ANOVA might be overkill since an effective exercise program would have similar\n","#    pain scores across bodily types when grouped for major muscle groups.\n","#    The pain scale employed includes smaller muscles not typically sore\n","#    compaared with larger generalized muscle groups.\n","#    From: https://www.cuemath.com/anova-formula/\n","#    TODO: find verification\n","#   Equation:\n","#   f = MSB / MSE\n","#   MSB = SSB / (k - 1)\n","#   MSE = SSE / (N - k)\n","#   SSE = (xi - xmu) ^ 2\n","#   SSB = number of observations whatever group(mean of whatever group - [sum of each mean group/number of groups])\n","\n","# 6) chi squared\n","# 7) pearson's chi squared\n","# 8) student's t-test\n","# https://www.ibm.com/docs/en/db2woc?topic=procedures-statistics-parametric-nonparametric\n","\n","# Non-parametric are used for Descrete variables. Discrete random variables\n","# are used for experiments such as flipping a coin or rolling a six-sided die.\n","# Variable is countable. They are for smaller numbers of data.\n","# https://libanswers.lib.miamioh.edu/stats-faq/faq/343628\n","# 9.) Pearson's chi-square test of independence\n","# 10.) Mann-whitney-wilcoxon,\n","# 11.) Spearmann rank correlation\n","# 12.) Wilcoxon paired sample\n","# https://www.ibm.com/docs/en/db2woc?topic=procedures-statistics-parametric-nonparametric\n","# 13.) Kruskal–Wallis and Friedman test is the non-parametric\n","#      equivilent of the parametric one way ANOVA test\n","\n","# Other statistics for predicitons and large datasets:\n","# 14.) k-means clustering measures distance to mean to cluster data\n","# 15.) k-nearest neighbors memorizes dataset and make predictions - probably computationally expensive\n","# 16.) naive-bayes -> predictor with no iterative learning -> https://www.cs.cornell.edu/courses/cs4780/2018fa/lectures/lecturenote05.html\n","# 17.) pca -> feature reduction technique for large datasets\n","# Neural networks - that's the mirror of the electrical components\n","# and low level programming of computers but without the hackerman risk\n","\n","# 18.) Feedforward\n","# 19.) Toggle Feedforward subsection\n","# 20.) Regulatory feedback\n","# 21.) Radial basis function (RBF)\n","# 22.) Toggle Radial basis function (RBF) subsection\n","# 23.) Deep belief network\n","# 24.) Recurrent neural network\n","# 25.) Toggle Recurrent neural network subsection\n","# 26.) Modular\n","# 27.) Toggle Modular subsection\n","# 28.) Dynamic\n","# 29.) Toggle Dynamic subsection\n","# 30.) Memory networks\n","# 31.) Toggle Memory networks subsection\n","# 32.) Hybrids"],"metadata":{"id":"VyI5B2aispBB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"K5yH-94Md5c2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"UdN_mG_QUz_m"}},{"cell_type":"code","source":["# Time it methods\n","\n","%time\n","\n","# Is the equivalent of:\n","\n","# time_0 = ((datetime.now()).strftime('%H:%M:%S.%f'))\n","# Code to be timed\n","# time_1 = ((datetime.now()).strftime('%H:%M:%S.%f'))\n","# time_strp_0 = time_0.split(\":\")\n","# time_strp_1 = time_1.split(\":\")\n","# timed = float(time_strp_1[2])-float(time_strp_0[2])\n","# return timed\n","\n","# Results\n","# Method0 = 0.00010481281281270126\n","# Method1 = 0.00005615615615591504\n","\n","# The first ~7 calculations of Method1 were similar to Method0,\n","# then performance increased several times maybe it is log(n) complexity\n","\n","# Why would the decreased space used decrease the time?\n","# Between the C compiler and Python Virtual Machines as Python\n","# code is translated into machine readable binary, there are probably\n","# methods to reduce hardware demands on redundant calculations.\n","\n","'''\n","# Timed methods\n","B = []\n","for i in range(1000):\n","  A = Data1_Parser.stm_remove(data1_flipped, data1_col_len)\n","  B.append(A)\n","  print(A)\n","C = sum(B)\n","print(C/999)\n","# Met = 0.00010481281281270126\n","# Met1 = 0.00005615615615591504\n","'''"],"metadata":{"id":"aCEVnSXbhEmr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"im6LHi3oyGk2"}},{"cell_type":"code","source":["  # These are computer science questions in efficiency\n","\n","  # TODO CS 180 Question 0\n","  # 'def csv_flipper'\n","  # is bad code because it assumes the ID column is in the 0 position\n","  # which might be different in other CSV reducing reusability\n","  # Starting the counter variable j at number of the numerical\n","  # column that you want to not be flipped would be easier.\n","  # The 'def column_name' function could translate the desired numerical\n","  # column text into a number:\n","  def column_name(self, data_val_list):\n","    excluded_column_int = []\n","    return excluded_column_int\n","  # Then 'def csv_flipper would accept <excluded_column_int> returned from the\n","  # 'def column_name' function and exclude that column from the scale flipping.\n","\n","  # TODO CS 180 Question 1: Auxilliary space question\n","  # Does the array already exist in memory represented as binary\n","  # and the loop accesses the array at index 'i'?\n","  # If you remove the stamina value at index 'i' using the 'pop' method,\n","  # are you keeping the same array but with the removed value?\n","  # Or are you making another array which would be the same as\n","  # appending all the values to a new array as in the\n","  # commented function stm_remove? Time each function with 'datetime'.\n","\n","  # Answer 1: This doesn't matter at our several hundred numbers or even\n","  # at several thousand but it would increase hardware demands as the\n","  # size of the list increased. You kids these days are so spoiled,\n","  # back in my day we were lucky to have two kilobytes to rub together\n","  # to make install compiled binary code!\n","\n","  # Step 1) Remove the unnecessary flipped stamina column from the flipped list\n","  # (Two methods)\n","\n","  '''\n","  # Method 0 :\n","  def stm_remove(self, flip_list, col_num):\n","    time_0 = ((datetime.now()).strftime('%H:%M:%S.%f'))\n","    flip_list_rm = []\n","    og_col_num = col_num\n","    for i in range(len(flip_list)):\n","      if i == 3:\n","          col_num = i + col_num\n","      elif i == col_num:\n","        col_num += og_col_num\n","      else:\n","        flip_list_rm.append(flip_list[i])\n","    time_1 = ((datetime.now()).strftime('%H:%M:%S.%f'))\n","    time_strp_0 = time_0.split(\":\")\n","    time_strp_1 = time_1.split(\":\")\n","    timed = float(time_strp_1[2])-float(time_strp_0[2])\n","    # return timed\n","    return flip_list\n","  '''\n","\n","  # TODO CS 180 Question 1: Auxilliary space continued\n","  # Why does Method0\n","\n","  # Step 3) Append unflipped stamina values to flipped list as a new column\n","\n","  '''\n","  # Method 0 :\n","  def stm_append(self, stm_rm, stamina_col, col_num):\n","    flip_append_list = []\n","    og_col_num = col_num\n","    col_len = 32\n","    j = 0\n","    k = 0\n","    for i in range(len(stm_rm) + col_len):\n","      if i == 3:\n","        flip_append_list.append(stamina_col[j])\n","        col_num = i + col_num\n","        j += 1\n","      elif i == col_num:\n","        flip_append_list.append(stamina_col[j])\n","        col_num += og_col_num\n","        j += 1\n","      else:\n","        flip_append_list.append(stm_rm[k])\n","        k += 1\n","    return flip_append_list\n","  '''\n","\n","  # TODO CS 180 Question 2\n","  # 0) Write a function to get the length of the column. This will be used in the\n","  # 'stm_append' function to append the unflipped stamina values from 'extract'\n","  # to the output of the 'stm_remove' function containing flipped values and\n","  # stamina column by extending the length of the items iterated over.\n","  # Or you could use the length of the original csv list from csv_value_list\n","  # as input into the stm_append.\n","\n","  # Step 2)\n","  def column_len(self):\n","    col_len = 32\n","    return col_len\n","\n","  # TODO CS 180 Question 3: Auxilliary space continued\n","\n","  # Examples of bad Big O\n","  # The column iterator performs statistical calculations on the\n","  # values of each column\n","  # Method 0 : Big O n^2 very slow bad nested for loop\n","  '''\n","  def column_iter(self, stm_ext_flip, col_num):\n","\n","    og_col_num = col_num\n","    # The ouput of the 'column_len' function\n","    col_len = 32\n","    # The column length without the column name\n","    col_val = col_len - 1\n","    og_flip_list_len = len(stm_ext_flip)\n","    j = 3\n","    for k in range(j,col_num):\n","      col_vert = []\n","      total = 0\n","      for i in range(len(stm_ext_flip)):\n","        if i == og_flip_list_len:\n","          break\n","        if i == k:\n","          if i < (og_col_num):\n","            pass\n","          else:\n","            col_vert.append(int(stm_ext_flip[i]))\n","            total += int(stm_ext_flip[i])\n","          col_num = i + og_col_num\n","        elif i == col_num:\n","          col_vert.append(int(stm_ext_flip[i]))\n","          total += int(stm_ext_flip[i])\n","          col_num += og_col_num\n","\n","      print(col_vert)\n","      mean = Data1_Parser.mu(total, col_val)\n","      print(mean)\n","      print('b')\n","      print(sum(col_vert)/col_val)\n","    return\n","   '''\n","\n","  # Method 1 : Still bad because of Big O n*log(n)\n","  # Did not finish\n","  '''\n","  def column_iter(self, stm_ext_flip, col_num):\n","    col_strt = 3\n","    val_col_strt = col_strt + col_num\n","    iter_0 = val_col_strt\n","    val_col = col_num - 3\n","    iter_int = len(stm_ext_flip)*val_col\n","    const_stm_len = len(stm_ext_flip)\n","    for u in range(iter_int):\n","      print(len(stm_ext_flip))\n","      if u % len(stm_ext_flip) == 0:\n","        iter_0 = (u + val_col_strt + 1) - const_stm_len\n","        print(iter_0)\n","      elif u == iter_0:\n","        # print(stm_ext_flip[u])\n","        iter_0 += col_num\n","    return\n","    '''\n","\n","'''\n","# This is the covar original version\n","# Get descriptive statistics of each column\n","for j in range(3,data1_col_num):\n","  # Refractor these\n","  data1_mean = Data1_Parser.mu(data1_stm_ext_flip, data1_col_num, j)\n","  stn_dev1 = Data1_Parser.stn(data1_stm_ext_flip, data1_col_num, j, data1_mean)\n","  kurt = Data1_Parser.kur(data1_stm_ext_flip, data1_col_num, j, data1_mean, stn_dev1)\n","  skew = Data1_Parser.skew(data1_stm_ext_flip, data1_col_num, j, data1_mean, stn_dev1)\n","  print(data1_stm_ext_flip[j])\n","  print(\"covar with\")\n","  for k in range(2,data2_col_num):\n","    #print(data2_comma_list[k])\n","    covar = Data1_Parser.covar1(data1_stm_ext_flip, data1_col_num, data1_mean, j, data2_comma_list, data2_col_num, data2_mean_list, k)\n","    print(covar)\n","    # cor = Data1_Parser.cor(covar, stn_dev1, stn_dev2)\n","'''\n","\n","'''\n","# Correlation score readability\n","# food.csv columns 0 Calories, 1 Exe, 2 Salt, 3 Fat, 4 Prot, 5 Carb, 6 Alc\n","cc = 3\n","for ii in range(len(cor)):\n","  if ii % 7 == 0:\n","    print(data1_stm_ext_flip[cc])\n","    print(cor[ii])\n","    cc += 1\n","  else:\n","    print(cor[ii])\n","'''"],"metadata":{"id":"mere2W9s4IR4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Semi-retired code\n","'''\n","  # Index the commas and line breaks\n","  def comma_index(self, open_file, column_len):\n","    data_comma_place = []\n","    column_pl_len = 0\n","    for i in range(len(open_file)):\n","      data1_col1 = open_file[i]\n","      if data1_col1 == \",\":\n","        data_comma_place.append(i)\n","      if data1_col1 == \"\\n\":\n","        data_comma_place.append(i)\n","        # If you want to use the function to get the column width, set to 1\n","        if column_len == 1:\n","          data_comma_place = len(data_comma_place)\n","          print(data_comma_place)\n","          return data_comma_place\n","          break\n","    las_val = data_comma_place[-1] + 2\n","    data_comma_place.append(las_val)\n","    return data_comma_place\n","\n","  # Get the width of the column\n","  # todo2 avoid repeated code\n","  def comma_width(self, open_file, column_len):\n","    data_comma_place = []\n","    column_pl_len = 0\n","    for i in range(len(open_file)):\n","      data1_col1 = open_file[i]\n","      if data1_col1 == \",\":\n","        data_comma_place.append(i)\n","      if data1_col1 == \"\\n\":\n","        data_comma_place.append(i)\n","        # If you want to use the function to get the column width, set to 1\n","        if column_len == 1:\n","          data_comma_place = len(data_comma_place)\n","          break\n","    return data_comma_place\n","\n","'''"],"metadata":{"id":"ZZKS_mjGpn12"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"OPW0NTsypoBk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"I2X-bJC2poEE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"0a8FjPGe9aQF"},"execution_count":null,"outputs":[]}]}