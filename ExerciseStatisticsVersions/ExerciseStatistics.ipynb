{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1fHIWbrpk4NMYcse3Xdkb-S8XiS2pxzJm","timestamp":1721260308720},{"file_id":"1STKhtVVaknUZiohwWLdfyoZ3zg6Veimx","timestamp":1721260179755}],"authorship_tag":"ABX9TyNeJB3+3vN/qR490XheXR1Q"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# List of primary issues\n","# todo    description                              hours  progress    Note\n","# todo0   no lib python function csv parser.           6  COMPLETE\n","# todo1   make defs from repeated code.                1  COMPLETE\n","# todo2   def into class.                              1  COMPLETE\n","# todo3   flip column                                  2  COMPLETE\n","# todo4   improve efficiency auxilliary space          7  COMPLETE\n","# todo5   mean, standard deviation                     6  COMPLETE\n","# todo6   kurt, skew, covar, cor                       10 COMPLETE\n","# todo7   rearrange csv list vertically by column      2  COMPLETE\n","# todo8   Unflipped stm to the flipped pain scale      1  COMPLETE\n","# todo8   more readable code and refractor             7  COMPLETE\n","# todo8   make a graph function                        13 COMPLETE\n","# todo9   r squared, ANOVA                             2  HALTED      The other equations are plugging numbers\n","# todo10  interpret results                            10 PROCESSING  Waiting for more data\n","# todo11  chapter 1 coursework                         50 PROCESSING  10\n","#                                             TOTAL\n","# Total estimate  : 47\n","# Total actual    : 62\n","# Total remaining : 10-1000 (estimated)\n","# Summary: There are a list of excessive statistics to write if you get bored.\n","# Otherwise just wait two months for the new dataset.\n","\n","# List of secondary issues\n","# todo   description                              progress\n","# todo1  Functionality? 1 to print, 0 to not      COMPLETE\n","# todo2  Avoid repeated code in the comma list    COMPLETE\n","# todo3  Function get length of columns           COMPLETE\n","# todo4  Function get column by the string name   COMPLETE\n","# todo5  Find a way to traverse CSV_Parser once   PROCESSING\n","# todo6  Reusable binned Graph function           PROCESSING\n","# todo7  Reusable flipper CSV_Parser function     PROCESSING\n","# todo8  Save the graphs as jpgs                  PROCESSING\n","\n","import sys\n","#from datetime import datetime\n","print(sys.version)\n","# 3.10.12 (main, Mar 22 2024, 16:50:05) [GCC 11.4.0]\n","\n","##############################################################################\n","# Part 1984: Any device connected to the internet is fed into the network    #\n","##############################################################################\n","\n","# The reasons for this level of police state is to avoid terrible things like\n","# human traficking, theft, murder, etc. but if the network itself were trained\n","# on biased information it would be impossible to disassemble\n","# An example is using military style tactics to enforce parking tickets\n","class input_nineteen_eighty_four:\n","  def __init(self,file_in):\n","    self.file_in = file_in\n","  # Creates a local area network to limit the sharing of information\n","  def local_area_network(self):\n","    return\n","  # Records your location whether the GPS is enabled or not\n","  def continual_GPS(self):\n","    return\n","  # Records the things you say\n","  # Frequent words are returned and added to a list\n","  def your_device_audio(self):\n","    return\n","  # Records the things your device sees whether the camera is on or not\n","  def your_device_video(self):\n","    return\n","  # Feedback into the device's operating system sent into the network. With\n","  # desktop computers it was amount of time moving or not moving the mouse over\n","  # content whose accuracy was increased when biometric heart rate reading the\n","  # heartbeat while media is being consumed.\n","  def your_device_biometrics(self):\n","    return\n","  # Records the things you say and other people say\n","  # Frequent words are returned and added to a list\n","  def proximity_device_audio(self):\n","    return\n","  # Records the things other device sees whether the camera is on or not\n","  def proximity_device_video(self):\n","    return\n","  # Records your GPS whether you have your device or not\n","  def facial_recognition_location(self):\n","    return\n","  # Returns the coordinates of your automobile\n","  def auto_gps(self):\n","    return\n","  # Viral replication on every device to make sure the security measures persist\n","  # in the event of physical revolution measures\n","  def viral_file_backup(self):\n","    return\n","  # Generic 10 year story arc that pushes words and movies at various points\n","  # Can be modified so you can make more money of rigging public opinion.\n","  def content_bag(self):\n","    return\n","\n","##############################################################################\n","# Part A: CSV parser class to open the file and parse the values into a list #\n","##############################################################################\n","class CSV_Parser:\n","  # Initialize the input variables\n","  def __init__(self, data_path):\n","    self.data_path = data_path\n","  def file_opener(self):\n","    with open(self.data_path, \"r\") as data_open:\n","      data_read = data_open.read()\n","      return data_read\n","  # Index the commas and line breaks\n","  def comma_index(self, open_file, column_len):\n","    data_comma_place = [0]\n","    column_pl_len = 0\n","    for i in range(len(open_file)):\n","      data1_col1 = open_file[i]\n","      if data1_col1 == \",\":\n","        data_comma_place.append(i)\n","        data_comma_place.append(i+1)\n","      if data1_col1 == \"\\n\":\n","        data_comma_place.append(i)\n","        data_comma_place.append(i+1)\n","        # If you want to use the function to get the column width, set to 1\n","        if column_len == 1:\n","          col_width = len(data_comma_place)\n","          return col_width\n","          break\n","    las_val = data_comma_place[-1] + 2\n","    data_comma_place.append(las_val)\n","    return data_comma_place\n","  # Splitting the csv characters into list of words based on indexed comma position\n","  def csv_value_list(self, data_comma_out, open_file, col_width, col_head):\n","    j = col_head\n","    data_val_list = []\n","    for i in range(len(data_comma_out)):\n","      if j >= len(data_comma_out):\n","        break\n","      comma_strt = data_comma_out[j]\n","      j += 1\n","      comma_end = data_comma_out[j]\n","      #print(comma_strt, \"and \", comma_end)\n","      j += 1\n","      data_val_list.append(open_file[comma_strt:comma_end])\n","      j = j + (col_width * 2)\n","    return data_val_list\n","  # Flipping the columns from high to low for readability\n","  # If the original value was 5, set it to equal 0 (no pain)\n","  # If the original value was 0, set it to equal to 5 (high pain) etc.\n","  # If none of those things are true, append the string (for the column header)\n","  def csv_flipper(self, csv_list, col_width):\n","    csv_flipped = []\n","    for i in csv_list:\n","      if i == str(5):\n","        n = str(1)\n","        csv_flipped.append(n)\n","      elif i == str(4):\n","        n = str(2)\n","        csv_flipped.append(n)\n","      elif i == str(3):\n","        n = str(3)\n","        csv_flipped.append(n)\n","      elif i == str(2):\n","        n = str(4)\n","        csv_flipped.append(n)\n","      elif i == str(1):\n","        n = str(5)\n","        csv_flipped.append(n)\n","      else:\n","        csv_flipped.append(i)\n","    return csv_flipped\n","\n","######################################################\n","# Part B: Get descriptive statistics of each column. #\n","######################################################\n","class Statistics:\n","  # Initialize the input variables\n","  def __init__(self, P0_flipped, P0_col_width, B0_list, B0_col_width):\n","    self.P0_flipped = P0_flipped\n","    self.P0_col_width = P0_col_width\n","    self.B0_list = B0_list\n","    self.B0_col_width = B0_col_width\n","  # Returns a dictionary with the header and mean\n","  def mu(self, col_list):\n","    total = 0\n","    for i in col_list[1:]:\n","      total = total + float(i)\n","    mean = total / (len(col_list) - 1)\n","    header_mean = [col_list[0], mean]\n","    return header_mean\n","  # Returns the 2-4 moment of the distribution\n","  def mnt(self, header, mean, col_list):\n","    col_1 = len(col_list) - 1\n","    stn = 0\n","    skew = 0\n","    kurt = 0\n","    for i in col_list[1:]:\n","      n1 = int(i) - mean\n","      n1_sqr = n1 ** 2\n","      n1_cube = n1 ** 3\n","      n1_quad = n1 ** 4\n","      stn = stn + n1_sqr\n","      skew = skew + n1_cube\n","      kurt = kurt + n1_quad\n","    stn_small_sqr = float(stn) / float(col_1)\n","    stn_small = stn_small_sqr ** .5\n","    skew_small_sqr = float(skew) / float(col_1)\n","    skew_small = skew_small_sqr / (stn_small ** 3)\n","    kurt_small_sqr = float(kurt) / float(col_1)\n","    kurt_small = kurt_small_sqr / (stn_small ** 4)\n","    return [header, stn_small, skew_small, kurt_small]\n","  # Covariance and correlation\n","  def covar(self, x_mean, y_mean, col_1_list, col_2_list):\n","    col_len = len(col_1_list) - 1\n","    covar = 0\n","    x1y1_sum = 0\n","    for i in range(col_len):\n","      # print(\"x_mean: \", x_mean[1], \"x_value: \", col_1_list[i+1])\n","      x1 = float(col_1_list[i+1]) - x_mean[1]\n","      y1 = float(col_2_list[i+1]) - y_mean[1]\n","      x1y1 = x1 * y1\n","      x1y1_sum = x1y1_sum + x1y1\n","    covar = x1y1_sum / col_len\n","    return covar\n","  def cor(self, covar, col_1_stnd, col_2_stnd):\n","    stnd12 = col_1_stnd * col_2_stnd\n","    cor = covar / stnd12\n","    return cor\n","  # Current footage of events could be upscaled or downscaled in pixel resolution\n","  # to resemble old or new footage. Applications include recycle old footage\n","  # of games that had very few viewers or convincing the viewer that they were\n","  # in a repeating simulation or crazy.\n","  def upsampling (self):\n","    return\n","  def downsampling (self):\n","    return\n","  def feature_extraction(self):\n","    return\n","  def chi_squared(self):\n","    return\n","  def pearson_chi_squared(self):\n","    return\n","  # https://www.ibm.com/docs/en/db2woc?topic=procedures-statistics-parametric-nonparametric\n","  def student_t_test(self):\n","    return\n","  # Non-parametric are used for Descrete variables. Discrete random variables\n","  # are used for experiments such as flipping a coin or rolling a six-sided die.\n","  # Variable is countable. They are for smaller numbers of data.\n","  # https://libanswers.lib.miamioh.edu/stats-faq/faq/343628\n","  def pearson_chi_ind(self):\n","    return\n","  def mann_whitney_wilcox(self):\n","    return\n","  def spearmann_rank_cor(self):\n","    return\n","  # https://www.ibm.com/docs/en/db2woc?topic=procedures-statistics-parametric-nonparametric\n","  def wilcox_paired_sample(self):\n","    return\n","  # Test is the non-parametric equivilent of the parametric one way ANOVA test\n","  def kruskal_wallis_friedman(self):\n","    return\n","\n","  # Other statistics for predicitons and large datasets\n","\n","  # Measures distance to mean to cluster data\n","  def k_means_cluster(self):\n","    return\n","  # k-nearest neighbors memorizes dataset and make predictions - probably computationally expensive\n","  def k_nearest_neighbor(self):\n","    return\n","  # Predictor with no iterative learning -> https://www.cs.cornell.edu/courses/cs4780/2018fa/lectures/lecturenote05.html\n","  def naive_bayes(self):\n","    return\n","  # Feature reduction technique for large datasets\n","  def pca(self):\n","    return\n","####################################################################\n","# Part C: Neural networks is a mirror of the electrical components #\n","####################################################################\n","# Teaches low level programming and hardware but without the hacker risk\n","class Neural_Networks:\n","    def __init__(self):\n","      return\n","    def feedforward(self):\n","      return\n","    def toggle_feedforward(self):\n","      return\n","    def regulatroy_feedback(self):\n","      return\n","    def radial_basis_function(self):\n","      return\n","    def toggle_radial_basis_function(self):\n","      return\n","    def deep_belief(self):\n","      return\n","    def recurent(self):\n","      return\n","    def toggl_reccurent(self):\n","      return\n","    def modular(self):\n","      return\n","    def toggle_modular(self):\n","      return\n","    def dynamic(self):\n","      return\n","    def toggle_dynamic(self):\n","      return\n","    def memory(self):\n","      return\n","    def toggle_memory(self):\n","      return\n","    def hybrids(self):\n","      return\n","\n","######################################################\n","# Part D: Data visualization with a timeseries graph #\n","######################################################\n","# 'Graph' class accepts three variables: verticle arranged 'data',\n","# the date column'date_col_num', and the data column 'data_col_num'\n","class Graph:\n","  # Initialize the input variables\n","  def __init__(self, data, date_col_num, data_col_num):\n","    self.data = data\n","    self.date_col_num = date_col_num\n","    self.data_col_num = data_col_num\n","  def hi_lo(self, data_col_num):\n","    # The date and date column to be used\n","    data_col = self.data[data_col_num]\n","    data_col_len = len(data_col)\n","    # High and low of values\n","    hi_lo_count = 1\n","    hi = data_col[1]\n","    lo = data_col[1]\n","    for e in range(len(data_col[1:])):\n","      hi_lo_count += 1\n","      if hi_lo_count == (len(data_col[1:]) + 1):\n","        break\n","      if hi < data_col[hi_lo_count]:\n","        hi = data_col[hi_lo_count]\n","      if lo > data_col[hi_lo_count]:\n","        lo = data_col[hi_lo_count]\n","    return [hi, lo]\n","  def binned(self, hi_lo):\n","    # high value (5 in this case or hi_lo[0])\n","    # The date and date column to be used\n","    # TODO it works but is not resuable for other data ranges\n","    date_col = self.data[self.date_col_num]\n","    data_col = self.data[self.data_col_num]\n","    data_col_len = len(data_col)\n","    fiver = []\n","    fourer = []\n","    threer = []\n","    twoer = []\n","    oner = []\n","    lol_stm_date = []\n","    counter = 1\n","    # Binned with date value\n","    for i in range(data_col_len):\n","      P0_column = self.data[self.data_col_num]\n","      if counter == len(self.data[0]):\n","        break\n","      if float(P0_column[counter]) == 5:\n","        fiver.append([date_col[counter], P0_column[counter]])\n","      elif float(P0_column[counter]) == 4:\n","        fourer.append([date_col[counter], P0_column[counter]])\n","      elif float(P0_column[counter]) == 3:\n","        threer.append([date_col[counter], P0_column[counter]])\n","      elif float(P0_column[counter]) == 2:\n","        twoer.append([date_col[counter], P0_column[counter]])\n","      elif float(P0_column[counter]) == 1:\n","        oner.append([date_col[counter], P0_column[counter]])\n","      counter += 1\n","    # Combining the binned data into one dictionary\n","    lol_date_stm = [fiver, fourer, threer, twoer, oner]\n","    return lol_date_stm\n","\n","  def time_series(self, date_hi_lo, lol_date_stm):\n","    date_col = self.data[self.date_col_num]\n","    # Base of the month, plus 00 i.e. 500\n","    date_base = int(date_hi_lo[1]) - 1\n","    # The number of spaces is the 'day' (date - month) - 'prev_day_space_int'\n","    # The difference between the values is multiplied by ' ' for each 5,4,3,2,1\n","    # Value with a '+' character marking the position\n","    spacer = []\n","    prev_day_space_int = 0\n","    for i in lol_date_stm:\n","      spacer_mid = []\n","      for ii in i:\n","        day = int(ii[0]) - date_base\n","        day_count = day - prev_day_space_int\n","        day_space_str = ((day_count-1)*2) * \" \"\n","        spacer_mid.append(day_space_str)\n","        prev_day_space_int = day\n","      prev_day_space_int = 0\n","      spacer.append(spacer_mid)\n","    y_val = [y for y in range(len(spacer),0,-1)]\n","    return [spacer, y_val]\n","  def time_series_print(self,spacer,y_val):\n","    date_col = self.data[self.date_col_num]\n","    for j,k in zip(spacer,y_val):\n","      # y values\n","      print(k,end=\" \")\n","      for l in j:\n","        print(l,end=\"\")\n","        print(\"+\",end=\" \")\n","      print()\n","    # x values\n","    for m in range(len(date_col[0])-1):\n","      print(\"  \",end=\"\")\n","      for n in date_col[1:]:\n","        print(n[m], end=\" \")\n","      print()\n","    return\n","  def time_series_write(self,header,txt_out,spacer,y_val):\n","    # Open the output file location and write data to the txt\n","    date_col = self.data[self.date_col_num]\n","    file_output = open(txt_out, \"w\")\n","    file_output.write(header)\n","    file_output.write(\"\\n\")\n","    file_output.write(\"\\n\")\n","    # y values\n","    for j,k in zip(spacer,y_val):\n","      file_output.write(str(k) + \" \")\n","      for l in j:\n","        file_output.write(str(l))\n","        file_output.write(\"+\" + \" \")\n","      file_output.write(\"\\n\")\n","    # x values\n","    for m in range(len(date_col[0])-1):\n","      file_output.write(\"  \")\n","      for n in date_col[1:]:\n","        file_output.write(str(n[m]) + \" \")\n","      file_output.write(\"\\n\")\n","    file_output.close()\n","    return\n","\n","######################################################\n","# Part E: Word statistics and lyric output           #\n","######################################################\n","\n","class WordStatistics:\n","  def __init__(self):\n","    return\n","  def word_homophone_generator(self):\n","    return\n","\n","######################################################\n","# Part F: Generate music based on input from devices #\n","######################################################\n","# The graph looks like something else I look at a lot:\n","# https://tabs.ultimate-guitar.com/tab/charlie-parr/1922-blues-tabs-5125777\n","# Using the audio input from devices or devices around you, this class generates\n","# music by matching the frequency of the notes to existing notes. An effective\n","# sequencer would add musical complexity to the graphs.\n","\n","class Music_Generation:\n","  def __init__(self):\n","    return\n","  def note_sequencer(self):\n","    return\n","\n","#######################################################\n","# Part G: Generate images based on input from devices #\n","#######################################################\n","# This image generation class would create viral memes based on political or behavior\n","# modifications deemed essential. Biometrics used to generate content.\n","\n","class Image_Generation:\n","  def __init__(self):\n","    return\n","\n","\n","######################################################\n","# Part H: Generate video based on input from devices #\n","######################################################\n","# Creates 3D models of faces from social media and camera inputs and inserts them into\n","# content streams for subtle sociological manipulation. Biometric feedbacks to generate content.\n","\n","class Video_Generation:\n","  def __init__(self):\n","    return\n","  # This function takes the output from feature_extraction and constructs an\n","  # idea of where to place the object in the user's content stream. It would\n","  # use correlation to insert/remove an object's pattern that is related to whatever\n","  # behavior modification that is desired such as adding a banana or removing beer,\n","  # such as everyone in the '90's that were dancing at parties with their own\n","  # boombox instead of a case of beer.\n","  def feature_insertion(self):\n","    return\n","  def feature_deletion(self):\n","    return\n","\n","######################################################\n","# Part I: Generate 3D masks to hide from computers   #\n","######################################################\n","# Someone enganged in even marginally illegal activities from evading taxes, to selling\n","# misdemenor amounts of weed, from former news reporters using legally grey\n","# area techniques to evade the subjects of their former stories, to literate\n","# people wishing to avoid blatant behvaior modification, 3D printed masks and makeup\n","# would be ideal to walk undisturbed through the streets of a city to get grocceries.\n","# Generating 3D models of people faces would occur through the aforementioned\n","# camera network.\n","\n","class Mask_Generation:\n","  def __init__(self):\n","    return\n","\n","######################################################\n","# Part J: Behavior modification from 1984 inputs     #\n","######################################################\n","# Mainly based on using the central limit theorem and other statistical models\n","# with massive amount of data to control the population. Really depends on if\n","# the countermeasure is economically viable. Behvior modification could further\n","# be used to destroy past records of whatever was deemed undesireable from\n","# copies of movies to images of events that were now being changed.\n","\n","# input_nineteen_eighty_four,CSV_Parser,Statistics,Graph\n","class behavior_modification:\n","  # Initialize the input variables\n","  def __init__(self,lan,device_gps,estimated_gps,device_audio,device_video,prox_audio,prox_video,virus):\n","    self.lan = lan\n","    self.device_gps = device_gps\n","    self.estimated_gps = estimated_gps\n","    self.device_audio = device_audio\n","    self.device_video = device_video\n","    self.prox_audio = prox_audio\n","    self.prox_video = prox_video\n","    self.virus = virus\n","  # Uses gps, audio, video, inputs to see if you're making noise when you shouldn't\n","  def noise_ordinence_enforcement(self):\n","    return\n","  # Uses automobile gps to give tickets\n","  def parking_enforcement(self):\n","    return\n","  # Object detection to read liscnece plate and charge unpaid tolls, speeding,\n","  # reckless driving, etc.\n","  def DOT_enforcement(self):\n","    return\n","  # Uses gps to see if the person/car is still in the country or leaves\n","  def border_control(self):\n","    return\n","  # Police stings or baiting political dissidents into commiting crimes using\n","  # manual or automated content bag -> generic character assassination\n","  def baiting_politcal_dissidents(self):\n","    return\n","  # Uses a camera system to create audio/visual/smell projections for\n","  # individual or crowd dispersal. Could range from mildly annoying gnats\n","  # to scary gangsters with gunshots to revenge internet content.\n","  # If your GPS is outside the desired demographic for an area this\n","  # might apply to you, i.e. an old man in a college bar district.\n","  def deterent(self):\n","    return\n","  # Biometric and viewing measurements are used to arbitrarily judge if the user\n","  # has reached their limit on content consumption for the hour, day, week, etc.\n","  # Would use the homophone function to plant undesireable words into the media\n","  # making the content subliminally unwatchable and forcing the user to do other things.\n","  def media_consumption_deterent(self):\n","    return\n","  # Uses the words most frequently occuring in the person's programming and spams\n","  # the person's content if the person starts realizing technology secrets until\n","  # they went insane, effectively gas lighting the person and negating their argument.\n","  def programming_deterent(self):\n","    return\n","\n","  def programming_deterent_assaination(self):\n","    return\n","  # Gathers evidence of minor/major crimes you commit and charges or blacklists you\n","  # if you cross a threshold barring you from income or voting. This would make it\n","  # difficult to get employment if the laws were changed. For example, if you got blacklisted\n","  # for something trivial like weed and were baited into a misdemeanor crime.\n","  def evidence_bag(self):\n","    return\n","\n","\n","# Part A: The path of the CSV to be parsed\n","# P0.csv contains the pain scale and B0.csv contains the food records\n","P0_path, B0_path = \"/content/P0.csv\", \"/content/B0.csv\"\n","# Create the CSV_Parser class object and open the files\n","P0_Parser, B0_Parser = CSV_Parser(P0_path), CSV_Parser(B0_path)\n","P0_read, B0_read = P0_Parser.file_opener(), B0_Parser.file_opener()\n","# Index the comma position from the CSV and split the characters into their values\n","P0_comma_indexed, B0_comma_indexed = P0_Parser.comma_index(P0_read, 0), B0_Parser.comma_index(B0_read, 0)\n","# Get the width of columns of the commas\n","P0_comma_width, B0_comma_width = P0_Parser.comma_index(P0_read, 1), B0_Parser.comma_index(B0_read, 1)\n","# Sort the list into verticle columns\n","# The P0 csv gets flipped, except for the Stm column\n","# Divide by two - the list of comma places is doubled for the start/end value\n","P0_col_width = int(((P0_comma_width - 1 ) / 2) - 1)\n","# Divide by two - the list of comma places is doubled for the start/end value\n","B0_col_width = int(((B0_comma_width - 1 ) / 2) - 1)\n","P0_vert = []\n","B0_vert = []\n","# List of columns to not be flipepd\n","unflipped_col = ['ID','Date','Day','Stm']\n","for i in range(0,P0_comma_width-1,2):\n","  P0_list = P0_Parser.csv_value_list(P0_comma_indexed, P0_read, P0_col_width, i)\n","  if P0_list[0] in unflipped_col:\n","    P0_vert.append(P0_list)\n","  else:\n","    P0_flip = P0_Parser.csv_flipper(P0_list, P0_col_width)\n","    P0_vert.append(P0_flip)\n","for j in range(0,B0_comma_width-1,2):\n","  B0_list = B0_Parser.csv_value_list(B0_comma_indexed, B0_read, B0_col_width, j)\n","  B0_vert.append(B0_list)\n","\n","# Part C: Get descriptive statistics\n","stats_class = Statistics(P0_vert, P0_col_width, B0_vert, B0_col_width)\n","# The first three columns are skipped because they are ID, Date, and Day\n","# These two loops calculate the means and moments\n","P0_means_list = []\n","P0_stnd_list = []\n","B0_means_list = []\n","B0_stnd_list = []\n","for l in stats_class.P0_flipped[3:]:\n","  P0_means = stats_class.mu(l)\n","  P0_means_list.append(P0_means)\n","  P0_mnt2_4 = stats_class.mnt(P0_means[0],P0_means[1],l)\n","  P0_stnd_list.append(P0_mnt2_4[1])\n","for m in stats_class.B0_list[3:]:\n","  B0_means = stats_class.mu(m)\n","  B0_means_list.append(B0_means)\n","  B0_mnt2_4 = stats_class.mnt(B0_means[0],B0_means[1],m)\n","  B0_stnd_list.append(B0_mnt2_4[1])\n","# The nested loops calculates the covariance and correlations between B0 and P0\n","for n in range(len(stats_class.P0_flipped[3:])):\n","  #print(\"x: \", stats_class.P0_flipped[o+3][0])\n","  for o in range(len(stats_class.B0_list[3:])):\n","    #print(\"    and \", stats_class.B0_list[p+3][0])\n","    P0B0_covar = stats_class.covar(P0_means_list[n],B0_means_list[o],stats_class.P0_flipped[n+3],stats_class.B0_list[o+3])\n","    P0B0_cor = stats_class.cor(P0B0_covar,P0_stnd_list[n],B0_stnd_list[o])\n","    #print(P0B0_cor)\n","  #print()\n","\n","# Part D: Make a graph\n","'''\n","graph_count = 3\n","for p in stats_class.P0_flipped[3:]:\n","  # date_col_num = 1 # data_col_num = each successive column\n","  # this would be a loop over columns 3-20, 1st column is the date\n","  jpg_print = []\n","  # print(p[0])\n","  # print()\n","  P0_graph = Graph(P0_vert, 1, graph_count)\n","  P0_hi_lo = P0_graph.hi_lo(graph_count)\n","  date_hi_lo = P0_graph.hi_lo(1)\n","  P0_binned = P0_graph.binned(P0_hi_lo)\n","  P0_time_series = P0_graph.time_series(date_hi_lo,P0_binned)\n","  P0_graph.time_series_print(P0_time_series[0],P0_time_series[1])\n","  # print()\n","  P0_file_out = \"/content/P0_\" + p[0] + \".txt\"\n","  # P0_time_series_write = P0_graph.time_series_write(p[0],P0_file_out,P0_time_series[0],P0_time_series[1])\n","  graph_count += 1\n","'''\n"],"metadata":{"id":"IxtfVwAjhyaV","colab":{"base_uri":"https://localhost:8080/","height":141},"executionInfo":{"status":"ok","timestamp":1724681734410,"user_tz":300,"elapsed":226,"user":{"displayName":"David Leifer","userId":"06279506333224389759"}},"outputId":"edce8f75-a55c-41c9-d4ce-467ecbfe365d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["3.10.12 (main, Jul 29 2024, 16:56:48) [GCC 11.4.0]\n"]},{"output_type":"execute_result","data":{"text/plain":["'\\ngraph_count = 3\\nfor p in stats_class.P0_flipped[3:]:\\n  # date_col_num = 1 # data_col_num = each successive column\\n  # this would be a loop over columns 3-20, 1st column is the date\\n  jpg_print = []\\n  # print(p[0])\\n  # print()\\n  P0_graph = Graph(P0_vert, 1, graph_count)\\n  P0_hi_lo = P0_graph.hi_lo(graph_count)\\n  date_hi_lo = P0_graph.hi_lo(1)\\n  P0_binned = P0_graph.binned(P0_hi_lo)\\n  P0_time_series = P0_graph.time_series(date_hi_lo,P0_binned)\\n  P0_graph.time_series_print(P0_time_series[0],P0_time_series[1])\\n  # print()\\n  P0_file_out = \"/content/P0_\" + p[0] + \".txt\"\\n  # P0_time_series_write = P0_graph.time_series_write(p[0],P0_file_out,P0_time_series[0],P0_time_series[1])\\n  graph_count += 1\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":[],"metadata":{"id":"Z1tNeC-KF53Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Semi-retired code\n","'''\n","  # Index the commas and line breaks\n","  def comma_index(self, open_file, column_len):\n","    data_comma_place = []\n","    column_pl_len = 0\n","    for i in range(len(open_file)):\n","      data1_col1 = open_file[i]\n","      if data1_col1 == \",\":\n","        data_comma_place.append(i)\n","      if data1_col1 == \"\\n\":\n","        data_comma_place.append(i)\n","        # If you want to use the function to get the column width, set to 1\n","        if column_len == 1:\n","          data_comma_place = len(data_comma_place)\n","          print(data_comma_place)\n","          return data_comma_place\n","          break\n","    las_val = data_comma_place[-1] + 2\n","    data_comma_place.append(las_val)\n","    return data_comma_place\n","\n","  # Get the width of the column\n","  # todo2 avoid repeated code\n","  def comma_width(self, open_file, column_len):\n","    data_comma_place = []\n","    column_pl_len = 0\n","    for i in range(len(open_file)):\n","      data1_col1 = open_file[i]\n","      if data1_col1 == \",\":\n","        data_comma_place.append(i)\n","      if data1_col1 == \"\\n\":\n","        data_comma_place.append(i)\n","        # If you want to use the function to get the column width, set to 1\n","        if column_len == 1:\n","          data_comma_place = len(data_comma_place)\n","          break\n","    return data_comma_place\n","\n","  def aaaa(self, P0_flipped):\n","    space_holder = 0\n","    for j, k in zip(P0_flipped[1],P0_flipped[3]):\n","      char_len = len(j)\n","      space_holder = space_holder + char_len\n","      hed_spc = \" \" * space_holder\n","      print(hed_spc)\n","\n","    for j in P0_flipped[1]:\n","      hed_spc = \" \" * len(j)\n","      # Prints the xy label\n","      if j == P0_flipped[1][0]:\n","        print(\"  \", end=\" \")\n","      # This part makes the newline\n","      elif j == P0_flipped[1][col_len-1]:\n","        print(\"\")\n","      # Prints the number of spaces held by date label (x variable)\n","      else:\n","        print(hed_spc, end =\" \")\n","    # This is where the high low value would help\n","    for i in range(4,-1,-1):\n","      print(i+1)\n","      if i == (float(P0_flipped[0][1])):\n","        # Date column loop\n","        for j in P0_flipped[1]:\n","          if j == P0_flipped[1][0]:\n","            print(\"yx\", end=\" \")\n","          else:\n","            print(j, end =\" \")\n","    return\n","'''"],"metadata":{"id":"ZZKS_mjGpn12"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"OPW0NTsypoBk"},"execution_count":null,"outputs":[]}]}
