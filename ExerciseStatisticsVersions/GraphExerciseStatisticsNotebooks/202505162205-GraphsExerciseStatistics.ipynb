{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1fHIWbrpk4NMYcse3Xdkb-S8XiS2pxzJm","timestamp":1721260308720},{"file_id":"1STKhtVVaknUZiohwWLdfyoZ3zg6Veimx","timestamp":1721260179755}],"authorship_tag":"ABX9TyMUwsWhr6Jj4feLXf96hZ/7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["def todo(self):\n","  # List of primary issues\n","  # todo    description                                   hours   progress      Note\n","  #\n","  # todo0   A01.csv skate, long, downhill, juggling,      83      Completed\n","  #         running mean duration by category.\n","  #\n","  # todo1   A01.csv category by day of the week or        .25     DNF           Hours are spread throughout the day.\n","  #         time of day i.e. morning, afternoon, night\n","  #         or blocks of 3.\n","  #\n","  # todo2   A01.csv nltk the 'Explanation' and 'Notes'                          Word frequency might be useful to find specific muscles.\n","  #         sections? Manual descriptions are already                           Topic analysis is included in 'Activity'. Sentiment analysis is\n","  #         included in the write-up.                                           redundant since 'Notes' is informational and not opinion.\n","  #\n","  # todo3   Another tutorial chapter on merge sort.               TODO\n","  #         Compare with Python's built-in len(),\n","  #         sort(), and replace().\n","  #\n","  # todo4   The graphing part could be included in        .25     DNF           This is a good project to learn syntax and documentation since it's visual.\n","  #         Chapter 1 with pandas and SciPy.\n","  #\n","  # todo5   A01.csv longboard and running distance.       .5      DNF           Running occured around 5 times and longboarding was recorded with time.\n","  #\n","  #\n","  # todo6   P0P1B0B1.csv timeseries graphing.             45.5    Completed\n","  #\n","  # todo7   P1.csv manual vs observed prediction          15.0    Processing    Refractor. Graph prediction, observation with precision, recall, F1 score.\n","  #         accuracy F1.                                                        Wilcoxon statistical test to compare target mean with total mean.\n","  #\n","  # todo8   B01.csv Pearson-Correlation and day-          2       Completed     Found that there was not correlation between parametric variables.\n","  #         delayed between calories, alcohol, exercise.                        An index similar to ENSO is redundant since there were no consecutive\n","  #                                                                             observations over 4 alcohol or excessive (calorie - calorie burned).\n","  #\n","  # todo9   A01P01B01 moving window spearman              .5      DNF           Would have to sort these for rank, which was completed in todo0.\n","  #         correlation between activity, duration,                             Square the difference between each numbers rank and sum all the numbers,\n","  #         time of day, pain, nutrients,                                       multiply by 6, divide by (number times (number squared minus one).\n","  #         calories, alcohol.                                                  1 - calculated number.\n","  #\n","  # todo10  tbd data filling and automatic predictions.   0       DNF\n","  #         idk if thats another chapter or avoided.\n","  #\n","  # todo11  Manual weather observations and PRISM data    0       DNF\n","  #         will be in a different GitHub to avoid\n","  #         confusion.\n","  #\n","  # Time spent at a computer programming\n","  # Total estimate  :\n","  # Total actual    :\n","  #\n","  # Purpose\n","  # The goal of writing this is to waste as much time as possible in between\n","  # skateboarding, lifting, or exercise to avoid overtraining while retaining\n","  # logical thought process during long stretches of unemployment. These were\n","  # written on a computer with a 1.5-2 hour battery to restrict excessive\n","  # programming by limiting hardware access.\n","  #\n","  # Abstract\n","  # No library Python with C-like syntax is used for data manipulation and\n","  # graphing whereby arrays are handled without dictionaries. The only\n","  # library used is Matplotlib for RGB graphing and to avoid writing a image or\n","  # video format that would likely spread misinformation. An implementation of\n","  # the merge sort algorithm was used to alphabetize exercise activity for\n","  # binning and graphing frequency by unique type. The built-in Python methods\n","  # for 'replace', 'split', 'len', and 'sort' were manually written for\n","  # learning purposes.\n","\n","  # Start date: 20250125\n","  # End date:\n","\n","  # Below is an exhaustive list of secondary issues.\n","\n","  # List of secondary issues\n","  # todo   description                                                  progress\n","  # todo0  rewrite parser for unicode csv str/int.\n","  # todo1  Stats class avoid NA, NAAN, -9999, etc.\n","  # todo2  refractor RGB_graphs.\n","  # todo3  monthly means on bar graphs.\n","  # todo4  organize merge_sort into another classe.                     Complete\n","  # todo5  modify merge sort to accept entire CSV.                      Class\n","  # todo6  Handle multi word activity descriptions consistently.        Class\n","  # todo7  switch the second capital letter to lower case if exists.    Class\n","  # todo8  unchain the four merge sort functions.                       Class\n","\n","  return\n","\n","# import sys\n","# for path in sys.path:\n","#   print(path)\n","import matplotlib\n","import matplotlib.pyplot as plt\n","import exercise_module as eu\n","# eu.test_function()\n","# print(sys.version)\n","# 3.10.12 (main, Mar 22 2024, 16:50:05) [GCC 11.4.0]\n","# 3.11.11 (main, Dec  4 2024, 08:55:07) [GCC 11.4.0]\n","\n","# In development.\n","###############################################\n","# Part D: Data visualization with a RGB graph #\n","###############################################\n","# Matplotlib for color because otherwise you would have\n","# to write hardware code to avoid using Python or C libraries.\n","\n","class Graphs_rgb: # 'Graphs_rgb_dev()' in 'exercise_module.py'\n","  # Initialize the input variables\n","  def __init__(self, data):\n","    self.data = data\n","\n","  def rgb_reverse_mean(self,data,x_axis):\n","    category = data[0][0]\n","    category_day = data[0][1]\n","    category_value = data[0][2]\n","    # z = [k[5] for k in data] # Category total mean.\n","    # y = [i[4] for i in data] # Target mean.\n","    # x = [j[3] for j in data] # Number of reverse days.\n","    # plot_0 = ax.scatter(x,y)\n","    # plot_0 = ax.scatter(x,z)\n","\n","    '''\n","    x = [data[0][3],data[0][3],\n","         data[0][3],data[0][3],\n","         ...n]\n","    y = [data[0][4],data[0][5],\n","         data[1][4],data[1][5],\n","         ...n]\n","    '''\n","    fig, ax = plt.subplots(figsize=(5, 5))\n","    plt.ylim(4,8)\n","    for i in range(len(data)):\n","      x = data[i][3],data[i][3]\n","      y = data[i][4],data[i][5]\n","      if data[i][4] > data[i][5]:\n","        marker_value = '+'\n","      elif data[i][5] > data[i][4]:\n","        marker_value = '_'\n","      else:\n","        marker_value = 'o'\n","      plot = ax.plot(x,y, marker=marker_value, linestyle='--')\n","\n","    # reformat category, include 'category_value',\n","    # recall, F1 scores with the prediction and actual value\n","    # in a text box.\n","    plt.title(\"Previous Day's Frequency\\nfor \" + category + \", July-October, 2024\", # pad=50,\n","              fontsize=12)\n","    plt.xticks(x_axis)\n","    plt.xlabel(\"Number of days before \" + category_day, fontsize=10)\n","    plt.ylabel('Previous Frequency Mean', fontsize=10)\n","    # ax.tick_params(axis='y', pad=50, labelsize=14)\n","    # ax.xaxis.set_ticks_position('top')\n","    # ax.xaxis.set_label_position('top')\n","    # plt.yticks(x, labels=x, ha='center')\n","\n","    plt.grid()\n","    plt.margins(y=0.01)\n","    # plt.savefig('P1-0 Activity Frequency Mean July-October, 2024' + '.jpg')\n","    return\n","\n","  # Graph prediction and observation for the P1.csv pain charts with\n","  # accuracy, precision, recall, and f1 score in a text box.\n","  def rgb_class_metrics(self,data):\n","    return\n","\n","# In development.\n","#################################################\n","# Part E: Part D visualization helper functions #\n","#################################################\n","# Merge sort is the fastest for worst case scenario sorting: N log(n)\n","# Implementation is from W3 and modified for AZ with ascii ord():\n","# https://www.w3schools.com/dsa/dsa_algo_mergesort.php\n","class Graphs_sort:\n","  # Initialize the input variables\n","  def __init__(self, data):\n","    self.data = data\n","\n","  # Returns the abnormal pain entry.\n","  def erroneous_values(self,P1_vert_column):\n","    erroneous_values = [[P1_vert_column[0],'NA']]\n","    for i in range(len(P1_vert_column)):\n","      if len(P1_vert_column[i]) > 1:\n","        continue\n","      # Not stamina and greater than 4 pain values and 'Day_ID' get sent\n","      # to the list of lists.\n","      if P1_vert_column[0] != 'Stm' and int(P1_vert_column[i]) > 3:\n","        erroneous_values.append([P1_vert_column[i], i-1])\n","      # If it is stamina, check for values 2 and less.\n","      elif P1_vert_column[0] == 'Stm' and int(P1_vert_column[i]) < 3:\n","        erroneous_values.append([P1_vert_column[i], i-1])\n","    return erroneous_values\n","\n","  # Functions to make graphing 'P1.csv' and 'A1.csv' easier.\n","  # Helper function used in 'activity_frequency' to calculate the frequency\n","  # between 'start' and 'end'\n","  def activity_frequency_helper(self,start,end):\n","    # self.data[0] is the 'Day_ID'.\n","    count = 1\n","    activity_frequency = []\n","    # Skips the header. 'total_start' is when the 'Pain' scale is abonormal\n","    # minus the number of days of interest [3,5,7,10,30...n]\n","    for i in range(start,end):\n","      # The last value doesn't have a '' to increment 'count' and is done here.\n","      if i == len(self.data[0]) - 1:\n","        count += 1\n","        activity_frequency.append(count)\n","      # When the length of the value is > 0 (or not ''), that is the activity\n","      # frequency and set 'count' back to 1.\n","      elif len(self.data[0][i]) > 0:\n","        activity_frequency.append(count)\n","        count = 1\n","      # 'count' starts at 1, the '' are blank and counted in each day.\n","      elif self.data[0][i] == '':\n","        count += 1\n","    return activity_frequency\n","\n","  # Number of activities per day for 'A1' and adjusted for reverse days.\n","  def activity_frequency(self,total_start,day_list,reverse_days):\n","    # self.data[0] is the 'Day_ID'.\n","    count = 1\n","    activity_frequency = []\n","    # Skips the header. 'total_start' is when the 'Pain' scale is abonormal\n","    # minus the number of days of interest [3,5,7,10,30,...n]\n","    header = reverse_days[0] # [0]\n","    print(header)\n","    # day_list X reverse_days (5 X n) = ~145\n","    # The range of 'Day_ID' adding the frequency for [3,5, ... n] for each\n","    # successive 'reverse_days' then skip those 30 for the total frequency.\n","    for day in day_list:\n","      for reverse in range(1,len(reverse_days)):\n","        # Check if there are enough days to reverse.\n","        day_start = reverse_days[reverse][1] - day\n","        if day_start > -1:\n","          day_end = reverse_days[reverse][1]\n","          # have start and end id doesnt help because A1 is longer than P1.\n","          day_frequency = self.activity_frequency_helper(day_start+2,day_end+2)\n","          # print(day,day_start,day_end,day_frequency)\n","    return activity_frequency\n","\n","#################################################\n","# Part F: Non-parametric Classification Metrics #\n","#################################################\n","# Inputs are observations and prediction columns.\n","# Assumes input has a header.\n","class classification_metrics:\n","  # true_positive  = true_positive   1  (true_positive 1 / true_positive 1 + fn4) or recall\n","  # true_negative  = true_negative   0  (true_negative 0 / true_negative 0 + false_positive 3)\n","  # false_positive = false_positive  3  predicted soreness, was not sore.\n","  #                                     false positive rate = false_positive 3 / false_positive 3 + true_negative 0\n","  # false_negative = false_negative  4  predicted not soreness, was sore\n","  # https://www.geeksforgeeks.org/metrics-for-machine-learning-model/#regression-evaluation-metrics\n","  # https://developers.google.com/machine-learning/crash-course/classification/accuracy-precision-recall\n","  '''\n","  print(P1_vert[0])\n","  print(P1_vert[1])\n","  print(P1_vert[2])\n","  # 0 6 7 8\n","  print(A1_vert[0]) # Day_ID\n","  print(A1_vert[6]) # Activity\n","  # print(A1_vert[7]) # Notes\n","  # print(A1_vert[8]) # Explaination\n","  '''\n","  def __init__(self,observations,predictions):\n","    # The input scale is 5-1 high pain to low pain (or stamina).\n","    # The original data was 1-5 high pain to low pain and was flipped\n","    # since it was confusing (except for stamina).\n","    self.observations = observations\n","    self.predictions = predictions\n","\n","  def binary_classification(self):\n","    # Returns 0 (True Negative) 1 (True Positive) if prediction\n","    # matches observation. False Positive when prediction was soreness\n","    # and observation was no soreness (3). False Negative when the prediction\n","    # was no soreness and there was soreness (4).\n","    # Also returns the count for the classifications.\n","    true_negative = 0\n","    true_positive = 0\n","    false_positive = 0\n","    false_negative = 0\n","    binary = []\n","    for i in range(1,len(self.observations)):\n","      if self.observations[i] == self.predictions[i]:\n","        result = 1\n","        true_positive += 1\n","      else:\n","        if self.predictions[i] == 'NA' or self.observations[i] == 'NA':\n","          result = 0\n","        # False positive predicted 4 or 5 (high soreness) and was 1,2,3.\n","        elif int(self.predictions[i]) > 3 and int(self.observations[i]) <= 3:\n","          result = 3\n","          false_positive += 1\n","        # False negative predicted 1,2,3 (low soreness) and was 4 or 5.\n","        elif int(self.predictions[i]) <= 3 and int(self.observations[i]) > 3:\n","          result = 4\n","          false_negative += 1\n","        else:\n","          result = 0\n","          true_negative += 1\n","      binary.append(result)\n","    return [binary,true_negative,true_positive,false_positive,false_negative]\n","\n","  def accuracy(self,binary):\n","    # Number of correct predictions / total, input is False/True 0/1.\n","    count = 0\n","    for i in binary:\n","      if i == 1:\n","        count += 1\n","    total = len(binary)\n","    result = count / total\n","    return result\n","\n","  def precision(self,true_positive,false_positive):\n","    # precision = true_positive 1 / (true_positive 1 + false_positive 3)\n","    result = true_positive / (true_positive + false_positive)\n","    return result\n","\n","  def recall(self,true_positive,false_negative):\n","    # (true_positive / true_positive + false_negative 4) or recall\n","    result = true_positive / (true_positive + false_negative)\n","    return result\n","\n","  def f1_score(self,true_positive,false_positive,false_negative):\n","    # 2 * (precision * recall) / (precision + recall)\n","    # (2 true_positive) / (2 true_positive + false_positive 3 + false_negative)\n","    result = (2 * true_positive) / ((2*true_positive) + false_positive + false_negative)\n","    return result\n","\n","  # After the previous n (10,7,5,3) days of activity frequency, use the non parametric\n","  # Wilcoxon's rank sum test to compare the two dependent or paired samples. The two\n","  # samples being compared are n days activity frequency with the entire dataset's activity\n","  # frequency. It is non-parametric because it is categorical or ordinal dataset and\n","  # not real world measurements, despite having over 30 observations.\n","  # https://www.stat.purdue.edu/~tqin/system101/method/method_wilcoxon_rank_sum_sas.htm\n","  # https://pmc.ncbi.nlm.nih.gov/articles/PMC4754273/\n","  def wilcoxon_rank_sum(self):\n","    return\n","\n","##############################################################################\n","# Part Z: Run the functions                                                  #\n","##############################################################################\n","\n","# Part A: The path of the CSV to be parsed\n","def CSV_running(path,unflipped_col):\n","  # Create the CSV_Parser class object and open the files\n","  parser = eu.CSV_Parser(path)\n","  read = parser.file_opener()\n","  # Index the comma position from the CSV and split the characters into their values\n","  comma_indexed = parser.comma_index(read, path, 0)\n","  # Get the width of columns of the commas\n","  comma_width = parser.comma_index(read, path, 1)\n","  # Sort the list into verticle columns\n","  # The P0 csv gets flipped, except for the Stm column\n","  # Divide by two - the list of comma places is doubled for the start/end value\n","  col_width = int(((comma_width - 1 ) / 2) - 1)\n","  vert = []\n","  for i in range(0,comma_width-1,2):\n","    value_list = parser.csv_value_list(comma_indexed, read, col_width, i)\n","    if unflipped_col == 0:\n","      vert.append(value_list)\n","    else:\n","      if value_list[0] in unflipped_col:\n","        vert.append(value_list)\n","      else:\n","        flip = parser.csv_flipper(value_list, col_width)\n","        vert.append(flip)\n","  return vert\n","\n","# Part F: Predictions vs Observed pain values using classification metrics.\n","def P1_Classification_RGB_graph(P1_vert,P1_vert_predictions):\n","\n","  # B1.csv - Nutrition - binary calories high and low -> above/below 2500\n","  # - Mean number of activities per day over 3-14 days\n","  #     - Exclude 09/09-09/13 since it was recorded with excessive detail.\n","  # - Not stretching in the one or two days afterward.\n","  # - Stretching too frequently in the one or two days afterward.\n","\n","  # Days of Interest :\n","  # Stamina for 08/27-0903 (value 4) except 08/29 (value 2) and abs (4) on 08/31.\n","      # Stamina for 09/13. Exclude 09/09-09/13 since it was recorded with excessive detail.\n","  # Stamina for 09/19-09/22 (value 4) except 09/21 (value 2).\n","  # The goal is to find an appropriate balance for exercise and not moving\n","  # by examining the frequency of Activities before these decreases.\n","\n","  # 'Day_ID' remove 49-53 for average graphing because they were recorded\n","  # differently and induce outliers. ['909','910','911','912','913']\n","  for P1 in range(len(P1_vert_predictions)):\n","    del P1_vert_predictions[P1][50:55]\n","    del P1_vert[P1][50:55]\n","  # Remove these dates: ['909','910','911','912','913']\n","  # in A1_vert[0], A1_vert[3]\n","  del A1_vert[0][271:326]\n","  del A1_vert[3][271:326]\n","  # Accuracy, Precision, Recall, F1\n","  # Uses F1 since RMSE is for regression prediction models. The pain scale\n","  # is numerical and is equivilent to nominal categories.\n","  title_full = ['','','',\n","  'Stamina',\n","  'Feet','Ankle','Calves',\n","  'Knees','Quadriceps','Gluteus','Groin',\n","  'Abdominals','Lower Back',\n","  'Latissimus Dorsi','Trapezius','Shoulders',\n","  'Chest','Triceps','Biceps',\n","  'Neck','Head']\n","  # todo classification_metrics\n","  # wilcoxon_rank_sum\n","  for i in range(3,len(P1_vert)):\n","    '''\n","    print('Pain Scale')\n","    print(P1_vert[i])\n","    print('Classification')\n","    class_met = classification_metrics(P1_vert[i],P1_vert_predictions[i])\n","    binary = class_met.binary_classification()\n","    print(binary[0])\n","    print()\n","    # i is the pain scale 'Day_ID' (1-101) for A1 (1-350ish) 'did'\n","    print(A1_vert[0]) # 'Day_ID\n","    print(A1_vert[1])\n","    print(A1_vert[6]) # 'Activity'\n","    print()\n","    '''\n","\n","    A1_graphs_sort = eu.Graphs_sort(A1_vert)\n","    A1_filter = A1_graphs_sort.filter_stop(A1_graphs_sort.data[6])\n","\n","    '''\n","    A1_graphs_sort = Graphs_sort(data)\n","    A1_graphs_sort.filter_stop(A1_graphs_sort.data[])\n","    acc_binary = class_met.accuracy(binary[0])\n","    # header : print(P1_vert[i][0])\n","    print('Accuracy', ' = ', acc_binary)\n","    precision_binary = class_met.precision(binary[2],binary[3]) # tsp fp\n","    print('Precision', ' = ', precision_binary)\n","    print('tsp', ' ', binary[2])\n","    print('fp', ' ', binary[3])\n","    print()\n","    recall_binary = class_met.recall(binary[2],binary[4]) # tsp fn\n","    print('Recall', ' = ', recall_binary)\n","    print('tsp', ' ', binary[2])\n","    print('fp', ' ', binary[3])\n","    print()\n","    f1_score_binary = class_met.f1_score(binary[2],binary[3],binary[4]) # tsp fp fn\n","    print('F1 Score', ' = ', f1_score_binary)\n","    print('tsp', ' ', binary[2])\n","    print('fp', ' ', binary[3])\n","    print('fn', ' ', binary[4])\n","    print()\n","    print()\n","    print()\n","    '''\n","\n","  return\n","\n","def A1_daily_RGB_graph(P1_vert,P1_vert_predictions,A1_vert):\n","  # Edited five days to remove overly detailed entries called 'A1-small.csv'\n","  # original is 'A1.csv' - ['909','910','911','912','913']\n","\n","  A1_Graphs_sort = Graphs_sort(A1_vert)\n","  total_start = 2\n","  day_list = [3,5,7,10,30]\n","  for i in P1_vert[3:]:\n","    reverse_days = A1_Graphs_sort.erroneous_values(i)\n","    if len(reverse_days) > 2:\n","      # Returns 'day_list' before errouneous 'Pain' rows.\n","      A1_frequency_list = A1_Graphs_sort.activity_frequency(total_start,day_list,reverse_days)\n","  A1_mean_list = []\n","  '''\n","  for i in A1_frequency_list:\n","    day_mean = sum(i) / len(i)\n","    A1_mean_list.append(day_mean)\n","  print(A1_mean_list)\n","  '''\n","  return\n","\n","# One month of May, 2024 observations\n","P0_path = \"/content/P0.csv\"\n","B0_path = \"/content/B0.csv\"\n","# A0 is a TSV because there are blank cells\n","A0_path = \"/content/A0.tsv\"\n","P0_unflipped_col = ['ID','Date','Day','Stm']\n","# P0_vert = CSV_running(P0_path,P0_unflipped_col)\n","# B0_vert = CSV_running(B0_path,0)\n","# A0_vert = CSV_running(A0_path,0)\n","# Four months of July-October observations\n","# P1.csv contains the pain scale and B1.csv contains the food records\n","P1_path = \"/content/P1-Observations-PaperFigures.csv\"\n","P1_path_predictions = \"/content/P1-Prediction-PaperFigures.csv\"\n","# B1_path = \"/content/B1.csv\"\n","# A1 is a tsv because of blank cells\n","# A1_path = \"/content/A1.tsv\" # The full dataset.\n","A1_path = \"/content/A1-small.tsv\"\n","# List of columns to not be flipepd\n","P1_unflipped_col = ['ID','Date','Day','Stm','Notes','Notes2']\n","P1_vert = CSV_running(P1_path,P1_unflipped_col)\n","P1_vert_predictions = CSV_running(P1_path_predictions,P1_unflipped_col)\n","# B1_vert = CSV_running(B1_path,0)\n","A1_vert = CSV_running(A1_path,0)\n","\n","# P1_RGB_graph(P1_vert)\n","# B1_RGB_graph(B1_vert)\n","# A0_RGB_graph(A0_vert)\n","# A1_RGB_graph(A1_vert)\n","# P1_Classification_RGB_graph(P1_vert,P1_vert_predictions)\n","A1_daily_RGB_graph(P1_vert,P1_vert_predictions,A1_vert)"],"metadata":{"id":"IxtfVwAjhyaV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1747450759858,"user_tz":300,"elapsed":22,"user":{"displayName":"David Leifer","userId":"06279506333224389759"}},"outputId":"6f49e291-3ace-412d-f226-cc9fae951f60"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["['Stm', 'NA']\n","3 10 13 [3]\n","3 35 38 [3]\n","3 50 53 [2]\n","3 58 61 []\n","5 8 13 [1, 4]\n","5 33 38 [5]\n","5 48 53 [4]\n","5 56 61 []\n","7 6 13 [3, 4]\n","7 31 38 [7]\n","7 46 53 [6]\n","7 54 61 [2]\n","10 3 13 [2, 4, 4]\n","10 28 38 [3, 7]\n","10 43 53 [3, 6]\n","10 51 61 [1, 4]\n","30 8 38 [1, 4, 5, 4, 4, 5, 7]\n","30 23 53 [3, 5, 7, 8, 6]\n","30 31 61 [7, 8, 6, 4]\n","['Qua', 'NA']\n","3 4 7 [1]\n","3 9 12 []\n","3 13 16 []\n","3 16 19 [2]\n","5 2 7 [3]\n","5 7 12 [2]\n","5 11 16 [2]\n","5 14 19 [4]\n","7 0 7 [5]\n","7 5 12 [4]\n","7 9 16 [4]\n","7 12 19 [1, 5]\n","10 2 12 [3, 4]\n","10 6 16 [3, 4]\n","10 9 19 [4, 5]\n","['But', 'NA']\n","3 5 8 []\n","3 6 9 [3]\n","3 7 10 [2]\n","3 10 13 [3]\n","5 3 8 [2]\n","5 4 9 [1, 4]\n","5 5 10 [4]\n","5 8 13 [1, 4]\n","7 1 8 [4]\n","7 2 9 [3, 4]\n","7 3 10 [2, 4]\n","7 6 13 [3, 4]\n","10 0 10 [5, 4]\n","10 3 13 [2, 4, 4]\n","['Gro', 'NA']\n","3 5 8 []\n","3 7 10 [2]\n","3 9 12 []\n","3 13 16 []\n","3 18 21 []\n","5 3 8 [2]\n","5 5 10 [4]\n","5 7 12 [2]\n","5 11 16 [2]\n","5 16 21 [2]\n","7 1 8 [4]\n","7 3 10 [2, 4]\n","7 5 12 [4]\n","7 9 16 [4]\n","7 14 21 [4]\n","10 0 10 [5, 4]\n","10 2 12 [3, 4]\n","10 6 16 [3, 4]\n","10 11 21 [2, 5]\n","['Abs', 'NA']\n","3 37 40 [1]\n","3 50 53 [2]\n","5 35 40 [3]\n","5 48 53 [4]\n","7 33 40 [5]\n","7 46 53 [6]\n","10 30 40 [1, 7]\n","10 43 53 [3, 6]\n","30 10 40 [3, 5, 4, 4, 5, 7]\n","30 23 53 [3, 5, 7, 8, 6]\n","['Nec', 'NA']\n","3 6 9 [3]\n","3 48 51 []\n","5 4 9 [1, 4]\n","5 46 51 []\n","7 2 9 [3, 4]\n","7 44 51 [2]\n","10 41 51 [5]\n","30 21 51 [1, 4, 5, 7, 8]\n","['Hea', 'NA']\n","3 44 47 [2]\n","3 62 65 [1]\n","5 42 47 [4]\n","5 60 65 [3]\n","7 40 47 [6]\n","7 58 65 [5]\n","10 37 47 [1, 8]\n","10 55 65 [1, 7]\n","30 17 47 [1, 4, 4, 5, 7, 8]\n","30 35 65 [3, 8, 6, 4, 7]\n"]}]},{"cell_type":"code","source":["#####|### |a = 'abcdefg'\n","'''\n","for i in range(1,len(a)):\n","  print(a[:i])\n","  print(a[i])\n","  print('zzzzz')\n","\n","  print(a[-1])'''"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"nyadd2nCLeqQ","executionInfo":{"status":"ok","timestamp":1744989152983,"user_tz":300,"elapsed":19,"user":{"displayName":"David Leifer","userId":"06279506333224389759"}},"outputId":"6c2810b5-68e0-40fb-aa98-bf24388e05dc"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"\\nfor i in range(1,len(a)):\\n  print(a[:i])\\n  print(a[i])\\n  print('zzzzz')\\n\\n  print(a[-1])\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":35}]},{"cell_type":"code","source":["abc = [\n","        [[0], ['a']],\n","        [[1], ['b']],\n","        [[2], ['c']],\n","        [[3], ['d']],\n","        [[4], ['e']],\n","        [[5], ['f']],\n","        [[6], ['g']],\n","        [[7], ['h']],\n","        [[8], ['i']],\n","        [[9], ['j']],\n","                      ]\n","# for i in range(10):\n","print(abc[1:2])"],"metadata":{"id":"SLyAYj_xtzdg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1744137032714,"user_tz":300,"elapsed":6,"user":{"displayName":"David Leifer","userId":"06279506333224389759"}},"outputId":"3bb4744a-366f-4183-a0ca-7f695d31af9e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[[1], ['b']]]\n"]}]},{"cell_type":"code","source":["a = '1234'\n","b = '567'\n","c = '89'\n","\n","\n","if len(a) == 4:\n","  end_sub = a[2:]\n","  print(end_sub)\n","\n","if len(b) == 3:\n","  end_sub = b[:1]\n","  print(end_sub)\n","\n","if len(c) == 2:\n","  end_sub = c"],"metadata":{"id":"kti4uK-eVPeZ","executionInfo":{"status":"ok","timestamp":1744769169351,"user_tz":300,"elapsed":9,"user":{"displayName":"David Leifer","userId":"06279506333224389759"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"1c1bc210-f9b0-4b10-b49e-62551d97b986"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["34\n","5\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"bNU5wcEd0AeC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"6wounMFJaZT3"},"execution_count":null,"outputs":[]}]}