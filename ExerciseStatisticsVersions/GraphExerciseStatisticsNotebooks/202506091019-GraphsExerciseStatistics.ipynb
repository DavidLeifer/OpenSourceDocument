{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1fHIWbrpk4NMYcse3Xdkb-S8XiS2pxzJm","timestamp":1721260308720},{"file_id":"1STKhtVVaknUZiohwWLdfyoZ3zg6Veimx","timestamp":1721260179755}],"authorship_tag":"ABX9TyOFQI1nnR3QIQWqbpRp/Kns"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["def todo(self):\n","  # List of primary issues\n","  # todo    description                                   hours   progress      Note\n","  #\n","  # todo0   A01.csv skate, long, downhill, juggling,      83      Completed\n","  #         running mean duration by category.\n","  #\n","  # todo1   A01.csv category by day of the week or        .25     DNF           Hours are spread throughout the day.\n","  #         time of day i.e. morning, afternoon, night\n","  #         or blocks of 3.\n","  #\n","  # todo2   A01.csv nltk the 'Explanation' and 'Notes'                          Word frequency might be useful to find specific muscles.\n","  #         sections? Manual descriptions are already                           Topic analysis is included in 'Activity'. Sentiment analysis is\n","  #         included in the write-up.                                           redundant since 'Notes' is informational and not opinion.\n","  #\n","  # todo3   Another tutorial chapter on merge sort.               TODO\n","  #         Compare with Python's built-in len(),\n","  #         sort(), and replace().\n","  #\n","  # todo4   The graphing part could be included in        .25     DNF           This is a good project to learn syntax and documentation since it's visual.\n","  #         Chapter 1 with pandas and SciPy.\n","  #\n","  # todo5   A01.csv longboard and running distance.       .5      DNF           Running occured around 5 times and longboarding was recorded with time.\n","  #\n","  #\n","  # todo6   P0P1B0B1.csv timeseries graphing.             45.5    Completed\n","  #\n","  # todo7   P1.csv manual vs observed prediction          33.5    Processing    Graph reverse time. Wilcoxon statistical test to compare\n","  #         accuracy F1.                                                        frequency target mean with total mean. Graph prediction, observation with\n","  #                                                                             precision, recall, F1 score.\n","  #\n","  # todo8   B01.csv Pearson-Correlation and day-          2       Completed     Found that there was not correlation between parametric variables.\n","  #         delayed between calories, alcohol, exercise.                        An index similar to ENSO is redundant since there were no consecutive\n","  #                                                                             observations over 4 alcohol or excessive (calorie - calorie burned).\n","  #\n","  # todo9   A01P01B01 moving window spearman              .5      DNF           Would have to sort these for rank, which was completed in todo0.\n","  #         correlation between activity, duration,                             Square the difference between each numbers rank and sum all the numbers,\n","  #         time of day, pain, nutrients,                                       multiply by 6, divide by (number times (number squared minus one).\n","  #         calories, alcohol.                                                  1 - calculated number.\n","  #\n","  # todo10  tbd data filling and automatic predictions.   0       DNF\n","  #         idk if thats another chapter or avoided.\n","  #\n","  # todo11  Manual weather observations and PRISM data    0       DNF\n","  #         will be in a different GitHub to avoid\n","  #         confusion.\n","  #\n","  # Time spent at a computer programming\n","  # Total estimate  :\n","  # Total actual    :\n","  #\n","  # Purpose\n","  # The goal of writing this is to waste as much time as possible in between\n","  # exercise to avoid overtraining while retaining logical thought process\n","  # during long stretches of unemployment. These were written on a computer\n","  # with a 1.5-2 hour battery to restrict excessive\n","  # programming by limiting hardware access.\n","  #\n","  # Abstract\n","  # Python with C-like syntax is used for data manipulation and\n","  # graphing arrays are handled without dictionaries. The only\n","  # library used is Matplotlib for RGB graphing and to avoid writing a image or\n","  # video format that would likely spread misinformation. An implementation of\n","  # the merge sort algorithm was used to alphabetize exercise activity for\n","  # binning and graphing frequency by unique type. The built-in Python methods\n","  # for 'replace', 'split', 'len', and 'sort' were manually written for\n","  # learning purposes.\n","\n","  # Start date: 20250125\n","  # End date:\n","\n","  # Below is an exhaustive list of secondary issues.\n","\n","  # List of secondary issues\n","  # todo   description                                                  progress\n","  # todo0  rewrite parser for unicode csv str/int.\n","  # todo1  Stats class avoid NA, NAAN, -9999, etc.\n","  # todo2  refractor RGB_graphs.\n","  # todo3  monthly means on bar graphs.\n","  # todo4  organize merge_sort into another classe.                     Complete\n","  # todo5  modify merge sort to accept entire CSV.                      Class\n","  # todo6  Handle multi word activity descriptions consistently.        Class\n","  # todo7  switch the second capital letter to lower case if exists.    Class\n","  # todo8  unchain the four merge sort functions.                       Class\n","\n","  return\n","\n","# import sys\n","# for path in sys.path:\n","#   print(path)\n","import matplotlib\n","import matplotlib.pyplot as plt\n","import exercise_module as eu\n","# eu.test_function()\n","# print(sys.version)\n","# 3.10.12 (main, Mar 22 2024, 16:50:05) [GCC 11.4.0]\n","# 3.11.11 (main, Dec  4 2024, 08:55:07) [GCC 11.4.0]\n","\n","# In development.\n","###############################################\n","# Part D: Data visualization with a RGB graph #\n","###############################################\n","# Matplotlib for color because otherwise you would have\n","# to write hardware code to avoid using Python or C libraries.\n","\n","class Graphs_rgb: # 'Graphs_rgb_dev()' in 'exercise_module.py'\n","  # Initialize the input variables\n","  def __init__(self, data):\n","    self.data = data\n","\n","  # Todo sort by observation def rgb_reverse_mean(self,mean_data)\n","  def rgb_reverse_category(self,data,mean_data):\n","    # category = data[0][0]\n","    # category_day = data[0][1]\n","    # category_value = data[0][2]\n","    print(data)\n","    print(mean_data)\n","    '''\n","    # from 202505130912-GraphsExerciseStatistics.ipynb\n","    x = [data[0][3],data[0][3],\n","         data[0][3],data[0][3],\n","         ...n]\n","    y = [data[0][4],data[0][5],\n","         data[1][4],data[1][5],\n","         ...n]\n","    '''\n","\n","    # 'category (list)', 'Date A1_ver[3]', 'abbreviated category P1_vert', 'P1 day_id', 'target_mean or average frequency by day for all days',\n","    # 'activity_frequency_mean or average frequency by day for the days [3,5,7,...n] before pain'\n","\n","    # fig, ax = plt.subplots(figsize=(5, 5))\n","    # plt.ylim(4,8)\n","    '''\n","    for i in range(len(data)):\n","      # Title is the body area.\n","      title_full = ['','','',\n","        'Stamina',\n","        'Feet','Ankle','Calves',\n","        'Knees','Quadriceps','Gluteus','Groin',\n","        'Abdominals','Lower Back',\n","        'Latissimus Dorsi','Trapezius','Shoulders',\n","        'Chest','Triceps','Biceps',\n","        'Neck','Head']\n","\n","      x =                     # day_list = [3,5,7,10,30] day period\n","      y =                     # number of activities in a [3,5,7,10,30] day period for abnormal pain values\n","      # z =                   # average number of activities in a [3,5,7,10,30] day period regardless of score    <-- calculate this value\n","      # z2 =                  # average number of activities in a [3,5,7,10,30] day period for not painful values\n","      count += 1\n","\n","      x = data[i][1] #,data[i][1] # the number of reverse days [3,5,7,...n]\n","      if data[i][4] > data[i][5]:\n","        marker_value = '+'\n","      elif data[i][5] > data[i][4]:\n","        marker_value = '_'\n","      else:\n","        marker_value = 'o'\n","      plot = ax.plot(x,y, marker=marker_value, linestyle='--')\n","\n","\n","    # reformat category, include 'category_value',\n","    # recall, F1 scores with the prediction and actual value\n","    # in a text box.\n","    plt.title(\"Previous Day's Frequency\\nfor \" + category + \", July-October, 2024\", # pad=50,\n","              fontsize=12)\n","    plt.xticks(x_axis)\n","    plt.xlabel(\"Number of days before \" + category_day, fontsize=10)\n","    plt.ylabel('Previous Frequency Mean', fontsize=10)\n","    # ax.tick_params(axis='y', pad=50, labelsize=14)\n","    # ax.xaxis.set_ticks_position('top')\n","    # ax.xaxis.set_label_position('top')\n","    # plt.yticks(x, labels=x, ha='center')\n","    plt.grid()\n","    plt.margins(y=0.01)\n","    # plt.savefig('P1-0 Activity Frequency Mean July-October, 2024' + '.jpg')\n","    '''\n","    return\n","\n","  def rgb_reverse_mean(self,mean_data):\n","    # Uses the 'splice_list' contained in 'mean_data[1]' calculated from\n","    # Graph_sort.mean_reverse_day() to graph each frequency along with\n","    # the mean frequency of each day group in 'mean_data[0]'.\n","\n","    # 'x' number of days in reverse, 'y' number of activities before pain.\n","    # x = [i[1] for i in self.data]\n","    y = []\n","    for i in range(len(mean_data[1])):\n","      if i == (len(mean_data[1])-1):\n","        break\n","      # Splicing at the days in reverse [3,5,7..etc] based on 'mean_data'.\n","      start = mean_data[1][i]\n","      end = mean_data[1][i+1]\n","      data_slice = self.data[start:end]\n","      y_subset = [j[6] for j in data_slice]\n","      y.append(y_subset)\n","    x = [k[0] for k in mean_data[0]]\n","    fig, ax = plt.subplots(figsize=(5, 5))\n","    # plt.ylim(4,8)\n","    # plot_0 = ax.scatter(x,y)\n","    # plot = plt.box(x,y)\n","    bplot = ax.boxplot(y,\n","                      # patch_artist=True,  # fill with color\n","                      tick_labels=x,\n","                      showmeans=True, meanprops={'label': 'Mean', 'alpha':0})\n","    # Add text box for mean\n","    z = [round(k[1],2) for k in mean_data[0]]\n","    for iter, mean_val in enumerate(bplot[\"means\"]):\n","        mean = mean_val.get_ydata()[0]\n","        if mean > 170:\n","          bx_pos = iter + .35\n","          by_pos = mean - 10\n","        else:\n","          bx_pos = iter + 1.5\n","          by_pos = mean + 1.75\n","        # 'mean' and 'z[iter]' are the same but 'z[iter]' was calculated by Graph_sort()\n","        # while 'mean' is calculated by Matplotlib 'bplot' graph.\n","        # The goal is to modify Graph_sort() to get the mean values before regular\n","        # days or days without pain to side by side compare in 'mean_str'.\n","        # mean_str = 'Mean\\n-No pain: ', str(mean), '\\n-Before pain: ', str(z[iter])\n","\n","        mean_str = round(z[iter],2)\n","        ax.text(\n","            bx_pos,\n","            by_pos,\n","            mean_str,\n","            ha=\"center\",\n","            va=\"bottom\",\n","            size=8,\n","            bbox=dict(facecolor=\"white\", edgecolor=\"black\", boxstyle=\"round\", alpha=0.75),\n","        )\n","\n","    # recall, F1 scores with the prediction and actual value\n","    # in a text box.\n","    plt.title(\"Previous Day's Frequency July-October, 2024\", # pad=50,\n","              fontsize=12)\n","    # plt.xticks(x_axis)\n","    plt.xlabel(\"Days before pain\", fontsize=10)\n","    plt.ylabel('Activity count', fontsize=10)\n","    # ax.tick_params(axis='y', pad=50, labelsize=14)\n","    # ax.xaxis.set_ticks_position('top')\n","    # ax.xaxis.set_label_position('top')\n","    # plt.yticks(x, labels=x, ha='center')\n","\n","    plt.grid()\n","    plt.margins(y=0.01)\n","    # plt.savefig('P1-0 Activity Frequency Mean July-October, 2024' + '.jpg')\n","    '''\n","    if data[i][4] > data[i][5]:\n","      marker_value = '+'\n","    elif data[i][5] > data[i][4]:\n","      marker_value = '_'\n","    else:\n","      marker_value = 'o'\n","    plot = ax.plot(x,y, marker=marker_value, linestyle='--')\n","\n","    '''\n","    return\n","\n","  # Graph prediction and observation for the P1.csv pain charts with\n","  # accuracy, precision, recall, and f1 score in a text box.\n","  def rgb_class_metrics(self,data):\n","    return\n","\n","# In development.\n","#################################################\n","# Part E: Part D visualization helper functions #\n","#################################################\n","# Merge sort is the fastest for worst case scenario sorting: N log(n)\n","# Implementation is from W3 and modified for AZ with ascii ord():\n","# https://www.w3schools.com/dsa/dsa_algo_mergesort.php\n","# Bubble sort is the fastest for almost sorted lists O(n)\n","# https://www.w3schools.com/dsa/dsa_timecomplexity_bblsort.php\n","# Python's built-in sort() function uses Tim Sort which uses a hybrid\n","# Insertion and Merge. Insertion is similar to Bubble with the same\n","# Time and Space complexity with worst case O(n^2) and best O(n).\n","class Graphs_sort:\n","  # Initialize the input variables\n","  def __init__(self, data):\n","    self.data = data\n","\n","  # Returns the abnormal pain entry.\n","  def erroneous_values(self,P1_vert_column):\n","    erroneous_values = [[P1_vert_column[0],'NA']]\n","    non_erroneous_values = [[P1_vert_column[0],'NA']]\n","    for i in range(len(P1_vert_column)):\n","      if len(P1_vert_column[i]) > 1:\n","        continue\n","      # Not stamina and greater than 4 pain values and 'Day_ID' get sent\n","      # to the list of lists.\n","      if P1_vert_column[0] != 'Stm' and int(P1_vert_column[i]) > 3:\n","        erroneous_values.append([P1_vert_column[i], i-1])\n","      # If it is stamina, check for values 2 and less.\n","      elif P1_vert_column[0] == 'Stm' and int(P1_vert_column[i]) < 3:\n","        erroneous_values.append([P1_vert_column[i], i-1])\n","      else:\n","        non_erroneous_values.append([P1_vert_column[i], i-1])\n","    return [erroneous_values,non_erroneous_values]\n","\n","  # The first method looks like a giant waste of time but the details of Tim sort were\n","  # revealed that combines insert (bubble in this case) and merge sort depending on the\n","  # length of the list since small lists perform similar regardless of if bubble or merge\n","  # sort are used.\n","  '''\n","  class TimSort:\n","    # Sorts a list using bubble sort.\n","    def bubble_sort(self,list0,count):\n","      list0_len = len(list0)\n","      for i in range(list0_len-1):\n","        swapped = False\n","        for j in range(list0_len-i-1):\n","          if list0[j][2] > list0[j+1][2]:\n","            list0[j], list0[j+1] = list0[j+1], list0[j]\n","            swapped = True\n","            count += 1\n","        if not swapped:\n","          break\n","      return [list0, count]\n","\n","    # Returns abnormal pain or stamina day with reverse days.\n","    def day_ID_range(self,day_list,reverse_days):\n","      # minus the number of days of interest [30,10,7,5,3 ... n].\n","      header = reverse_days[0]\n","      day_start_end = [['minus_one',-1,-1,-1]]\n","      # The range of 'Day_ID' adding the frequency for [30,10,7,5,3 ... n] for each\n","      # successive 'reverse_days' then skip those 30 for the total frequency.\n","      for day in day_list:\n","        # Skips the header.\n","        for reverse in range(1,len(reverse_days)):\n","          # Check if there are enough days to reverse.\n","          day_start = reverse_days[reverse][1] - day\n","          if day_start > -1:\n","            day_end = reverse_days[reverse][1]\n","            day_start_end.append([header[0],day,day_start,day_end])\n","      return day_start_end\n","\n","    # The main function is to return the number of activities before a day with erroneous pain.\n","    # Returns: 'Body_Part', 'Days_reverse', 'Day_ID_start', 'Day_ID_end', 'Time_ID_start' (or 'count_0'), 'Time_ID_end' (or 'count_1'), 'time_difference', 'id'\n","    def dayid_2_timeid(self,ordered_days_bubble):\n","      # Calculates activity frequencies before the erroneous pain value by converting\n","      # the P1.csv 'Day_ID' (0-99 rows) 'start' and 'end' (contained in\n","      # ordered_days_bubble[0]) to A1.csv 'Time_ID' (0-525 from self.data[0])).\n","      # Returns the difference between start and end.\n","\n","      # Worst case is len(ordered_days_bubble[0]),len(self.data[0]) or 102 X 525 = ~53,000.\n","      # This method is increments the second loop to the 'start' called\n","      # ordered_days_bubble[0][i][2]. Since ordered_days_bubble[0] is already\n","      # sorted, it avoids looping through the entire 525 rows in A1.csv len(self.data[0])\n","      # and reduces iterations to ~13,000.\n","      counter = 0\n","      activity_frequency_list = []\n","      # Skipping the first 7 values is hardcoded because they are boilerplate\n","      # returns from a previous function. A more elegant solution is an 'if value == -1'.\n","      for i in range(7,len(ordered_days_bubble[0])):\n","        for j in range(ordered_days_bubble[0][i][2],len(self.data[0])):\n","          # Found the start value, 'count_0' is set to 'j'.\n","          if str(self.data[0][j]) == str(ordered_days_bubble[0][i][2]): # str, int\n","\n","            # The goal is to find 'activity' frequency of overlapping ranges to avoid\n","            # looping over each range and each day as a different number of activities.\n","            # i.e. [start:end] = [0:7], [3:10] shares the values [3:7], the counter already\n","            # knows the number of activity values for [3:7] is 5 so it only loops over\n","            # [0:2] equals 2 and [8:10] equals 3.\n","\n","            # These if/else reduce the iterations to 12,374 and you could reduce by\n","            # another few hundred by using greater than the 'start' and same as the 'end'\n","            # but is redundant.\n","            if ordered_days_bubble[0][i][2] == ordered_days_bubble[0][i-1][2]:\n","              # The erroneous values occured on the same day, the start and end are\n","              # the same, use the alrady calculated frequency and break the iteration.\n","              if ordered_days_bubble[0][i][3] == ordered_days_bubble[0][i-1][3]:\n","                # print('Same')\n","                # print('No calculation needed: ', ordered_days_bubble[0][i-1][2], ':', ordered_days_bubble[0][i-1][3])\n","                # print(ordered_days_bubble[0][i],ordered_days_bubble[0][i-1])\n","                # print(i,i-1)\n","                count_0 = count_0\n","                count_1 = count_1\n","                break\n","              # If the previous days 'end' is less than the current days 'end'\n","              # add it onto the already calculated frequency.\n","              elif ordered_days_bubble[0][i-1][3] < ordered_days_bubble[0][i][3]:\n","                # print('End is less than')\n","                # print('Already know this one: ', ordered_days_bubble[0][i-1][2], ':', ordered_days_bubble[0][i-1][3])\n","                # The start is the same as the previous one.\n","                count_0 = count_0\n","                # print('Trying to get this frequency: ', ordered_days_bubble[0][i][2], ':', ordered_days_bubble[0][i][3])\n","                # print('Calculate by adding this range onto the already known: ', ordered_days_bubble[0][i-1][3], ':', ordered_days_bubble[0][i][3])\n","                # print(ordered_days_bubble[0][i],ordered_days_bubble[0][i-1])\n","                # print(i,i-1)\n","                count_1_end = 0\n","                # Calculate the additional frequency.\n","                for k in range(count_1, len(self.data[0])):\n","                  count_1_end += 1\n","                  # When the range between the previous 'end' and the new 'end\n","                  # are the same, that is the additional frequencies and add\n","                  # it onto the already known frequency which has the same start.\n","                  # print(self.data[0][k],ordered_days_bubble[0][i][3])\n","                  counter += 1\n","                  if str(self.data[0][k]) == str(ordered_days_bubble[0][i][3]):\n","                    count_1 = count_1 + count_1_end - 1\n","                    break\n","                break\n","              # If the previous days 'end' is greater than the current days 'end'\n","              # add it onto the already calculated frequency.\n","              #else:\n","                # You have to calculate the frequency as normal.\n","                #print('Greater, doesnt help. Have to calculate range.')\n","            else:\n","              count_0 = j\n","\n","          # Found the 'end' value, 'count_1' is set to 'j' minus 1.\n","          if str(self.data[0][j]) == str(ordered_days_bubble[0][i][3]): # str, int\n","            count_1 = j\n","            # Breaks the loop and starts a new one at the next 'start' value at\n","            # ordered_days_bubble[0][i][2] avoiding unneccessary iterations.\n","            break\n","          # 'counter' is incremented for performance evaluations.\n","          counter += 1\n","        # 'count_0' through 'count_1' is A1.csv 'start' and 'end'.\n","        # print(ordered_days_bubble[0][i])\n","        # print(count_0, ':', count_1)\n","        # These are the original P1.csv 'Day_ID'.\n","        # print(self.data[0][count_0], ' : ', self.data[0][count_1])\n","        # A1.csv 'count_0' and 'count_1' are the start and end 'Time_ID'\n","        # similar to P1.csv 'Day_ID'. 'activity_frequency' is the difference\n","        # between 'count_1' and 'count_0'.\n","        time_difference = count_1 - count_0\n","        ordered_days_bubble[0][i].append(count_0)\n","        ordered_days_bubble[0][i].append(count_1)\n","        ordered_days_bubble[0][i].append(time_difference)\n","        activity_frequency_list.append(ordered_days_bubble[0][i])\n","      # print(counter)\n","      # print(len(ordered_days_bubble[0]),len(self.data[0]))\n","      return activity_frequency_list\n","\n","    # Function to find the mean of each painful day group.\n","    def mean_reverse_days(self,frequency_day_sort):\n","      # The loop requires a boilerplate value to complete all iterations.\n","      frequency_day_sort.append(['z',0,0,0,0,0,0])\n","      # print(frequency_day_sort[0],0)\n","      # The sum and count starts at the first value, otherwise it's not included.\n","      frequency_sum = frequency_day_sort[0][6]\n","      frequency_count = 1\n","      mean_list = []\n","      splice_list = [0]\n","      # Find the mean of each day before the pain.\n","      for j in range(len(frequency_day_sort)):\n","        # Skip the last value\n","        if frequency_day_sort[j-1] == frequency_day_sort[-1]:\n","          continue\n","        # If the reverse day column is different than the previous, calculate the mean.\n","        elif frequency_day_sort[j-1][1] != frequency_day_sort[j][1]:\n","          splice_list.append(j)\n","          frequency_mean = round(frequency_sum / frequency_count,2)\n","          mean_list.append([frequency_day_sort[j-1][1],frequency_mean])\n","          # print(frequency_sum, frequency_count, frequency_mean)\n","          # print()\n","          # print(frequency_day_sort[j],j)\n","          # Reset the 'frequency_sum' and 'frequency_count' to the current value.\n","          frequency_sum = frequency_day_sort[j][6]\n","          frequency_count = 1\n","        # If the reverse days are the same, increment\n","        # the 'frequency_sum' and 'frequency_count'.\n","        elif frequency_day_sort[j-1][1] == frequency_day_sort[j][1]:\n","          # print(frequency_day_sort[j],j)\n","          frequency_sum += frequency_day_sort[j][6]\n","          frequency_count += 1\n","      return [mean_list,splice_list]\n","\n","  '''\n","  # Calculates the activity frequency for each day in ~ 500 iterations.\n","  # Returns 'Day_ID', 'start', and 'end' for splicing in 'activity_reverse()'.\n","  def activity_frequency(self):\n","    # Skips the first ten values, 'Day_ID' is '10' in P1.csv and\n","    # 'start' is the 'Time_ID' in A1.tsv. The first 10 days are discarded\n","    # because they are why the information was collected.\n","    start = 53\n","    activity_frequency = []\n","    # The 'data' is from the function's class and needs a boilerplate\n","    # value appended to return the entire length of the 'data' list.\n","    data = self.data[0]\n","    data.append('100')\n","    for i in range(start,len(data)):\n","      # Checks 'Day_ID' P1.csv against 'Time_ID' from A1.tsv.\n","      # If 'Day_ID' is not '' or the values in A1.tsv,\n","      # they must by an integer (as long as the first value\n","      # header 'Day_ID' is ignored).\n","      if len(data[i]) > 0:\n","        day_id = int(data[i])\n","        activity_frequency.append([day_id-1, start, i])\n","        # 'start' is set to the 'i' or the iterator, which resumes checking\n","        # the length of A1.tsv.\n","        start = i\n","    # Deletes the null first value.\n","    del activity_frequency[0]\n","    return activity_frequency\n","\n","  # Function to find the number of activities [30,10,7,5,3] and\n","  # returns the difference and number of days.\n","  def activity_reverse(self,day_id,activity_frequency):\n","    print(day_id)\n","    print(activity_frequency)\n","    print()\n","    print()\n","    counter = 0\n","    for i in range(len(day_id)):\n","      if type(day_id[i][1]) == str:\n","        category = day_id[i][0] # the category\n","      elif type(day_id[i][1]) == int:\n","        if day_id[i][1] > 9:\n","          # The number of days in reverse.\n","          reverse_days = [3,5,7,10,30]\n","          # 'Day_ID' ignores the first 10 days by subtracting 10 from 'start' and 'end'.\n","          known_ID = 0\n","          activity_by_category = []\n","          for k in range(len(reverse_days)):\n","            start = day_id[i][1] - reverse_days[k]\n","            end = day_id[i][1] - known_ID\n","            print('start: ', start, ' = ', day_id[i][1], ' - ', reverse_days[k])\n","            print('end: ', end, ' = ', day_id[i][1], ' - ', known_ID)\n","            # Avoids calculating frequencies for the first 10 days.\n","            if start > 9:\n","              # The number of activities 'reverse_days[k]' from the pain observation.\n","              activity_total = 0\n","              for j in range(start-10,end-10):\n","                # Summation for the number of activities, 'reverse_days' (k) from pain observation.\n","                activity_difference = activity_frequency[j][2] - activity_frequency[j][1]\n","                print('Activity calculating : ', activity_difference, ' = ', activity_frequency[j][2], ' - ', activity_frequency[j][1])\n","                activity_total += activity_difference\n","                counter += 1\n","              print('Activity Subset = ', activity_total)\n","              # 'known_ID' is used to avoid calculating frequencies that are already known.\n","              known_ID += reverse_days[k]\n","              # If 'k' is greater than '0', the previous day range frequency difference\n","              # was already calcualted and is used to calculate the frequency, reducing\n","              # unnecessary iterations. If 'reverse_days[k]' is '5' the frequency is already\n","              # known for '3', the difference for days '4' and '5' are calculated and added\n","              # onto 'activity_previous'.\n","              if k > 0:\n","                activity_previous = activity_intermediate + activity_total\n","              else:\n","                activity_previous = activity_total\n","              # The previous total is held for the next iteration.\n","              print('Activity Total = ', activity_previous)\n","              activity_intermediate = activity_previous\n","              activity_by_category.append([category,day_id[i][1],reverse_days[k],activity_previous])\n","          print()\n","    print(counter) # ~472 iterations without skips or 258 with skipping already calculated differences.\n","    return\n","\n","#################################################\n","# Part F: Non-parametric Classification Metrics #\n","#################################################\n","# Inputs are observations and prediction columns.\n","# Assumes input has a header.\n","class classification_metrics:\n","  # true_positive  = true_positive   1  (true_positive 1 / true_positive 1 + fn4) or recall\n","  # true_negative  = true_negative   0  (true_negative 0 / true_negative 0 + false_positive 3)\n","  # false_positive = false_positive  3  predicted soreness, was not sore.\n","  #                                     false positive rate = false_positive 3 / false_positive 3 + true_negative 0\n","  # false_negative = false_negative  4  predicted not soreness, was sore\n","  # https://www.geeksforgeeks.org/metrics-for-machine-learning-model/#regression-evaluation-metrics\n","  # https://developers.google.com/machine-learning/crash-course/classification/accuracy-precision-recall\n","  '''\n","  print(P1_vert[0])\n","  print(P1_vert[1])\n","  print(P1_vert[2])\n","  # 0 6 7 8\n","  print(A1_vert[0]) # Day_ID\n","  print(A1_vert[6]) # Activity\n","  # print(A1_vert[7]) # Notes\n","  # print(A1_vert[8]) # Explaination\n","  '''\n","  def __init__(self,observations,predictions):\n","    # The input scale is 5-1 high pain to low pain (or stamina).\n","    # The original data was 1-5 high pain to low pain and was flipped\n","    # since it was confusing (except for stamina).\n","    self.observations = observations\n","    self.predictions = predictions\n","\n","  def binary_classification(self):\n","    # Returns 0 (True Negative) 1 (True Positive) if prediction\n","    # matches observation. False Positive when prediction was soreness\n","    # and observation was no soreness (3). False Negative when the prediction\n","    # was no soreness and there was soreness (4).\n","    # Also returns the count for the classifications.\n","    true_negative = 0\n","    true_positive = 0\n","    false_positive = 0\n","    false_negative = 0\n","    binary = []\n","    for i in range(1,len(self.observations)):\n","      if self.observations[i] == self.predictions[i]:\n","        result = 1\n","        true_positive += 1\n","      else:\n","        if self.predictions[i] == 'NA' or self.observations[i] == 'NA':\n","          result = 0\n","        # False positive predicted 4 or 5 (high soreness) and was 1,2,3.\n","        elif int(self.predictions[i]) > 3 and int(self.observations[i]) <= 3:\n","          result = 3\n","          false_positive += 1\n","        # False negative predicted 1,2,3 (low soreness) and was 4 or 5.\n","        elif int(self.predictions[i]) <= 3 and int(self.observations[i]) > 3:\n","          result = 4\n","          false_negative += 1\n","        else:\n","          result = 0\n","          true_negative += 1\n","      binary.append(result)\n","    return [binary,true_negative,true_positive,false_positive,false_negative]\n","\n","  def accuracy(self,binary):\n","    # Number of correct predictions / total, input is False/True 0/1.\n","    count = 0\n","    for i in binary:\n","      if i == 1:\n","        count += 1\n","    total = len(binary)\n","    result = count / total\n","    return result\n","\n","  def precision(self,true_positive,false_positive):\n","    # precision = true_positive 1 / (true_positive 1 + false_positive 3)\n","    result = true_positive / (true_positive + false_positive)\n","    return result\n","\n","  def recall(self,true_positive,false_negative):\n","    # (true_positive / true_positive + false_negative 4) or recall\n","    result = true_positive / (true_positive + false_negative)\n","    return result\n","\n","  def f1_score(self,true_positive,false_positive,false_negative):\n","    # 2 * (precision * recall) / (precision + recall)\n","    # (2 true_positive) / (2 true_positive + false_positive 3 + false_negative)\n","    result = (2 * true_positive) / ((2*true_positive) + false_positive + false_negative)\n","    return result\n","\n","  # After the previous n (10,7,5,3) days of activity frequency, use the non parametric\n","  # Wilcoxon's rank sum test to compare the two dependent or paired samples. The two\n","  # samples being compared are n days activity frequency with the entire dataset's activity\n","  # frequency. It is non-parametric because it is categorical or ordinal dataset and\n","  # not real world measurements, despite having over 30 observations.\n","  # https://www.stat.purdue.edu/~tqin/system101/method/method_wilcoxon_rank_sum_sas.htm\n","  # https://pmc.ncbi.nlm.nih.gov/articles/PMC4754273/\n","  def wilcoxon_rank_sum(self):\n","    return\n","\n","##############################################################################\n","# Part Z: Run the functions                                                  #\n","##############################################################################\n","\n","# Part A: The path of the CSV to be parsed\n","def CSV_running(path,unflipped_col):\n","  # Create the CSV_Parser class object and open the files\n","  parser = eu.CSV_Parser(path)\n","  read = parser.file_opener()\n","  # Index the comma position from the CSV and split the characters into their values\n","  comma_indexed = parser.comma_index(read, path, 0)\n","  # Get the width of columns of the commas\n","  comma_width = parser.comma_index(read, path, 1)\n","  # Sort the list into verticle columns\n","  # The P0 csv gets flipped, except for the Stm column\n","  # Divide by two - the list of comma places is doubled for the start/end value\n","  col_width = int(((comma_width - 1 ) / 2) - 1)\n","  vert = []\n","  for i in range(0,comma_width-1,2):\n","    value_list = parser.csv_value_list(comma_indexed, read, col_width, i)\n","    if unflipped_col == 0:\n","      vert.append(value_list)\n","    else:\n","      if value_list[0] in unflipped_col:\n","        vert.append(value_list)\n","      else:\n","        flip = parser.csv_flipper(value_list, col_width)\n","        vert.append(flip)\n","  return vert\n","\n","# Part F: Predictions vs Observed pain values using classification metrics.\n","def P1_Classification_RGB_graph(P1_vert,P1_vert_predictions):\n","\n","  # B1.csv - Nutrition - binary calories high and low -> above/below 2500\n","  # - Mean number of activities per day over 3-14 days\n","  #     - Exclude 09/09-09/13 since it was recorded with excessive detail.\n","  # - Not stretching in the one or two days afterward.\n","  # - Stretching too frequently in the one or two days afterward.\n","\n","  # Days of Interest :\n","  # Stamina for 08/27-0903 (value 4) except 08/29 (value 2) and abs (4) on 08/31.\n","      # Stamina for 09/13. Exclude 09/09-09/13 since it was recorded with excessive detail.\n","  # Stamina for 09/19-09/22 (value 4) except 09/21 (value 2).\n","  # The goal is to find an appropriate balance for exercise and not moving\n","  # by examining the frequency of Activities before these decreases.\n","\n","  # 'Day_ID' remove 49-53 for average graphing because they were recorded\n","  # differently and induce outliers. ['909','910','911','912','913']\n","  for P1 in range(len(P1_vert_predictions)):\n","    del P1_vert_predictions[P1][50:55]\n","    del P1_vert[P1][50:55]\n","  # Remove these dates: ['909','910','911','912','913']\n","  # in A1_vert[0], A1_vert[3]\n","  del A1_vert[0][271:326]\n","  del A1_vert[3][271:326]\n","  # Accuracy, Precision, Recall, F1\n","  # Uses F1 since RMSE is for regression prediction models. The pain scale\n","  # is numerical and is equivilent to nominal categories.\n","  title_full = ['','','',\n","  'Stamina',\n","  'Feet','Ankle','Calves',\n","  'Knees','Quadriceps','Gluteus','Groin',\n","  'Abdominals','Lower Back',\n","  'Latissimus Dorsi','Trapezius','Shoulders',\n","  'Chest','Triceps','Biceps',\n","  'Neck','Head']\n","  # todo classification_metrics\n","  # wilcoxon_rank_sum\n","  for i in range(3,len(P1_vert)):\n","    '''\n","    print('Pain Scale')\n","    print(P1_vert[i])\n","    print('Classification')\n","    class_met = classification_metrics(P1_vert[i],P1_vert_predictions[i])\n","    binary = class_met.binary_classification()\n","    print(binary[0])\n","    print()\n","    # i is the pain scale 'Day_ID' (1-101) for A1 (1-350ish) 'did'\n","    print(A1_vert[0]) # 'Day_ID\n","    print(A1_vert[1])\n","    print(A1_vert[6]) # 'Activity'\n","    print()\n","    '''\n","\n","    A1_graphs_sort = eu.Graphs_sort(A1_vert)\n","    A1_filter = A1_graphs_sort.filter_stop(A1_graphs_sort.data[6])\n","\n","    '''\n","    A1_graphs_sort = Graphs_sort(data)\n","    A1_graphs_sort.filter_stop(A1_graphs_sort.data[])\n","    acc_binary = class_met.accuracy(binary[0])\n","    # header : print(P1_vert[i][0])\n","    print('Accuracy', ' = ', acc_binary)\n","    precision_binary = class_met.precision(binary[2],binary[3]) # tsp fp\n","    print('Precision', ' = ', precision_binary)\n","    print('tsp', ' ', binary[2])\n","    print('fp', ' ', binary[3])\n","    print()\n","    recall_binary = class_met.recall(binary[2],binary[4]) # tsp fn\n","    print('Recall', ' = ', recall_binary)\n","    print('tsp', ' ', binary[2])\n","    print('fp', ' ', binary[3])\n","    print()\n","    f1_score_binary = class_met.f1_score(binary[2],binary[3],binary[4]) # tsp fp fn\n","    print('F1 Score', ' = ', f1_score_binary)\n","    print('tsp', ' ', binary[2])\n","    print('fp', ' ', binary[3])\n","    print('fn', ' ', binary[4])\n","    print()\n","    print()\n","    print()\n","    '''\n","\n","  return\n","\n","def A1_daily_RGB_graph(P1_vert,P1_vert_predictions,A1_vert):\n","  # Edited five days to remove overly detailed entries called 'A1-small.csv'\n","  # original is 'A1.csv' - ['909','910','911','912','913']\n","\n","  A1_Graphs_sort = Graphs_sort(A1_vert)\n","  # Attempting to save time in calculating frequency of activiites before\n","  # the erroneous value observation.\n","  # day_list = [3,5,7,10,30]\n","  day_list = [30,10,7,5,3]\n","  count = 0\n","  days_pain = []\n","  days_not_pain = []\n","\n","  # Loop returns the bodily part, number of days, and erroneous pain or\n","  # stamina values start and end from the erroneous observation minus\n","  # number of days.\n","  for i in P1_vert[3:]:\n","    reverse_days = A1_Graphs_sort.erroneous_values(i)\n","\n","    if len(reverse_days[0]) > 2:\n","      days_pain += reverse_days[0]\n","      days_not_pain += reverse_days[1]\n","\n","      '''\n","      # Returns 'day_list' before errouneous 'Pain' rows.\n","      A1_frequency_list = A1_Graphs_sort.day_ID_range(day_list,reverse_days[0])\n","      # Reverse by the group [n...,7,5,3] to [3,5,7...n].\n","      A1_frequency_group_sort = sorted(A1_frequency_list, key=lambda x: x[1])\n","      # Sort the categories by the day.\n","      A1_frequency_category_sort = sorted(A1_frequency_group_sort, key=lambda x: x[3])\n","      ordered_days_pain += A1_frequency_category_sort[1:]\n","  # overly complicated activity frequency finder.\n","  for a in aaa:\n","        # Sorts the list for 'start' using bubble sort since it's already almost sorted.\n","        day_bubble = A1_Graphs_sort.bubble_sort(A1_frequency_list[0],A1_frequency_list[1])\n","        # day_bubble = sorted(A1_frequency_list[0], key=lambda x: x[2])\n","        ordered_days_pain += day_bubble[0]\n","        count += day_bubble[1]\n","\n","    # Sorts each category using 'start'. Built-in 'sorted()' does the same thing.\n","    # ordered_days = sorted(ordered_days, key=lambda x: x[2])\n","    ordered_days_bubble = A1_Graphs_sort.bubble_sort(ordered_days_pain,count)\n","    # Python sort is nearly identical to Bubble Sort (or Insertion) in this case.\n","    # The lists already almost sorted and those algorithms are O(n) in best case\n","    # and uses less space than merge sort with O(1) vs O(n). At 10,000,000,000\n","    # 'activities', run time is around 35 hours.\n","\n","    # print(ordered_days_bubble[0])\n","    # print(ordered_days_bubble[1]) # count = 2175\n","\n","    # It's being sorted to save time calculating the frequency 'n' number of days\n","    # before the erroneous pain observation in A1.csv.\n","    # Saves from ~52,000 to ~12,000 iterations.\n","    A1_activity_frequency = A1_Graphs_sort.dayid_2_timeid(ordered_days_bubble)\n","    # Sort by number of days before pain to make iterations easier.\n","    A1_frequency_day_sort = sorted(A1_activity_frequency, key=lambda x: x[1])\n","    # Find the mean by 'day_list = [3,5,7,10,30]'\n","    A1_mean_reverse_day = A1_Graphs_sort.mean_reverse_days(A1_frequency_day_sort)\n","    # Sorts each 'Day' group alphabetically and from [30,10,7,5,3,] to the opposite.\n","    A1_sorted_category = []\n","    for j in range(len(A1_mean_reverse_day[1])):\n","      if j == (len(A1_mean_reverse_day[1])-1):\n","        break\n","      # Splicing at the days in reverse [3,5,7..etc] based on 'A1_mean_reverse_day'.\n","      start = A1_mean_reverse_day[1][j]\n","      end = A1_mean_reverse_day[1][j+1]\n","      data_slice = A1_activity_frequency[start:end]\n","      sorted_category = sorted(data_slice, key=lambda x: x[0])\n","      sorted_day_list = sorted(sorted_category, key=lambda x: x[1])\n","      A1_sorted_category += sorted_day_list\n","    # Sort the categories by the day.\n","    A1_frequency_category_sort = sorted(A1_sorted_category, key=lambda x: x[5])\n","\n","    # Graphing section.\n","    A1_graph_rgb = Graphs_rgb(A1_frequency_day_sort)\n","  '''\n","\n","  # Returns the frequency of activities for every day (discards the first 10).\n","  A1_activity_frequency = A1_Graphs_sort.activity_frequency()\n","  A1_activity_pain = A1_Graphs_sort.activity_reverse(days_pain,A1_activity_frequency)\n","  # A1_activity_not_pain = A1_Graphs_sort.activity_reverse(days_not_pain,A1_activity_frequency)\n","  # [category, NA], ['value', 'day_id'], ... n\n","  # then calculate\n","\n","  # A1_reverse_mean_category = A1_graph_rgb.rgb_reverse_category(A1_frequency_category_sort,A1_mean_reverse)\n","  return\n","\n","# One month of May, 2024 observations\n","P0_path = \"/content/P0.csv\"\n","B0_path = \"/content/B0.csv\"\n","# A0 is a TSV because there are blank cells\n","A0_path = \"/content/A0.tsv\"\n","P0_unflipped_col = ['ID','Date','Day','Stm']\n","# P0_vert = CSV_running(P0_path,P0_unflipped_col)\n","# B0_vert = CSV_running(B0_path,0)\n","# A0_vert = CSV_running(A0_path,0)\n","# Four months of July-October observations\n","# P1.csv contains the pain scale and B1.csv contains the food records\n","P1_path = \"/content/P1-Observations-PaperFigures.csv\"\n","P1_path_predictions = \"/content/P1-Prediction-PaperFigures.csv\"\n","# B1_path = \"/content/B1.csv\"\n","# A1 is a tsv because of blank cells\n","# A1_path = \"/content/A1.tsv\" # The full dataset.\n","A1_path = \"/content/A1-small.tsv\"\n","# List of columns to not be flipepd\n","P1_unflipped_col = ['ID','Date','Day','Stm','Notes','Notes2']\n","P1_vert = CSV_running(P1_path,P1_unflipped_col)\n","P1_vert_predictions = CSV_running(P1_path_predictions,P1_unflipped_col)\n","# B1_vert = CSV_running(B1_path,0)\n","A1_vert = CSV_running(A1_path,0)\n","\n","# P1_RGB_graph(P1_vert)\n","# B1_RGB_graph(B1_vert)\n","# A0_RGB_graph(A0_vert)\n","# A1_RGB_graph(A1_vert)\n","# P1_Classification_RGB_graph(P1_vert,P1_vert_predictions)\n","A1_daily_RGB_graph(P1_vert,P1_vert_predictions,A1_vert)"],"metadata":{"id":"IxtfVwAjhyaV","executionInfo":{"status":"ok","timestamp":1749482295152,"user_tz":300,"elapsed":50,"user":{"displayName":"David Leifer","userId":"06279506333224389759"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"4b458e27-00d7-4fb7-da9d-d91e9eb46e8a"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["[['Stm', 'NA'], ['2', 0], ['2', 13], ['2', 38], ['2', 53], ['2', 61], ['Qua', 'NA'], ['4', 0], ['4', 1], ['4', 7], ['4', 12], ['4', 16], ['4', 19], ['But', 'NA'], ['4', 0], ['4', 1], ['4', 8], ['4', 9], ['4', 10], ['4', 13], ['Gro', 'NA'], ['4', 8], ['4', 10], ['4', 12], ['4', 16], ['4', 21], ['Abs', 'NA'], ['4', 40], ['4', 53], ['Nec', 'NA'], ['4', 0], ['4', 9], ['4', 51], ['Hea', 'NA'], ['4', 47], ['4', 65]]\n","[[10, 53, 57], [11, 57, 64], [12, 64, 70], [13, 70, 74], [14, 74, 81], [15, 81, 87], [16, 87, 95], [17, 95, 99], [18, 99, 106], [19, 106, 112], [20, 112, 116], [21, 116, 121], [22, 121, 127], [23, 127, 133], [24, 133, 134], [25, 134, 141], [26, 141, 148], [27, 148, 155], [28, 155, 162], [29, 162, 170], [30, 170, 181], [31, 181, 186], [32, 186, 190], [33, 190, 195], [34, 195, 203], [35, 203, 211], [36, 211, 218], [37, 218, 227], [38, 227, 233], [39, 233, 239], [40, 239, 243], [41, 243, 249], [42, 249, 253], [43, 253, 256], [44, 256, 260], [45, 260, 264], [46, 264, 265], [47, 265, 268], [48, 268, 271], [49, 271, 277], [50, 277, 285], [51, 285, 292], [52, 292, 300], [53, 300, 311], [54, 311, 316], [55, 316, 321], [56, 321, 327], [57, 327, 330], [58, 330, 334], [59, 334, 338], [60, 338, 344], [61, 344, 348], [62, 348, 352], [63, 352, 356], [64, 356, 366], [65, 366, 372], [66, 372, 379], [67, 379, 386], [68, 386, 390], [69, 390, 395], [70, 395, 399], [71, 399, 404], [72, 404, 407], [73, 407, 410], [74, 410, 412], [75, 412, 417], [76, 417, 420], [77, 420, 427], [78, 427, 433], [79, 433, 435], [80, 435, 438], [81, 438, 440], [82, 440, 444], [83, 444, 447], [84, 447, 449], [85, 449, 456], [86, 456, 459], [87, 459, 463], [88, 463, 468], [89, 468, 472], [90, 472, 475], [91, 475, 482], [92, 482, 489], [93, 489, 493], [94, 493, 497], [95, 497, 504], [96, 504, 508], [97, 508, 513], [98, 513, 519], [99, 519, 525]]\n","\n","\n","start:  10  =  13  -  3\n","end:  13  =  13  -  0\n","Activity calculating :  4  =  57  -  53\n","Activity calculating :  7  =  64  -  57\n","Activity calculating :  6  =  70  -  64\n","Activity Subset =  17\n","Activity Total =  17\n","start:  8  =  13  -  5\n","end:  10  =  13  -  3\n","start:  6  =  13  -  7\n","end:  10  =  13  -  3\n","start:  3  =  13  -  10\n","end:  10  =  13  -  3\n","start:  -17  =  13  -  30\n","end:  10  =  13  -  3\n","\n","start:  35  =  38  -  3\n","end:  38  =  38  -  0\n","Activity calculating :  8  =  211  -  203\n","Activity calculating :  7  =  218  -  211\n","Activity calculating :  9  =  227  -  218\n","Activity Subset =  24\n","Activity Total =  24\n","start:  33  =  38  -  5\n","end:  35  =  38  -  3\n","Activity calculating :  5  =  195  -  190\n","Activity calculating :  8  =  203  -  195\n","Activity Subset =  13\n","Activity Total =  37\n","start:  31  =  38  -  7\n","end:  30  =  38  -  8\n","Activity Subset =  0\n","Activity Total =  37\n","start:  28  =  38  -  10\n","end:  23  =  38  -  15\n","Activity Subset =  0\n","Activity Total =  37\n","start:  8  =  38  -  30\n","end:  13  =  38  -  25\n","\n","start:  50  =  53  -  3\n","end:  53  =  53  -  0\n","Activity calculating :  8  =  285  -  277\n","Activity calculating :  7  =  292  -  285\n","Activity calculating :  8  =  300  -  292\n","Activity Subset =  23\n","Activity Total =  23\n","start:  48  =  53  -  5\n","end:  50  =  53  -  3\n","Activity calculating :  3  =  271  -  268\n","Activity calculating :  6  =  277  -  271\n","Activity Subset =  9\n","Activity Total =  32\n","start:  46  =  53  -  7\n","end:  45  =  53  -  8\n","Activity Subset =  0\n","Activity Total =  32\n","start:  43  =  53  -  10\n","end:  38  =  53  -  15\n","Activity Subset =  0\n","Activity Total =  32\n","start:  23  =  53  -  30\n","end:  28  =  53  -  25\n","Activity calculating :  6  =  133  -  127\n","Activity calculating :  1  =  134  -  133\n","Activity calculating :  7  =  141  -  134\n","Activity calculating :  7  =  148  -  141\n","Activity calculating :  7  =  155  -  148\n","Activity Subset =  28\n","Activity Total =  60\n","\n","start:  58  =  61  -  3\n","end:  61  =  61  -  0\n","Activity calculating :  4  =  334  -  330\n","Activity calculating :  4  =  338  -  334\n","Activity calculating :  6  =  344  -  338\n","Activity Subset =  14\n","Activity Total =  14\n","start:  56  =  61  -  5\n","end:  58  =  61  -  3\n","Activity calculating :  6  =  327  -  321\n","Activity calculating :  3  =  330  -  327\n","Activity Subset =  9\n","Activity Total =  23\n","start:  54  =  61  -  7\n","end:  53  =  61  -  8\n","Activity Subset =  0\n","Activity Total =  23\n","start:  51  =  61  -  10\n","end:  46  =  61  -  15\n","Activity Subset =  0\n","Activity Total =  23\n","start:  31  =  61  -  30\n","end:  36  =  61  -  25\n","Activity calculating :  5  =  186  -  181\n","Activity calculating :  4  =  190  -  186\n","Activity calculating :  5  =  195  -  190\n","Activity calculating :  8  =  203  -  195\n","Activity calculating :  8  =  211  -  203\n","Activity Subset =  30\n","Activity Total =  53\n","\n","start:  9  =  12  -  3\n","end:  12  =  12  -  0\n","start:  7  =  12  -  5\n","end:  12  =  12  -  0\n","start:  5  =  12  -  7\n","end:  12  =  12  -  0\n","start:  2  =  12  -  10\n","end:  12  =  12  -  0\n","start:  -18  =  12  -  30\n","end:  12  =  12  -  0\n","\n","start:  13  =  16  -  3\n","end:  16  =  16  -  0\n","Activity calculating :  4  =  74  -  70\n","Activity calculating :  7  =  81  -  74\n","Activity calculating :  6  =  87  -  81\n","Activity Subset =  17\n","Activity Total =  17\n","start:  11  =  16  -  5\n","end:  13  =  16  -  3\n","Activity calculating :  7  =  64  -  57\n","Activity calculating :  6  =  70  -  64\n","Activity Subset =  13\n","Activity Total =  30\n","start:  9  =  16  -  7\n","end:  8  =  16  -  8\n","start:  6  =  16  -  10\n","end:  8  =  16  -  8\n","start:  -14  =  16  -  30\n","end:  8  =  16  -  8\n","\n","start:  16  =  19  -  3\n","end:  19  =  19  -  0\n","Activity calculating :  8  =  95  -  87\n","Activity calculating :  4  =  99  -  95\n","Activity calculating :  7  =  106  -  99\n","Activity Subset =  19\n","Activity Total =  19\n","start:  14  =  19  -  5\n","end:  16  =  19  -  3\n","Activity calculating :  7  =  81  -  74\n","Activity calculating :  6  =  87  -  81\n","Activity Subset =  13\n","Activity Total =  32\n","start:  12  =  19  -  7\n","end:  11  =  19  -  8\n","Activity Subset =  0\n","Activity Total =  32\n","start:  9  =  19  -  10\n","end:  4  =  19  -  15\n","start:  -11  =  19  -  30\n","end:  4  =  19  -  15\n","\n","start:  7  =  10  -  3\n","end:  10  =  10  -  0\n","start:  5  =  10  -  5\n","end:  10  =  10  -  0\n","start:  3  =  10  -  7\n","end:  10  =  10  -  0\n","start:  0  =  10  -  10\n","end:  10  =  10  -  0\n","start:  -20  =  10  -  30\n","end:  10  =  10  -  0\n","\n","start:  10  =  13  -  3\n","end:  13  =  13  -  0\n","Activity calculating :  4  =  57  -  53\n","Activity calculating :  7  =  64  -  57\n","Activity calculating :  6  =  70  -  64\n","Activity Subset =  17\n","Activity Total =  17\n","start:  8  =  13  -  5\n","end:  10  =  13  -  3\n","start:  6  =  13  -  7\n","end:  10  =  13  -  3\n","start:  3  =  13  -  10\n","end:  10  =  13  -  3\n","start:  -17  =  13  -  30\n","end:  10  =  13  -  3\n","\n","start:  7  =  10  -  3\n","end:  10  =  10  -  0\n","start:  5  =  10  -  5\n","end:  10  =  10  -  0\n","start:  3  =  10  -  7\n","end:  10  =  10  -  0\n","start:  0  =  10  -  10\n","end:  10  =  10  -  0\n","start:  -20  =  10  -  30\n","end:  10  =  10  -  0\n","\n","start:  9  =  12  -  3\n","end:  12  =  12  -  0\n","start:  7  =  12  -  5\n","end:  12  =  12  -  0\n","start:  5  =  12  -  7\n","end:  12  =  12  -  0\n","start:  2  =  12  -  10\n","end:  12  =  12  -  0\n","start:  -18  =  12  -  30\n","end:  12  =  12  -  0\n","\n","start:  13  =  16  -  3\n","end:  16  =  16  -  0\n","Activity calculating :  4  =  74  -  70\n","Activity calculating :  7  =  81  -  74\n","Activity calculating :  6  =  87  -  81\n","Activity Subset =  17\n","Activity Total =  17\n","start:  11  =  16  -  5\n","end:  13  =  16  -  3\n","Activity calculating :  7  =  64  -  57\n","Activity calculating :  6  =  70  -  64\n","Activity Subset =  13\n","Activity Total =  30\n","start:  9  =  16  -  7\n","end:  8  =  16  -  8\n","start:  6  =  16  -  10\n","end:  8  =  16  -  8\n","start:  -14  =  16  -  30\n","end:  8  =  16  -  8\n","\n","start:  18  =  21  -  3\n","end:  21  =  21  -  0\n","Activity calculating :  7  =  106  -  99\n","Activity calculating :  6  =  112  -  106\n","Activity calculating :  4  =  116  -  112\n","Activity Subset =  17\n","Activity Total =  17\n","start:  16  =  21  -  5\n","end:  18  =  21  -  3\n","Activity calculating :  8  =  95  -  87\n","Activity calculating :  4  =  99  -  95\n","Activity Subset =  12\n","Activity Total =  29\n","start:  14  =  21  -  7\n","end:  13  =  21  -  8\n","Activity Subset =  0\n","Activity Total =  29\n","start:  11  =  21  -  10\n","end:  6  =  21  -  15\n","Activity Subset =  0\n","Activity Total =  29\n","start:  -9  =  21  -  30\n","end:  -4  =  21  -  25\n","\n","start:  37  =  40  -  3\n","end:  40  =  40  -  0\n","Activity calculating :  9  =  227  -  218\n","Activity calculating :  6  =  233  -  227\n","Activity calculating :  6  =  239  -  233\n","Activity Subset =  21\n","Activity Total =  21\n","start:  35  =  40  -  5\n","end:  37  =  40  -  3\n","Activity calculating :  8  =  211  -  203\n","Activity calculating :  7  =  218  -  211\n","Activity Subset =  15\n","Activity Total =  36\n","start:  33  =  40  -  7\n","end:  32  =  40  -  8\n","Activity Subset =  0\n","Activity Total =  36\n","start:  30  =  40  -  10\n","end:  25  =  40  -  15\n","Activity Subset =  0\n","Activity Total =  36\n","start:  10  =  40  -  30\n","end:  15  =  40  -  25\n","Activity calculating :  4  =  57  -  53\n","Activity calculating :  7  =  64  -  57\n","Activity calculating :  6  =  70  -  64\n","Activity calculating :  4  =  74  -  70\n","Activity calculating :  7  =  81  -  74\n","Activity Subset =  28\n","Activity Total =  64\n","\n","start:  50  =  53  -  3\n","end:  53  =  53  -  0\n","Activity calculating :  8  =  285  -  277\n","Activity calculating :  7  =  292  -  285\n","Activity calculating :  8  =  300  -  292\n","Activity Subset =  23\n","Activity Total =  23\n","start:  48  =  53  -  5\n","end:  50  =  53  -  3\n","Activity calculating :  3  =  271  -  268\n","Activity calculating :  6  =  277  -  271\n","Activity Subset =  9\n","Activity Total =  32\n","start:  46  =  53  -  7\n","end:  45  =  53  -  8\n","Activity Subset =  0\n","Activity Total =  32\n","start:  43  =  53  -  10\n","end:  38  =  53  -  15\n","Activity Subset =  0\n","Activity Total =  32\n","start:  23  =  53  -  30\n","end:  28  =  53  -  25\n","Activity calculating :  6  =  133  -  127\n","Activity calculating :  1  =  134  -  133\n","Activity calculating :  7  =  141  -  134\n","Activity calculating :  7  =  148  -  141\n","Activity calculating :  7  =  155  -  148\n","Activity Subset =  28\n","Activity Total =  60\n","\n","start:  48  =  51  -  3\n","end:  51  =  51  -  0\n","Activity calculating :  3  =  271  -  268\n","Activity calculating :  6  =  277  -  271\n","Activity calculating :  8  =  285  -  277\n","Activity Subset =  17\n","Activity Total =  17\n","start:  46  =  51  -  5\n","end:  48  =  51  -  3\n","Activity calculating :  1  =  265  -  264\n","Activity calculating :  3  =  268  -  265\n","Activity Subset =  4\n","Activity Total =  21\n","start:  44  =  51  -  7\n","end:  43  =  51  -  8\n","Activity Subset =  0\n","Activity Total =  21\n","start:  41  =  51  -  10\n","end:  36  =  51  -  15\n","Activity Subset =  0\n","Activity Total =  21\n","start:  21  =  51  -  30\n","end:  26  =  51  -  25\n","Activity calculating :  5  =  121  -  116\n","Activity calculating :  6  =  127  -  121\n","Activity calculating :  6  =  133  -  127\n","Activity calculating :  1  =  134  -  133\n","Activity calculating :  7  =  141  -  134\n","Activity Subset =  25\n","Activity Total =  46\n","\n","start:  44  =  47  -  3\n","end:  47  =  47  -  0\n","Activity calculating :  4  =  260  -  256\n","Activity calculating :  4  =  264  -  260\n","Activity calculating :  1  =  265  -  264\n","Activity Subset =  9\n","Activity Total =  9\n","start:  42  =  47  -  5\n","end:  44  =  47  -  3\n","Activity calculating :  4  =  253  -  249\n","Activity calculating :  3  =  256  -  253\n","Activity Subset =  7\n","Activity Total =  16\n","start:  40  =  47  -  7\n","end:  39  =  47  -  8\n","Activity Subset =  0\n","Activity Total =  16\n","start:  37  =  47  -  10\n","end:  32  =  47  -  15\n","Activity Subset =  0\n","Activity Total =  16\n","start:  17  =  47  -  30\n","end:  22  =  47  -  25\n","Activity calculating :  4  =  99  -  95\n","Activity calculating :  7  =  106  -  99\n","Activity calculating :  6  =  112  -  106\n","Activity calculating :  4  =  116  -  112\n","Activity calculating :  5  =  121  -  116\n","Activity Subset =  26\n","Activity Total =  42\n","\n","start:  62  =  65  -  3\n","end:  65  =  65  -  0\n","Activity calculating :  4  =  352  -  348\n","Activity calculating :  4  =  356  -  352\n","Activity calculating :  10  =  366  -  356\n","Activity Subset =  18\n","Activity Total =  18\n","start:  60  =  65  -  5\n","end:  62  =  65  -  3\n","Activity calculating :  6  =  344  -  338\n","Activity calculating :  4  =  348  -  344\n","Activity Subset =  10\n","Activity Total =  28\n","start:  58  =  65  -  7\n","end:  57  =  65  -  8\n","Activity Subset =  0\n","Activity Total =  28\n","start:  55  =  65  -  10\n","end:  50  =  65  -  15\n","Activity Subset =  0\n","Activity Total =  28\n","start:  35  =  65  -  30\n","end:  40  =  65  -  25\n","Activity calculating :  8  =  211  -  203\n","Activity calculating :  7  =  218  -  211\n","Activity calculating :  9  =  227  -  218\n","Activity calculating :  6  =  233  -  227\n","Activity calculating :  6  =  239  -  233\n","Activity Subset =  36\n","Activity Total =  64\n","\n","101\n"]}]},{"cell_type":"code","source":["######|### |a = 'abcdefg'\n","'''\n","for i in range(1,len(a)):\n","  print(a[:i])\n","  print(a[i])\n","  print('zzzzz')\n","\n","  print(a[-1])'''"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"nyadd2nCLeqQ","executionInfo":{"status":"ok","timestamp":1749480169036,"user_tz":300,"elapsed":8,"user":{"displayName":"David Leifer","userId":"06279506333224389759"}},"outputId":"a002dbcf-d792-4966-9e49-b2f262e8c999"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"\\nfor i in range(1,len(a)):\\n  print(a[:i])\\n  print(a[i])\\n  print('zzzzz')\\n\\n  print(a[-1])\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["abc = [\n","        [[0], ['a']],\n","        [[1], ['b']],\n","        [[2], ['c']],\n","        [[3], ['d']],\n","        [[4], ['e']],\n","        [[5], ['f']],\n","        [[6], ['g']],\n","        [[7], ['h']],\n","        [[8], ['i']],\n","        [[9], ['j']],\n","                      ]\n","# for i in range(10):\n","print(abc[1:2])"],"metadata":{"id":"SLyAYj_xtzdg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1744137032714,"user_tz":300,"elapsed":6,"user":{"displayName":"David Leifer","userId":"06279506333224389759"}},"outputId":"3bb4744a-366f-4183-a0ca-7f695d31af9e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[[1], ['b']]]\n"]}]},{"cell_type":"code","source":["a = '1234'\n","b = '567'\n","c = '89'\n","\n","\n","if len(a) == 4:\n","  end_sub = a[2:]\n","  print(end_sub)\n","\n","if len(b) == 3:\n","  end_sub = b[:1]\n","  print(end_sub)\n","\n","if len(c) == 2:\n","  end_sub = c"],"metadata":{"id":"kti4uK-eVPeZ","executionInfo":{"status":"ok","timestamp":1744769169351,"user_tz":300,"elapsed":9,"user":{"displayName":"David Leifer","userId":"06279506333224389759"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"1c1bc210-f9b0-4b10-b49e-62551d97b986"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["34\n","5\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"bNU5wcEd0AeC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"6wounMFJaZT3"},"execution_count":null,"outputs":[]}]}