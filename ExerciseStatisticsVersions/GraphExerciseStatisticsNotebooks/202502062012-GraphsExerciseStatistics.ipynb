{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1fHIWbrpk4NMYcse3Xdkb-S8XiS2pxzJm","timestamp":1721260308720},{"file_id":"1STKhtVVaknUZiohwWLdfyoZ3zg6Veimx","timestamp":1721260179755}],"authorship_tag":"ABX9TyOxVnBmYkXTDcfFQh4laFd2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# List of primary issues\n","# todo    description                                   hours   progress      Note\n","# todo0   A0/1.csv skate, long, downhill, juggling,\n","#         running duration per day, overall mean.\n","# todo1   A0/1.csv longboard distance, running\n","#         distance per day, overall mean\n","# todo2   P0.csv observations, mean in each,            20      Halted        Halted at ARIMA\n","#         category ARIMA (after todo3).\n","# todo3   p1 observations, manual prediction, mean in   4       Processing    Left at P1 correlation\n","#         each category, ARIMA.\n","# todo4   B01.csv calories, salt, fat, protein, carb,   2       Halted        Halted at ARIMA\n","#         alc each day, overall mean, ARIMA (todo3).\n","# todo5   B01 weather summary, OS PRISM, exercise\n","#         intensity.\n","# todo6   B01 (moving window) correlation between\n","#         exercise and ___.\n","#         (calorie, real weather, alcohol)\n","# todo7   B01 moving window spearman correlation\n","#         between todo0 duration and pain, calories\n","#         burned. duration and nutrients. real and\n","#         summary weather. pain and real weather.\n","#         pain and summary weather. ???.\n","# todo8   tbd data filling idk if thats another\n","#         chapter or avoided.\n","#\n","# Time spent at a computer programming\n","# Total estimate  :\n","# Total actual    :\n","#\n","# Summary\n","# asdfasdf\n","#\n","# Start date: 20250125\n","# End date:\n","\n","# There is an exhaustive list of excessive secondary issues.\n","\n","# List of secondary issues\n","# todo   description                              progress\n","# todo0  rewrite parser for unicode csv str/int\n","# todo1  Stats class avoid NA, NAAN, -9999\n","# todo2  refractor RGB_graphs\n","\n","import sys\n","import matplotlib.pyplot as plt\n","#from datetime import datetime\n","print(sys.version)\n","# 3.10.12 (main, Mar 22 2024, 16:50:05) [GCC 11.4.0]\n","\n","##############################################################################\n","# Part A: CSV parser class to open the file and parse the values into a list #\n","##############################################################################\n","class CSV_Parser:\n","  # Initialize the input variables\n","  def __init__(self, data_path):\n","    self.data_path = data_path\n","  def file_opener(self):\n","    with open(self.data_path, \"r\") as data_open:\n","      data_read = data_open.read()\n","      return data_read\n","  # Index the commas and line breaks\n","  def comma_index(self, open_file, column_len):\n","    data_comma_place = [0]\n","    column_pl_len = 0\n","    for i in range(len(open_file)):\n","      data1_col1 = open_file[i]\n","      if data1_col1 == \",\":\n","        data_comma_place.append(i)\n","        data_comma_place.append(i+1)\n","      if data1_col1 == \"\\n\":\n","        data_comma_place.append(i)\n","        data_comma_place.append(i+1)\n","        # If you want to use the function to get the column width, set to 1\n","        if column_len == 1:\n","          col_width = len(data_comma_place)\n","          return col_width\n","          break\n","    last_val = data_comma_place[-1] + 2\n","    data_comma_place.append(last_val)\n","    return data_comma_place\n","  # Splitting the csv characters into list of words based on indexed comma position\n","  def csv_value_list(self, data_comma_out, open_file, col_width, col_head):\n","    j = col_head\n","    data_val_list = []\n","    for i in range(len(data_comma_out)):\n","      if j >= len(data_comma_out):\n","        break\n","      comma_strt = data_comma_out[j]\n","      j += 1\n","      comma_end = data_comma_out[j]\n","      #print(comma_strt, \"and \", comma_end)\n","      j += 1\n","      data_val_list.append(open_file[comma_strt:comma_end])\n","      j = j + (col_width * 2)\n","    return data_val_list\n","  # Flipping the columns from high to low for readability\n","  # If the original value was 5, set it to equal 0 (no pain)\n","  # If the original value was 0, set it to equal to 5 (high pain) etc.\n","  # If none of those things are true, append the string (for the column header)\n","  def csv_flipper(self, csv_list, col_width):\n","    csv_flipped = []\n","    for i in csv_list:\n","      if i == str(5):\n","        n = str(1)\n","        csv_flipped.append(n)\n","      elif i == str(4):\n","        n = str(2)\n","        csv_flipped.append(n)\n","      elif i == str(3):\n","        n = str(3)\n","        csv_flipped.append(n)\n","      elif i == str(2):\n","        n = str(4)\n","        csv_flipped.append(n)\n","      elif i == str(1):\n","        n = str(5)\n","        csv_flipped.append(n)\n","      else:\n","        csv_flipped.append(i)\n","    return csv_flipped\n","\n","######################################################\n","# Part B: Get descriptive statistics of each column. #\n","######################################################\n","class Statistics:\n","  # Returns a dictionary with the header and mean\n","  def mu(self, col_list):\n","    total = 0\n","    counter = 0\n","    # Column has to have a header\n","    for i in col_list[1:]:\n","      if i == \"NA\":\n","        continue\n","      total = total + float(i)\n","      counter += 1\n","    mean = total / counter\n","    header_mean = [col_list[0], mean]\n","    return header_mean\n","  # Returns the 2-4 moment of the distribution\n","  # Different than Google Sheets sample vs population\n","  def mnt(self, header, mean, col_list):\n","    col_1 = len(col_list) - 1\n","    stn = 0\n","    skew = 0\n","    kurt = 0\n","    counter = 0\n","    for i in col_list[1:]:\n","      if i == \"NA\":\n","        continue\n","      # secondary todo: doesn't work with decimals\n","      n1 = int(i) - mean\n","      n1_sqr = n1 ** 2\n","      n1_cube = n1 ** 3\n","      n1_quad = n1 ** 4\n","      stn = stn + n1_sqr\n","      skew = skew + n1_cube\n","      kurt = kurt + n1_quad\n","      counter += 1\n","    # Sample variance (n-1)\n","    # Population variance (n)\n","    counter = (counter - 1)\n","    stn_small_sqr = float(stn) / counter\n","    stn_small = stn_small_sqr ** .5\n","    skew_small_sqr = float(skew) / counter\n","    skew_small = skew_small_sqr / (stn_small ** 3)\n","    kurt_small_sqr = float(kurt) / counter\n","    kurt_small = kurt_small_sqr / (stn_small ** 4)\n","    return [header, stn_small, skew_small, kurt_small]\n","  # Covariance and correlation\n","  def covar(self, x_mean, y_mean, col_1_list, col_2_list):\n","    col_len = len(col_1_list) - 1\n","    covar = 0\n","    x1y1_sum = 0\n","    counter = 0\n","    for i in range(col_len):\n","      if i == \"NA\":\n","        continue\n","      # print(\"x_mean: \", x_mean[1], \"x_value: \", col_1_list[i+1])\n","      x1 = float(col_1_list[i+1]) - x_mean[1]\n","      y1 = float(col_2_list[i+1]) - y_mean[1]\n","      x1y1 = x1 * y1\n","      x1y1_sum = x1y1_sum + x1y1\n","      counter += 1\n","    covar = x1y1_sum / counter\n","    return covar\n","  def cor(self, covar, col_1_stnd, col_2_stnd):\n","    stnd12 = col_1_stnd * col_2_stnd\n","    cor = covar / stnd12\n","    return cor\n","\n","######################################################\n","# Part C: Data visualization with a timeseries graph #\n","######################################################\n","# 'Graph' class accepts three variables: verticle arranged 'data',\n","# the date column'date_col_num', and the data column 'data_col_num'\n","class Graph:\n","  # Initialize the input variables\n","  def __init__(self, data, date_col_num, data_col_num):\n","    self.data = data\n","    self.date_col_num = date_col_num\n","    self.data_col_num = data_col_num\n","  def hi_lo(self, data_col_num):\n","    # The date and date column to be used\n","    data_col = self.data[data_col_num]\n","    data_col_len = len(data_col)\n","    # High and low of values\n","    hi_lo_count = 1\n","    hi = data_col[1]\n","    lo = data_col[1]\n","    for e in range(len(data_col[1:])):\n","      hi_lo_count += 1\n","      if hi_lo_count == (len(data_col[1:]) + 1):\n","        break\n","      if hi < data_col[hi_lo_count]:\n","        hi = data_col[hi_lo_count]\n","      if lo > data_col[hi_lo_count]:\n","        lo = data_col[hi_lo_count]\n","    return [hi, lo]\n","  def binned(self, hi_lo):\n","    # high value (5 in this case or hi_lo[0])\n","    # The date and date column to be used\n","    # TODO it works but is not resuable for other data ranges\n","    date_col = self.data[self.date_col_num]\n","    data_col = self.data[self.data_col_num]\n","    data_col_len = len(data_col)\n","    fiver = []\n","    fourer = []\n","    threer = []\n","    twoer = []\n","    oner = []\n","    lol_stm_date = []\n","    counter = 1\n","    # Binned with date value\n","    for i in range(data_col_len):\n","      P0_column = self.data[self.data_col_num]\n","      if counter == len(self.data[0]):\n","        break\n","      if float(P0_column[counter]) == 5:\n","        fiver.append([date_col[counter], P0_column[counter]])\n","      elif float(P0_column[counter]) == 4:\n","        fourer.append([date_col[counter], P0_column[counter]])\n","      elif float(P0_column[counter]) == 3:\n","        threer.append([date_col[counter], P0_column[counter]])\n","      elif float(P0_column[counter]) == 2:\n","        twoer.append([date_col[counter], P0_column[counter]])\n","      elif float(P0_column[counter]) == 1:\n","        oner.append([date_col[counter], P0_column[counter]])\n","      counter += 1\n","    # Combining the binned data into one dictionary\n","    lol_date_stm = [fiver, fourer, threer, twoer, oner]\n","    return lol_date_stm\n","\n","  def time_series(self, date_hi_lo, lol_date_stm):\n","    date_col = self.data[self.date_col_num]\n","    # Base of the month, plus 00 i.e. 500\n","    date_base = int(date_hi_lo[1]) - 1\n","    # The number of spaces is the 'day' (date - month) - 'prev_day_space_int'\n","    # The difference between the values is multiplied by ' ' for each 5,4,3,2,1\n","    # Value with a '+' character marking the position\n","    spacer = []\n","    prev_day_space_int = 0\n","    for i in lol_date_stm:\n","      spacer_mid = []\n","      for ii in i:\n","        day = int(ii[0]) - date_base\n","        day_count = day - prev_day_space_int\n","        day_space_str = ((day_count-1)*2) * \" \"\n","        spacer_mid.append(day_space_str)\n","        prev_day_space_int = day\n","      prev_day_space_int = 0\n","      spacer.append(spacer_mid)\n","    y_val = [y for y in range(len(spacer),0,-1)]\n","    return [spacer, y_val]\n","  def time_series_print(self,spacer,y_val):\n","    date_col = self.data[self.date_col_num]\n","    for j,k in zip(spacer,y_val):\n","      # y values\n","      print(k,end=\" \")\n","      for l in j:\n","        print(l,end=\"\")\n","        print(\"+\",end=\" \")\n","      print()\n","    # x values\n","    for m in range(len(date_col[0])-1):\n","      print(\"  \",end=\"\")\n","      for n in date_col[1:]:\n","        print(n[m], end=\" \")\n","      print()\n","    return\n","  def time_series_write(self,header,txt_out,spacer,y_val):\n","    # Open the output file location and write data to the txt\n","    date_col = self.data[self.date_col_num]\n","    file_output = open(txt_out, \"w\")\n","    file_output.write(header)\n","    file_output.write(\"\\n\")\n","    file_output.write(\"\\n\")\n","    # y values\n","    for j,k in zip(spacer,y_val):\n","      file_output.write(str(k) + \" \")\n","      for l in j:\n","        file_output.write(str(l))\n","        file_output.write(\"+\" + \" \")\n","      file_output.write(\"\\n\")\n","    # x values\n","    for m in range(len(date_col[0])-1):\n","      file_output.write(\"  \")\n","      for n in date_col[1:]:\n","        file_output.write(str(n[m]) + \" \")\n","      file_output.write(\"\\n\")\n","    file_output.close()\n","    return\n","\n","###############################################\n","# Part D: Data visualization with a RGB graph #\n","###############################################\n","# Matplotlib for color because otherwise you would have\n","# to write hardware code to avoid using Python or C libraries.\n","class Graphs_rgb:\n","  # Initialize the input variables\n","  def __init__(self, data, date_col_num, data_col_num):\n","    self.data = data\n","    self.date_col_num = date_col_num\n","    self.data_col_num = data_col_num\n","  # Bar plots for each column\n","  # P0.csv\n","  '''\n","  def rgb_timeseries_bar(self,title_full):\n","    #date_col = self.data[self.date_col_num]\n","    date_col = self.data[0]\n","    data_col = self.data[self.data_col_num]\n","    # Skipping the first text value\n","    dist0 = [int(x)+1 for x in date_col[1:]]\n","    dist1 = [int(y) for y in data_col[1:]]\n","    # Functionalize\n","    figure_dim = [5,15]\n","    plt.rcParams['figure.figsize'] = [figure_dim[1], figure_dim[0]]\n","    plt.bar(dist0, dist1, width=0.8, align='edge')\n","    plt.yticks(range(1,6))\n","    plt.grid()\n","    plt.xlabel(\"May Date\")\n","    plt.margins()\n","\n","    if title_full == 'Stamina':\n","      plt.ylabel(title_full)\n","    else:\n","      plt.title(title_full)\n","      plt.ylabel(\"Pain\")\n","    plt.xticks(dist0)\n","    plt.savefig(title_full + '.jpg')\n","    plt.show()\n","    return'''\n","  # B0.csv\n","  '''\n","  def rgb_timeseries_bar(self,title_full):\n","    #date_col = self.data[self.date_col_num]\n","    date_col = self.data[0]\n","    data_col = self.data[self.data_col_num]\n","    # Skipping the first text value\n","    dist0 = [int(x)+1 for x in date_col[1:]]\n","    dist1 = [int(y) for y in data_col[1:]]\n","    plt.bar(dist0, dist1, width=0.8, align='edge')\n","    figure_dim = [5,15]\n","    plt.rcParams['figure.figsize'] = [figure_dim[1], figure_dim[0]]\n","    if title_full == 'Calories':\n","      plt.yticks(range(0,3600,400))\n","      plt.ylabel(\"Intake\")\n","      plt.title(title_full)\n","    elif title_full == 'Alcohol Servings':\n","      plt.yticks(range(1,6))\n","      plt.title(\"Alcohol\")\n","      plt.ylabel(\"Servings\")\n","    elif title_full == 'Exercise':\n","      plt.yticks(range(0,3))\n","      plt.title(title_full)\n","      plt.ylabel(\"Calories Out\")\n","    else:\n","      plt.yticks(range(1,6))\n","      plt.title(title_full)\n","      plt.ylabel(\"Intake\")\n","    plt.xticks(dist0)\n","    # function\n","    plt.margins()\n","    plt.grid()\n","    plt.xlabel(\"May Day\")\n","    plt.savefig(title_full + '.jpg')\n","    plt.show()\n","    return'''\n","\n","  # Multiple lines same graphs.\n","  # P0\n","  '''\n","  def rgb_timeseries_line(self,title_full):\n","    #date_col = self.data[self.date_col_num]\n","    date_col = self.data[0]\n","    data = self.data\n","    # Skipping the first text value in date column\n","    dist0 = [int(x)+1 for x in date_col[1:]]\n","    # secondary todo: name instead of number position\n","    # Uses the position of each body part name in the list\n","    data_groups_num = [3,4,7,11,13,16,19,21]\n","    j = 1\n","    # Adding multiple lines to a single plot by group with formatting\n","    # secondayr todo: refractor\n","    for i in range(len(data_groups_num)):\n","      subset0 = data_groups_num[i:j][0]\n","      if subset0 == data_groups_num[-1]:\n","        break\n","      subset1 = data_groups_num[i+1:j+1][0]\n","      data_groups = data[subset0:subset1]\n","      # First 3 columns in data are ID, while the title list isn't.\n","      # Subtract each subset by 3\n","      title_group = title_full[(subset0-3):(subset1-3)]\n","      legend_label = ['Stamina','Lower Legs','Upper Legs','Core','Upper Back','Arms','Head']\n","      # functinalize\n","      fig, ax = plt.subplots()\n","      figure_dim = [5,15]\n","      plt.rcParams['figure.figsize'] = [figure_dim[1], figure_dim[0]]\n","      if legend_label[j-1] == 'Stamina':\n","        plt.ylabel(legend_label[j-1])\n","      else:\n","        plt.ylabel(\"Pain\")\n","        plt.title(legend_label[j-1])\n","      # Plot each line from the group and add to legend\n","      m = 0\n","      for k in data_groups:\n","        # Skipping the first text value in pain column\n","        dist1_group = [int(y) for y in k[1:]]\n","        ax.plot(dist0, dist1_group, label=title_group[m], linewidth=10)\n","        if title_group[m] == 'Stamina':\n","          continue\n","        else:\n","          ax.legend()\n","        m += 1\n","      plt.yticks(range(1,6))\n","      plt.margins()\n","      plt.xticks(dist0)\n","      plt.xlabel(\"May Date\")\n","      plt.grid()\n","      plt.savefig(legend_label[j-1] + '.jpg')\n","      plt.show()\n","      j += 1\n","    return'''\n","  # B0.csv\n","  '''\n","  def rgb_timeseries_line(self,title_full):\n","    date_col = self.data[0]\n","    data = self.data\n","    # Skipping the first text value in date column\n","    dist0 = [int(x)+1 for x in date_col[1:]]\n","    # secondary todo: name instead of number position\n","    # B0.csv\n","    data_groups_num = [2,3,4,8,9]\n","    j = 1\n","    # Adding multiple lines to a single plot by group with formatting\n","    # secondayr todo: refractor\n","    for i in range(len(data_groups_num)):\n","      subset0 = data_groups_num[i:j][0]\n","      if subset0 == data_groups_num[-1]:\n","        break\n","      subset1 = data_groups_num[i+1:j+1][0]\n","      data_groups = data[subset0:subset1]\n","      # First 3 columns in data are ID, while the title list isn't.\n","      # Subtract each subset by 3\n","      title_group = title_full[(subset0-2):(subset1-2)]\n","      # Create the plot\n","      fig, ax = plt.subplots()\n","      j += 1\n","      # Plot each line from the group and add to legend\n","      m = 0\n","      for k in data_groups:\n","        # Skipping the first text value in pain column\n","        if title_group[m] == 'Calories':\n","          plt.yticks(range(0,3600,400))\n","          dist1_group = [int(y) for y in k[1:]]\n","          ax.plot(dist0, dist1_group, label=title_group[m], linewidth=10)\n","          plt.ylabel(\"Intake\")\n","          plt.title(title_group[m])\n","        elif title_group[m] == 'Exercise':\n","          plt.yticks(range(0,3))\n","          dist1_group = [int(y) for y in k[1:]]\n","          ax.plot(dist0, dist1_group, label=title_group[m], linewidth=10)\n","          plt.ylabel(\"Calories Out\")\n","          plt.title(title_group[m])\n","        else:\n","          plt.yticks(range(1,6))\n","          dist1_group = [int(y) for y in k[1:]]\n","          ax.plot(dist0, dist1_group, label=title_group[m], linewidth=10)\n","          # plt.title(title_group[m])\n","          if title_group[m] == \"Alcohol Servings\":\n","            plt.ylabel(\"Servings\")\n","            plt.title(\"Alcohol\")\n","          else:\n","            plt.ylabel(\"Intake\")\n","            plt.title(\"Nutrients\")\n","            ax.legend()\n","        m += 1\n","      # Plot formatting\n","      plt.xticks(dist0)\n","      plt.xlabel(\"May Date\")\n","      plt.margins()\n","      plt.grid()\n","      figure_dim = [5,15]\n","      plt.rcParams['figure.figsize'] = [figure_dim[1], figure_dim[0]]\n","      plt.savefig(title_group[m-1] + '.jpg')\n","      plt.show()\n","    return'''\n","\n","  # Displays on two graphs: upper and lower\n","  # P0.csv\n","  '''\n","  def rgb_timeseries_small(self):\n","    date_col = self.data[0]\n","    data = self.data\n","    # Skipping the first text value in date column\n","    dist0 = [int(x)+1 for x in date_col[1:]]\n","    # secondary todo: name instead of number position\n","    # Uses the position of each body part name in the list\n","    data_groups_num_list = [[3,4],[4,7,11,13],[13,16,19,21]]\n","    legend_label = ['Stamina','Lower Legs','Upper Legs','Core','Upper Back','Arms','Head']\n","    p = 0\n","    for data_groups_num in data_groups_num_list:\n","      j = 1\n","      # Adding multiple lines to a single plot by group with formatting\n","      # secondary todo: refractor\n","      # Create the plot\n","      fig, ax = plt.subplots()\n","      figure_dim = [5,15]\n","      plt.rcParams[\"figure.figsize\"] = [figure_dim[1], figure_dim[0]]\n","      for i in range(len(data_groups_num)):\n","        subset0 = data_groups_num[i:j][0]\n","        if subset0 == data_groups_num[-1]:\n","          break\n","        subset1 = data_groups_num[i+1:j+1][0]\n","        data_groups = data[subset0:subset1]\n","        data_group_mean = []\n","        for k in range(len(date_col)):\n","          if k == len(date_col)-1:\n","            break\n","          row_list = [int(sublist[k+1]) for sublist in data_groups]\n","          row_count = len(row_list)\n","          row_sum = sum(row_list)\n","          row_mean = row_sum / row_count\n","          data_group_mean.append(row_mean)\n","        j += 1\n","        ax.plot(dist0, data_group_mean, label=legend_label[p], linewidth=7)\n","        p += 1\n","      # Plot formatting\n","      plt.margins()\n","      plt.xticks(dist0)\n","      plt.yticks(range(1,6))\n","      plt.xlabel(\"May Day\")\n","      plt.grid()\n","      if sum(data_groups_num) == sum(data_groups_num_list[1]):\n","        ax.legend()\n","        plt.title(\"Lower Body\")\n","        plt.ylabel(\"Pain\")\n","        plt.savefig(\"Lower Body Pain.jpg\")\n","      elif sum(data_groups_num) == sum(data_groups_num_list[2]):\n","        ax.legend()\n","        plt.title(\"Upper Body\")\n","        plt.ylabel(\"Pain\")\n","        plt.savefig(\"Upper Body Pain.jpg\")\n","      else:\n","        plt.ylabel(\"Stamina\")\n","        plt.savefig(\"Stamina.jpg\")\n","      plt.show()\n","    return'''\n","  # Combines each category into stamina, upper, lower\n","  # P0.csv\n","  '''\n","  def rgb_timeseries_smallest(self):\n","    date_col = self.data[0]\n","    data = self.data\n","    # Skipping the first text value in date column\n","    dist0 = [int(x)+1 for x in date_col[1:]]\n","    # secondary todo: name instead of number position\n","    # Uses the position of each body part name in the list\n","    data_groups_num_list = [[3,4],[4,12],[13,21]]\n","    legend_label = ['Stamina','Lower Body', 'Upper Body']\n","    p = 0\n","    fig, ax = plt.subplots()\n","    figure_dim = [5,15]\n","    plt.rcParams['figure.figsize'] = [figure_dim[1], figure_dim[0]]\n","    for data_groups_num in data_groups_num_list:\n","      # Create the plot\n","      j = 1\n","      for i in range(len(data_groups_num)):\n","        subset0 = data_groups_num[i:j][0]\n","        if subset0 == data_groups_num[-1]:\n","          break\n","        subset1 = data_groups_num[i+1:j+1][0]\n","        data_groups = data[subset0:subset1]\n","        j += 1\n","        data_group_mean = []\n","        for k in range(len(date_col)):\n","          if k == len(date_col)-1:\n","            break\n","          row_list = [int(sublist[k+1]) for sublist in data_groups]\n","          row_count = len(row_list)\n","          row_sum = sum(row_list)\n","          row_mean = row_sum / row_count\n","          data_group_mean.append(row_mean)\n","      # Plot the summarized means\n","      ax.plot(dist0, data_group_mean,label=legend_label[p],linewidth=7)\n","      ax.legend()\n","      p += 1\n","    # Plot formatting\n","    plt.margins()\n","    plt.xticks(dist0)\n","    plt.yticks(range(1,6))\n","    plt.xlabel(\"May Day\")\n","    plt.ylabel(\"Pain or Stamina\")\n","    plt.grid()\n","    plt.savefig('P0_smallest.jpg')\n","    plt.show()\n","    # Figure reference.\n","    # https://matplotlib.org/stable/gallery/showcase/anatomy.html#sphx-glr-gallery-showcase-anatomy-py\n","    # Heat map to display each value in Chapter 11 for style consistency.\n","    # https://matplotlib.org/stable/gallery/images_contours_and_fields/image_annotated_heatmap.html#sphx-glr-gallery-images-contours-and-fields-image-annotated-heatmap-py\n","    # Compare means and correlation could use heat map or this box plot.\n","    # https://matplotlib.org/stable/gallery/statistics/boxplot_color.html#sphx-glr-gallery-statistics-boxplot-color-py\n","    return\n","    '''\n","\n","  # Excessive\n","  '''\n","  def rgb_animation(self):\n","    # Ball kick physics kind of.\n","    # https://matplotlib.org/stable/gallery/animation/double_pendulum.html#sphx-glr-gallery-animation-double-pendulum-py\n","    # Interesting album cover.\n","    # https://matplotlib.org/stable/gallery/animation/unchained.html#sphx-glr-gallery-animation-unchained-py\n","    # Animation Updates\n","    # Bayes\n","    # https://matplotlib.org/stable/gallery/animation/bayes_update.html#sphx-glr-gallery-animation-bayes-update-py\n","    # Histogram\n","    # https://matplotlib.org/stable/gallery/animation/animated_histogram.html#sphx-glr-gallery-animation-animated-histogram-py\n","    # Ticks\n","    # https://matplotlib.org/stable/gallery/animation/animate_decay.html#sphx-glr-gallery-animation-animate-decay-py\n","    # Save as gif\n","    # https://matplotlib.org/stable/gallery/animation/simple_scatter.html#sphx-glr-gallery-animation-simple-scatter-py\n","    # Heart rate monitor animation.\n","    # https://matplotlib.org/stable/gallery/animation/strip_chart.html#sphx-glr-gallery-animation-strip-chart-py\n","    return'''\n","\n","\n","#################################\n","# Part 0: Run P0.csv and B0.csv #\n","#################################\n","# secondary todo: refractor into function\n","def May_Running(self):\n","  # Part A: The path of the CSV to be parsed\n","  # P0.csv contains the pain scale and B0.csv contains the food records\n","  P0_path, B0_path = \"/content/P0.csv\", \"/content/B0.csv\"\n","  # Create the CSV_Parser class object and open the files\n","  P0_Parser, B0_Parser = CSV_Parser(P0_path), CSV_Parser(B0_path)\n","  P0_read, B0_read = P0_Parser.file_opener(), B0_Parser.file_opener()\n","  # Index the comma position from the CSV and split the characters into their values\n","  P0_comma_indexed, B0_comma_indexed = P0_Parser.comma_index(P0_read, 0), B0_Parser.comma_index(B0_read, 0)\n","  # Get the width of columns of the commas\n","  P0_comma_width, B0_comma_width = P0_Parser.comma_index(P0_read, 1), B0_Parser.comma_index(B0_read, 1)\n","  # Sort the list into verticle columns\n","  # The P0 csv gets flipped, except for the Stm column\n","  # Divide by two - the list of comma places is doubled for the start/end value\n","  P0_col_width = int(((P0_comma_width - 1 ) / 2) - 1)\n","  # Divide by two - the list of comma places is doubled for the start/end value\n","  B0_col_width = int(((B0_comma_width - 1 ) / 2) - 1)\n","  P0_vert = []\n","  B0_vert = []\n","  # List of columns to not be flipepd\n","  unflipped_col = ['ID','Date','Day','Stm']\n","  for i in range(0,P0_comma_width-1,2):\n","    P0_list = P0_Parser.csv_value_list(P0_comma_indexed, P0_read, P0_col_width, i)\n","    if P0_list[0] in unflipped_col:\n","      P0_vert.append(P0_list)\n","    else:\n","      P0_flip = P0_Parser.csv_flipper(P0_list, P0_col_width)\n","      P0_vert.append(P0_flip)\n","  for j in range(0,B0_comma_width-1,2):\n","    B0_list = B0_Parser.csv_value_list(B0_comma_indexed, B0_read, B0_col_width, j)\n","    B0_vert.append(B0_list)\n","\n","  # Part B: Get descriptive statistics\n","  stats_class = Statistics()\n","  # The first three columns are skipped because they are ID, Date, and Day\n","  # These two loops calculate the means and moments\n","  P0_means_list = []\n","  P0_stnd_list = []\n","  B0_means_list = []\n","  B0_stnd_list = []\n","  # secondary todo: rename l, m, n to something more meaningful\n","  # might make these functions idk\n","  for l in P0_vert[3:]:\n","    P0_means = stats_class.mu(l)\n","    P0_means_list.append(P0_means)\n","    P0_mnt2_4 = stats_class.mnt(P0_means[0],P0_means[1],l)\n","    P0_stnd_list.append(P0_mnt2_4[1])\n","  for m in B0_vert[3:]:\n","    B0_means = stats_class.mu(m)\n","    B0_means_list.append(B0_means)\n","    B0_mnt2_4 = stats_class.mnt(B0_means[0],B0_means[1],m)\n","    B0_stnd_list.append(B0_mnt2_4[1])\n","  # The nested loops calculates the covariance and correlations between B0 and P0\n","  for n in range(len(P0_vert[3:])):\n","    #print(\"x: \", P0_vert[o+3][0])\n","    for o in range(len(B0_vert[3:])):\n","      #print(\"    and \", B0_vert[p+3][0])\n","      P0B0_covar = stats_class.covar(P0_means_list[n],B0_means_list[o],P0_vert[n+3],B0_vert[o+3])\n","      P0B0_cor = stats_class.cor(P0B0_covar,P0_stnd_list[n],B0_stnd_list[o])\n","      #print(P0B0_cor)\n","    #print()\n","\n","  # Part C: Data visualization\n","  '''\n","  title_full = ['Stamina',\n","                'Feet','Ankle','Calves',\n","                'Knees','Quadriceps','Gluteus','Groin',\n","                'Abdominals','Lower Back',\n","                'Latissimus Dorsi','Trapezius','Shoulders',\n","                'Chest','Triceps','Biceps',\n","                'Neck','Head']\n","  graph_count = 3\n","  for p in stats_class.P0_flipped[3:]:\n","    #if graph_count == 4:\n","    #  break\n","    # Initialize graph class\n","    P0_graph = Graph(P0_vert, 1, graph_count)\n","    # ASCII Graphs\n","    # date_col_num = 1 # data_col_num = each successive column\n","    # this would be a loop over columns 3-20, 1st column is the date\n","    jpg_print = []\n","    print(p[0])\n","    # print()\n","    P0_hi_lo = P0_graph.hi_lo(graph_count)\n","    date_hi_lo = P0_graph.hi_lo(1)\n","    P0_binned = P0_graph.binned(P0_hi_lo)\n","    P0_time_series = P0_graph.time_series(date_hi_lo,P0_binned)\n","    P0_graph.time_series_print(P0_time_series[0],P0_time_series[1])\n","    # print(\"variable 'P0_rgb_graph':\\n\", P0_rgb_graph)\n","    # print()\n","    # P0_file_out = \"/content/P0_\" + p[0] + \".txt\"\n","    # P0_time_series_write = P0_graph.time_series_write(p[0],P0_file_out,P0_time_series[0],P0_time_series[1])\n","    print(\"\\n\")\n","    # Part D: RGB Bar Graph P0.csv\n","    P0_rgb_graph = Graphs_rgb(P0_vert, 1, graph_count)\n","    # P0_rgb_bar = P0_rgb_graph.rgb_timeseries_bar(title_full[graph_count-3])\n","    graph_count += 1\n","  # Part D: Continued: P0\n","  # RGB Line Graphs by Group for B0.csv\n","  # P0_rgb_line = P0_rgb_graph.rgb_timeseries_line(title_full)\n","  # RGB Line graphs by upper/lower body group means\n","  # P0_rgb_line_small = P0_rgb_graph.rgb_timeseries_small()\n","  # RGB Line graphs by upper/lower body group means\n","  # P0_rgb_line_smallest = P0_rgb_graph.rgb_timeseries_smallest()\n","\n","  # B0.csv (2:6 by 30)\n","  title_full = ['Calories','Exercise',\n","                'Salt', 'Fat', 'Protein',\n","                'Carbohydrates', 'Alcohol Servings'\n","                ]\n","  graph_count = 2\n","  for p in stats_class.B0_list[2:]:\n","    #if graph_count == 4:\n","    #  break\n","    # Initialize graph class\n","    B0_graph = Graph(B0_vert, 1, graph_count)\n","    # ASCII Graphs\n","    # date_col_num = 1 # data_col_num = each successive column\n","    # this would be a loop over columns 3-20, 1st column is the date\n","    jpg_print = []\n","    print(p[0])\n","    # print()\n","    B0_hi_lo = B0_graph.hi_lo(graph_count)\n","    date_hi_lo = B0_graph.hi_lo(1)\n","    B0_binned = B0_graph.binned(B0_hi_lo)\n","    B0_time_series = B0_graph.time_series(date_hi_lo,B0_binned)\n","    B0_graph.time_series_print(B0_time_series[0],B0_time_series[1])\n","    print()\n","    B0_file_out = \"/content/B0_\" + p[0] + \".txt\"\n","    # B0_time_series_write = B0_graph.time_series_write(p[0],B0_file_out,B0_time_series[0],B0_time_series[1])\n","    print(\"\\n\")\n","    # Part D: RGB Bar Graph B0.csv\n","    # B0_rgb_graph = Graphs_rgb(B0_vert, 1, graph_count)\n","    # B0_rgb_bar = B0_rgb_graph.rgb_timeseries_bar(title_full[graph_count-2])\n","    graph_count += 1\n","  # Part D Continued: B0\n","  # RGB Line Graphs by Group for B0.csv\n","  # B0_rgb_line = B0_rgb_graph.rgb_timeseries_line(title_full)\n","'''\n","\n","#################################\n","# Part 1: Run P1.csv and B1.csv #\n","#################################\n","# Part A: The path of the CSV to be parsed\n","# P1.csv contains the pain scale and B1.csv contains the food records\n","# P1_path, B1_path = \"/content/P1-Observations-PaperFigures.csv\", \"/content/B1.csv\"\n","P1_path, B1_path = \"/content/P0.csv\", \"/content/B0.csv\"\n","# Create the CSV_Parser class object and open the files\n","P1_Parser, B1_Parser = CSV_Parser(P1_path), CSV_Parser(B1_path)\n","P1_read, B1_read = P1_Parser.file_opener(), B1_Parser.file_opener()\n","# Index the comma position from the CSV and split the characters into their values\n","P1_comma_indexed, B1_comma_indexed = P1_Parser.comma_index(P1_read, 0), B1_Parser.comma_index(B1_read, 0)\n","# Get the width of columns of the commas\n","P1_comma_width, B1_comma_width = P1_Parser.comma_index(P1_read, 1), B1_Parser.comma_index(B1_read, 1)\n","# Sort the list into verticle columns\n","# The P0 csv gets flipped, except for the Stm column\n","# Divide by two - the list of comma places is doubled for the start/end value\n","P1_col_width = int(((P1_comma_width - 1 ) / 2) - 1)\n","# Divide by two - the list of comma places is doubled for the start/end value\n","B1_col_width = int(((B1_comma_width - 1 ) / 2) - 1)\n","\n","P1_vert = []\n","B1_vert = []\n","# List of columns to not be flipepd\n","unflipped_col = ['ID','Date','Day','Stm','Notes','Notes2']\n","for i in range(0,P1_comma_width-1,2):\n","  P1_list = P1_Parser.csv_value_list(P1_comma_indexed, P1_read, P1_col_width, i)\n","  if P1_list[0] in unflipped_col:\n","    P1_vert.append(P1_list)\n","  else:\n","    P1_flip = P1_Parser.csv_flipper(P1_list, P1_col_width)\n","    P1_vert.append(P1_flip)\n","for j in range(0,B1_comma_width-1,2):\n","  B1_list = B1_Parser.csv_value_list(B1_comma_indexed, B1_read, B1_col_width, j)\n","  B1_vert.append(B1_list)\n","# Part B: Get descriptive statistics\n","stats_class = Statistics()\n","# The first three columns are skipped because they are ID, Date, and Day\n","# These two loops calculate the means and moments\n","P1_means_list = []\n","P1_stnd_list = []\n","B1_means_list = []\n","B1_stnd_list = []\n","# secondary todo: might make these functions\n","for l in P1_vert[3:]:\n","  P1_means = stats_class.mu(l)\n","  P1_means_list.append(P1_means)\n","  P1_mnt2_4 = stats_class.mnt(P1_means[0],P1_means[1],l)\n","  P1_stnd_list.append(P1_mnt2_4[1])\n","for m in B1_vert[2:]:\n","  B1_means = stats_class.mu(m)\n","  B1_means_list.append(B1_means)\n","  B1_mnt2_4 = stats_class.mnt(B1_means[0],B1_means[1],m)\n","  B1_stnd_list.append(B1_mnt2_4[1])\n","# The nested loops calculates the covariance and correlations between B0 and P0\n","for n in range(len(P1_vert[3:])):\n","  # print(\"x: \", P1_vert[o+3][0])\n","  for o in range(len(B1_vert[2:])):\n","    # print(\"    and \", B1_vert[p+3][0])\n","    P1B1_covar = stats_class.covar(P1_means_list[n],B1_means_list[o],P1_vert[n+3],B1_vert[o+2])\n","    P1B1_cor = stats_class.cor(P1B1_covar,P1_stnd_list[n],B1_stnd_list[o])\n","    # print(P1B1_cor)\n","  #print()\n","\n","\n","\n","\n","\n","def foo_graph(self):\n","  # Part C: Data visualization\n","  title_full = ['Stamina',\n","                'Feet','Ankle','Calves',\n","                'Knees','Quadriceps','Gluteus','Groin',\n","                'Abdominals','Lower Back',\n","                'Latissimus Dorsi','Trapezius','Shoulders',\n","                'Chest','Triceps','Biceps',\n","                'Neck','Head']\n","  graph_count = 3\n","  for p in stats_class.P0_flipped[3:]:\n","    #if graph_count == 4:\n","    #  break\n","    # Initialize graph class\n","    P0_graph = Graph(P0_vert, 1, graph_count)\n","    # ASCII Graphs\n","    # date_col_num = 1 # data_col_num = each successive column\n","    # this would be a loop over columns 3-20, 1st column is the date\n","    jpg_print = []\n","    print(p[0])\n","    # print()\n","    P0_hi_lo = P0_graph.hi_lo(graph_count)\n","    date_hi_lo = P0_graph.hi_lo(1)\n","    P0_binned = P0_graph.binned(P0_hi_lo)\n","    P0_time_series = P0_graph.time_series(date_hi_lo,P0_binned)\n","    P0_graph.time_series_print(P0_time_series[0],P0_time_series[1])\n","    # print(\"variable 'P0_rgb_graph':\\n\", P0_rgb_graph)\n","    # print()\n","    # P0_file_out = \"/content/P0_\" + p[0] + \".txt\"\n","    # P0_time_series_write = P0_graph.time_series_write(p[0],P0_file_out,P0_time_series[0],P0_time_series[1])\n","    print(\"\\n\")\n","    # Part D: RGB Bar Graph P0.csv\n","    P0_rgb_graph = Graphs_rgb(P0_vert, 1, graph_count)\n","    # P0_rgb_bar = P0_rgb_graph.rgb_timeseries_bar(title_full[graph_count-3])\n","    graph_count += 1\n","  # Part D: Continued: P0\n","  # RGB Line Graphs by Group for B0.csv\n","  # P0_rgb_line = P0_rgb_graph.rgb_timeseries_line(title_full)\n","  # RGB Line graphs by upper/lower body group means\n","  # P0_rgb_line_small = P0_rgb_graph.rgb_timeseries_small()\n","  # RGB Line graphs by upper/lower body group means\n","  # P0_rgb_line_smallest = P0_rgb_graph.rgb_timeseries_smallest()\n","\n","  # B0.csv (2:6 by 30)\n","\n","  title_full = ['Calories','Exercise',\n","                'Salt', 'Fat', 'Protein',\n","                'Carbohydrates', 'Alcohol Servings'\n","                ]\n","  graph_count = 2\n","  for p in stats_class.B0_list[2:]:\n","    #if graph_count == 4:\n","    #  break\n","    # Initialize graph class\n","    B0_graph = Graph(B0_vert, 1, graph_count)\n","    # ASCII Graphs\n","    # date_col_num = 1 # data_col_num = each successive column\n","    # this would be a loop over columns 3-20, 1st column is the date\n","    jpg_print = []\n","    print(p[0])\n","    # print()\n","    B0_hi_lo = B0_graph.hi_lo(graph_count)\n","    date_hi_lo = B0_graph.hi_lo(1)\n","    B0_binned = B0_graph.binned(B0_hi_lo)\n","    B0_time_series = B0_graph.time_series(date_hi_lo,B0_binned)\n","    B0_graph.time_series_print(B0_time_series[0],B0_time_series[1])\n","    print()\n","    B0_file_out = \"/content/B0_\" + p[0] + \".txt\"\n","    # B0_time_series_write = B0_graph.time_series_write(p[0],B0_file_out,B0_time_series[0],B0_time_series[1])\n","    print(\"\\n\")\n","    # Part D: RGB Bar Graph B0.csv\n","    # B0_rgb_graph = Graphs_rgb(B0_vert, 1, graph_count)\n","    # B0_rgb_bar = B0_rgb_graph.rgb_timeseries_bar(title_full[graph_count-2])\n","    graph_count += 1\n","  # Part D Continued: B0\n","  # RGB Line Graphs by Group for B0.csv\n","  # B0_rgb_line = B0_rgb_graph.rgb_timeseries_line(title_full)\n","\n","\n","\n","\n","\n","\n"],"metadata":{"id":"IxtfVwAjhyaV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1738894201741,"user_tz":360,"elapsed":101,"user":{"displayName":"David Leifer","userId":"06279506333224389759"}},"outputId":"40039f54-12e5-4c39-ee52-6ce140d18314"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["3.11.11 (main, Dec  4 2024, 08:55:07) [GCC 11.4.0]\n","x:  ['But', '1', '4', '2', '2', '1', '1', '2', '2', '4', '2', '1', '2', '1', '1', '2', '1', '2', '1', '1', '1', '2', '1', '1', '2', '1', '1', '1', '4', '4', '2', '1']\n","-0.15924493426914146\n","0.0040000114094315194\n","-0.2676901274800325\n","-0.3398425306580413\n","-0.3428886101501313\n","-0.2583845512184361\n","-0.3883115825825685\n","\n","x:  ['But', '1', '4', '2', '2', '1', '1', '2', '2', '4', '2', '1', '2', '1', '1', '2', '1', '2', '1', '1', '1', '2', '1', '1', '2', '1', '1', '1', '4', '4', '2', '1']\n","-0.011226890934833015\n","0.21030612474198854\n","-0.07966515957119163\n","-0.08196188278097741\n","-0.1727908206024162\n","-0.18524897271708857\n","-0.03670745272525027\n","\n","x:  ['But', '1', '4', '2', '2', '1', '1', '2', '2', '4', '2', '1', '2', '1', '1', '2', '1', '2', '1', '1', '1', '2', '1', '1', '2', '1', '1', '1', '4', '4', '2', '1']\n","0.07538300924500459\n","0.0793242938083018\n","0.2804526193933921\n","0.3737253917042502\n","0.3838029609857442\n","0.17080094661771858\n","0.019971080149027244\n","\n","x:  ['But', '1', '4', '2', '2', '1', '1', '2', '2', '4', '2', '1', '2', '1', '1', '2', '1', '2', '1', '1', '1', '2', '1', '1', '2', '1', '1', '1', '4', '4', '2', '1']\n","-0.013993460185188352\n","0.13314564396582768\n","-0.05043632935445834\n","-0.15242803223602086\n","-0.21537053156577196\n","-0.2308986645644453\n","-0.17469338742996246\n","\n","x:  ['But', '1', '4', '2', '2', '1', '1', '2', '2', '4', '2', '1', '2', '1', '1', '2', '1', '2', '1', '1', '1', '2', '1', '1', '2', '1', '1', '1', '4', '4', '2', '1']\n","0.07038568354350659\n","-0.22580651099660892\n","0.16712573654305862\n","0.3398261776626088\n","0.3182487580102547\n","0.10404133310782888\n","0.006945496407783417\n","\n","x:  ['But', '1', '4', '2', '2', '1', '1', '2', '2', '4', '2', '1', '2', '1', '1', '2', '1', '2', '1', '1', '1', '2', '1', '1', '2', '1', '1', '1', '4', '4', '2', '1']\n","0.07597663544637942\n","0.10539784318022843\n","0.2076115815918834\n","0.39881390930637484\n","0.4991108865924815\n","0.32578435965362157\n","0.24648203776729835\n","\n","x:  ['But', '1', '4', '2', '2', '1', '1', '2', '2', '4', '2', '1', '2', '1', '1', '2', '1', '2', '1', '1', '1', '2', '1', '1', '2', '1', '1', '1', '4', '4', '2', '1']\n","-0.1107970913294343\n","0.10014577368666121\n","0.13846563449278534\n","0.11220972047395704\n","0.30032690247562793\n","0.04851758809257074\n","0.3211902113459399\n","\n","x:  ['But', '1', '4', '2', '2', '1', '1', '2', '2', '4', '2', '1', '2', '1', '1', '2', '1', '2', '1', '1', '1', '2', '1', '1', '2', '1', '1', '1', '4', '4', '2', '1']\n","0.08877202304994704\n","0.020274556008425232\n","0.29389249463351413\n","0.3676846685456705\n","0.5341631398385434\n","0.27740858802821505\n","0.5170480663494498\n","\n","x:  ['But', '1', '4', '2', '2', '1', '1', '2', '2', '4', '2', '1', '2', '1', '1', '2', '1', '2', '1', '1', '1', '2', '1', '1', '2', '1', '1', '1', '4', '4', '2', '1']\n","-0.034139597074867085\n","0.10275073509143691\n","-0.18517704933541856\n","-0.11528017002743783\n","-0.0844216204151573\n","-0.21804293226086277\n","-0.10064024117348337\n","\n","x:  ['But', '1', '4', '2', '2', '1', '1', '2', '2', '4', '2', '1', '2', '1', '1', '2', '1', '2', '1', '1', '1', '2', '1', '1', '2', '1', '1', '1', '4', '4', '2', '1']\n","0.12057407570394145\n","-0.23547043458454275\n","0.15775433343065115\n","0.02123582079452805\n","0.044769041129250044\n","0.047996871881321956\n","0.23733458936530194\n","\n","x:  ['But', '1', '4', '2', '2', '1', '1', '2', '2', '4', '2', '1', '2', '1', '1', '2', '1', '2', '1', '1', '1', '2', '1', '1', '2', '1', '1', '1', '4', '4', '2', '1']\n","0.07666513554079474\n","-0.20594916066743899\n","0.008915967626173896\n","0.009173012360596774\n","0.09427473920918161\n","-0.059606512127778725\n","0.3196012898010883\n","\n","x:  ['But', '1', '4', '2', '2', '1', '1', '2', '2', '4', '2', '1', '2', '1', '1', '2', '1', '2', '1', '1', '1', '2', '1', '1', '2', '1', '1', '1', '4', '4', '2', '1']\n","0.13158685677839213\n","-0.061523260375132185\n","0.03936016683050667\n","-0.09164637279250001\n","0.015726193342793054\n","-0.095138830273974\n","0.012755979039741815\n","\n","x:  ['But', '1', '4', '2', '2', '1', '1', '2', '2', '4', '2', '1', '2', '1', '1', '2', '1', '2', '1', '1', '1', '2', '1', '1', '2', '1', '1', '1', '4', '4', '2', '1']\n","0.1474233456443143\n","0.07694670675911908\n","0.17693257165480014\n","0.14941476873821308\n","0.14307825610593852\n","0.0428076680032452\n","0.03238743950975472\n","\n","x:  ['But', '1', '4', '2', '2', '1', '1', '2', '2', '4', '2', '1', '2', '1', '1', '2', '1', '2', '1', '1', '1', '2', '1', '1', '2', '1', '1', '1', '4', '4', '2', '1']\n","-0.07027134471856203\n","0.004791819539302287\n","-0.09559887815140365\n","-0.09835496579952548\n","-0.08530241022126651\n","-0.13506857559234092\n","-0.0031934446018337145\n","\n","x:  ['But', '1', '4', '2', '2', '1', '1', '2', '2', '4', '2', '1', '2', '1', '1', '2', '1', '2', '1', '1', '1', '2', '1', '1', '2', '1', '1', '1', '4', '4', '2', '1']\n","0.049166351322968045\n","-0.008130275960201038\n","0.03490434227049293\n","-0.09505753473102949\n","-0.062346317913312604\n","-0.06684146360245177\n","-0.0785655620212247\n","\n","x:  ['But', '1', '4', '2', '2', '1', '1', '2', '2', '4', '2', '1', '2', '1', '1', '2', '1', '2', '1', '1', '1', '2', '1', '1', '2', '1', '1', '1', '4', '4', '2', '1']\n","0.15854560612849547\n","0.055080175527663616\n","0.27313768995837123\n","0.28101216953477964\n","0.20981742501721942\n","0.2249451811564644\n","0.3770856507230255\n","\n","x:  ['But', '1', '4', '2', '2', '1', '1', '2', '2', '4', '2', '1', '2', '1', '1', '2', '1', '2', '1', '1', '1', '2', '1', '1', '2', '1', '1', '1', '4', '4', '2', '1']\n","0.23030429188251736\n","-0.13314564396582773\n","0.05043632935445835\n","-0.14918488261397786\n","-0.10255739598370099\n","-0.1099517450306883\n","-0.05453391459453855\n","\n","x:  ['But', '1', '4', '2', '2', '1', '1', '2', '2', '4', '2', '1', '2', '1', '1', '2', '1', '2', '1', '1', '1', '2', '1', '1', '2', '1', '1', '1', '4', '4', '2', '1']\n","0.07291344603956304\n","-0.14951360107354164\n","-0.05448584771770539\n","-0.056056658743901686\n","-0.021769597149941346\n","-0.07501878251626606\n","0.13874113024810336\n","\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"-nFsmafK9qPM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"_rbkOBIoVFv9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"49dfF0jwVFyW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"KMfY_RzQVF1X"},"execution_count":null,"outputs":[]}]}